# Building

# Generative AI

# Agents

```
Using LangGraph, AutoGen,
and CrewAI
―
```
Tom Taulli · Gaurav Deshmukh


**Building Generative**

**AI Agents**

**Using LangGraph, AutoGen,**

**and CrewAI**

**Tom Taulli**

**Gaurav Deshmukh**


**Building Generative AI Agents: Using LangGraph, AutoGen, and CrewAI**

ISBN-13 (pbk): 979-8-8688-1133-3 ISBN-13 (electronic): 979-8-8688-1134-
https://doi.org/10.1007/979-8-8688-1134-

Copyright © 2025 by Tom Taulli, Gaurav Deshmukh
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or
part of the material is concerned, specifically the rights of translation, reprinting, reuse of
illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way,
and transmission or information storage and retrieval, electronic adaptation, computer software,
or by similar or dissimilar methodology now known or hereafter developed.
Trademarked names, logos, and images may appear in this book. Rather than use a trademark
symbol with every occurrence of a trademarked name, logo, or image we use the names, logos,
and images only in an editorial fashion and to the benefit of the trademark owner, with no
intention of infringement of the trademark.
The use in this publication of trade names, trademarks, service marks, and similar terms, even if
they are not identified as such, is not to be taken as an expression of opinion as to whether or not
they are subject to proprietary rights.
While the advice and information in this book are believed to be true and accurate at the date of
publication, neither the authors nor the editors nor the publisher can accept any legal
responsibility for any errors or omissions that may be made. The publisher makes no warranty,
express or implied, with respect to the material contained herein.
Managing Director, Apress Media LLC: Welmoed Spahr
Acquisitions Editor: Shiva Ramachandran
Development Editor: James Markham
Project Manager: Jessica Vakili
Distributed to the book trade worldwide by Springer Science+Business Media New York, 1 New
York Plaza, New York, NY 10004. Phone 1-800-SPRINGER, fax (201) 348-4505, e-mail orders-ny@
springer-sbm.com, or visit [http://www.springeronline.com.](http://www.springeronline.com.) Apress Media, LLC is a Delaware LLC and
the sole member (owner) is Springer Science + Business Media Finance Inc (SSBM Finance Inc).
SSBM Finance Inc is a **Delaware** corporation.
For information on translations, please e-mail booktranslations@springernature.com; for
reprint, paperback, or audio rights, please e-mail bookpermissions@springernature.com.
Apress titles may be purchased in bulk for academic, corporate, or promotional use. eBook
versions and licenses are also available for most titles. For more information, reference our Print
and eBook Bulk Sales web page at [http://www.apress.com/bulk-sales.](http://www.apress.com/bulk-sales.)
If disposing of this product, please recycle the paper

Tom Taulli
Monrovia, CA, USA

```
Gaurav Deshmukh
Tarzana, CA, USA
```

**关于作者**

**Tom Taulli** 是一位为多家公司（如风险投资支持的生成式AI初创企业Aisera）提供咨询的专家。他著有《人工智能基础》和《生成式AI》等多本书籍。Tom还曾在UCLA、PluralSight和O’Reilly Media教授IT课程，内容涵盖如何使用Python构建深度学习和机器学习模型，以及自然语言处理（NLP）等主题。

**Gaurav Deshmukh** 是一位经验丰富的技术领导者，在推动变革性软件工程项目方面拥有十多年的经验。他曾在Guidewire、Cigna、Home Depot、美国农业实验室（AmAgLab）、Tata Elxsi和Amdocs等知名企业担任关键技术职位。Gaurav精通云计算、网络安全、软件自动化、数据工程以及多种编程语言和Web技术框架的全栈开发。他善于利用广博的知识创造创新解决方案，以优化工作流程并促进业务增长。Gaurav拥有MBA和计算机科学硕士学位，专注于数据仓库和计算机视觉。他致力于提升软件工程在实现商业价值中的战略作用。


© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 1

https://doi.org/10.1007/979-8-8688-1134-0_

**CHAPTER 1**

**Introduction to AI**

**Agents**

Andrew Ng 是人工智能领域的杰出人物，兼具学者与企业家的双重身份。
在上世纪 90 年代，许多科技界人士专注于互联网泡沫时，Ng 却更关注人工智能。在贝尔实验室工作期间，他致力于模型评估、特征选择优化以及强化学习的研究。
随后，他在麻省理工学院（MIT）获得电气工程与计算机科学硕士学位，并在加州大学伯克利分校获得计算机科学博士学位，其博士论文主题为强化学习。
Ng 后来成为斯坦福大学的教授，他主讲的 CS229 课程成为最受欢迎的课程之一。他也是最早意识到 GPU（图形处理单元）对 AI 系统有重要作用的人之一。
Ng 最终将 AI 技能应用于商业领域，曾担任百度首席科学家，并参与创建 Google Brain。
2011 年，他主导开发了斯坦福大学的大规模开放在线课程（MOOC）平台，该平台迅速吸引了大量学生注册。


Ng 利用这些经验共同创办了 Coursera，这是全球顶尖的在线学习平台之一。该公司于 2021 年上市，市值接近 60 亿美元。目前，Coursera 拥有约 1.48 亿注册用户，并与 325 多所大学和企业建立了合作关系。^1  
此后，Ng 又创办了 DeepLearning.AI 和 Landing AI 等公司，还发起了风险投资基金。  
毫无疑问，Ng 擅长把握趋势——尤其是在 AI 领域。他是那种你不应该与之对赌的人。  
那么，他接下来关注的是什么？他认为最大的机会在哪里？  
答案是 AI Agent。他指出，这是一个“令人兴奋的趋势”，也是你“应该关注的”方向。^2 他还表示：

```
AGI（通用人工智能）更像是一段旅程，而不是一个终点。但我认为……Agent 工作流或许能让我们在这段漫长旅程中迈出一小步。^3
```
Ng 绝非特例。科技行业许多最具影响力的人物都对 AI Agent 持乐观态度。
以比尔·盖茨为例。他在自己的博客中写道：

```
在计算机行业，我们常常谈论平台——也就是应用和服务赖以构建的技术基础。Android、iOS 和 Windows 都是平台。Agent 将成为下一个平台。
```
在他的文章中，他详细阐述了自从 1970 年代中期创办微软以来，软件其实并没有太大改变。应用程序依然“相当愚蠢”。

(^1) https://investor.coursera.com/overview/default.aspx
(^2) https://www.youtube.com/watch?v=sal78ACtGTc&t=125s
(^3) https://www.youtube.com/watch?v=sal78ACtGTc&t=125s
Chapter 1 IntroduCtIon to aI agents


但 AI Agent 将改变一切。其关键在于系统能够理解你的“工作、个人生活、兴趣和人际关系”。换句话说，软件将变得非常智能——也会更加有用和高效。
盖茨表示：

```
想象一下你想计划一次旅行。一个旅行机器人会帮你挑选符合预算的酒店。而一个 Agent 则会知道你要出行的季节，并结合你是喜欢每次探索新目的地，还是更愿意反复前往同一个地方的习惯，推荐合适的地点。当你提出请求时，它会根据你的兴趣和冒险倾向，推荐适合的活动，并预订你喜欢类型的餐厅。如果你现在想要这种深度个性化的规划，就必须雇佣旅行社，还得花时间告诉他们你的需求。^4
```
然后，来看一下麦肯锡（McKinsey）对AI Agent的看法。麦肯锡是帮助企业利用AI技术的全球领导者之一：

```
Agent释放的价值，来自其自动化处理各种复杂用例的潜力——这些用例通常具有极其多样化的输入和输出，以往难以通过成本效益高或省时的方式解决。以商务出行为例，可能涉及无数行程方案，包括不同的航空公司和航班，以及酒店积分计划、餐厅预订和业余活动等，这些都需要在不同的在线平台之间协调处理。尽管已有尝试对部分流程进行自动化，
```
(^4) https://www.gatesnotes.com/AI-agents
Chapter 1 IntroduCtIon to aI agents


```
许多流程仍然需要人工处理。这在很大程度上是因为输入和输出的多样性，使得自动化过程变得过于复杂、昂贵或耗时。^5
注意：Sonya Huang 是红杉资本（Sequoia Capital）的合伙人。她投资了 Hugging Face、Glean 和 LangChain 等最热门的生成式 AI 创业公司。^6 她表示：“我们坚信，Agent 是 AI 的下一个浪潮，整个行业正从 Copilot 迈向 Agent 时代。”^7
```

什么是 AI Agent？

对于 AI Agent，目前没有一个明确、统一的定义。但这并不令人意外。AI Agent 这一领域还处于初期阶段，技术发展极为迅速。正如互联网最终涵盖了各种应用和服务，AI Agent 也很可能经历类似的快速发展与多样化过程。这意味着开发者正处于一个充满机遇和创新的时代。
当然，我们仍然需要一个基本的定义。那么，这个定义应该是什么？一个很好的起点，是参考生成式 AI 革命的先驱之一——Harrison Chase。他是 LangChain 的联合创始人，而 LangChain 是目前最流行的 AI Agent 开发框架之一。

(^5) https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/
why-agents-are-the-next-frontier-of-generative-ai
(^6) https://www.linkedin.com/in/sonyaruihuang/details/experience/
(^7) https://www.sequoiacap.com/podcast/training-data-harrison-chase/
Chapter 1 IntroduCtIon to aI agents


```
以下是他对生成式 AI Agent 的定义：
```
```
我认为，Agent 就是在应用程序的控制流中由 LLM 做决策。我的意思是，如果你有一个更传统的 RAG（检索增强生成）链，步骤往往是预先设定好的，比如你首先会生成一个搜索查询，然后检索一些文档，然后生成答案，最后返回给用户。这是一个非常固定的顺序。^8
```
```
而当我谈到“Agentic”的时候，我指的是让 LLM 处于核心位置，由它决定具体要做什么。也许有时候它会执行搜索查询，有时候不会，可能直接回复用户。有时它会先查一次，再查多次，然后再回复。所以，相当于让 LLM 自主决定整个流程。
```

另一种理解 AI Agent 的方式是分析其核心组成部分。这些组件包括反思、工具、记忆、规划、多 Agent 协作和自主性。  
下面我们将分别介绍每一项。

反思(Reflection)

在AI代理中，反思(Reflection)是指系统能够自我检查并调整其认知过程。这种自我意识使AI能够审视自身的决策过程、学习模式和解决问题的方法。通过反思，AI可以分解复杂挑战，从经验中提取洞见，并为其结论提供更清晰的理由说明。

(^8) https://www.sequoiacap.com/podcast/training-data-harrison-chase/
Chapter 1 IntroduCtIon to aI agents


最新研究（如 Reflexion 框架）表明，自我反思对于提升 AI 能力具有重要意义。Reflexion 通过语言化的自我反思为未来的尝试生成有价值的反馈，并将这些反馈存储在代理的记忆中。该过程涉及一种迭代的优化方式：代理评估自身行为、获取反馈、并据此调整其行为。这种方法已被证明能够提升决策、推理和编程等任务的表现。

这种元认知能力增强了 AI 系统的灵活性和适应力。当 AI 评估自身以往的表现和结果时，可以不断优化策略，拓展自主能力。该过程有助于错误检测、策略演化和更高效地实现目标。例如，Reflexion 代理在 AlfWorld 环境以及基于搜索的问题解答和代码生成等任务中表现出了更优的性能。^9

工具(Tool)

在生成式 AI 代理中，“工具”指的是代理与外部工具、API 或软件的交互能力，这极大地增强了其功能，使其能够完成更复杂的任务。这一特性让 AI 系统不仅限于基础的文本或图像生成，还能够获取最新信息、检索实时数据、执行计算、操作文件，并通过串联多个操作实现自动化工作流。这种集成显著提高了 AI 的准确性，并拓展了其领域知识。

生成式 AI 工具使用的典型例子包括：网页浏览以获得最新信息、在实时环境中执行代码、数据分析与可视化、日历管理、文件操作以及复杂的数学运算。这些能力让 AI 代理能够高效处理更广泛的任务。例如，Salesforce 的 Einstein GPT 集成了 CRM 工具，为各类业务场景生成 AI 内容。又如 AWS 的 Solution Architect Agent 利用定制工具查询 AWS 文档、生成代码和创建架构图。

复杂任务常常发生在动态环境中，解决方案并不总是显而易见，情况也可能随时变化。例如，某些数据源可能临时不可用，代理需要自动切换到其他来源；或者某些操作可能带来意外的副作用。再比如在应用开发中，一次 API 请求可能因网络问题、参数错误或接口变更而失败。此时，代理需要根据反馈（如错误信息）调整参数重试，或请求人的帮助。

如果没有可用的 API，代理还需具备操作终端用户界面的能力。这项任务极具挑战性：代理需理解界面内容（可通过解析 HTML 元素或识别屏幕截图中的像素），然后判断如何操作（比如点击按钮、填写表单），并通过检测确认信息等方式验证操作是否成功。每一步操作都会改变界面状态，影响后续行为，这要求代理持续调整与适应其策略。

记忆（Memory）

在 AI 代理中，记忆是一项关键能力，使系统能够保留和利用先前交互或任务中的信息。这一能力让 AI 能够保持上下文、从经验中学习，并输出更连贯、更个性化的响应。

记忆有不同的类型。首先是短期记忆（Short-term memory），它用于临时保留和处理与当前任务相关的信息。短期记忆跟踪最近发生的事件或数据点，这些信息在短时间内有用，随后会被丢弃或转移到长期记忆。实现方式通常包括维护最近操作或对话轮次的日志。

其次是长期记忆（Long-term memory）。在较高层面，长期记忆让代理能够在较长时间跨度内保留和访问信息，存储累积的知识、经验和已建立的模式，从而影响其决策和适应能力。长期记忆常通过向量数据库实现，便于根据事件、描述和相关元数据进行高效检索。数据的结构、表示与检索机制会显著影响记忆的回溯效果和 AI 代理的整体性能。

长期记忆包含以下几类：

- 情节记忆（Episodic Memory）：存储具体事件或经历，使代理能够回忆过去的情景，并将经验应用于当前任务。
- 语义记忆（Semantic Memory）：保存关于世界的一般性知识和事实，使代理理解对象、概念、关系和程序，即使在陌生场景下也能够推理和归纳。
- 程序性记忆（Procedural Memory）：侧重于存储习得的技能和流程，更关注“如何做”而非具体事件的回忆。

最新研究表明，具备短期、情节和语义记忆系统的 AI 代理，在复杂环境下的表现优于没有结构化记忆的代理，这证明了这些记忆类型对于任务执行和学习效率的提升作用（Kim 等, 2023）。^10

随着任务复杂度的提高，发展先进的记忆系统对于提升 AI 代理的自主能力至关重要。例如，JARVIS-1 代理通过多模态记忆增强了其复杂开放环境下的任务规划与执行能力，展现出显著的性能和适应性优势（Weng, 2023）。^11

Planning

在 AI 代理中，规划（Planning）指的是利用大语言模型（LLM）自主确定实现更大目标所需的一系列步骤。这一过程帮助 AI 将复杂目标拆解为可管理的具体任务，从而增强其执行复杂项目的能力。例如，LLM 可以指导 AI 代理组织一场虚拟活动，将整体任务细分为选择讲者、安排日程、协调技术支持等步骤。

近年来的进展显示，基于 LLM 的规划对自主代理系统有深远影响。例如，Reflexion 框架将规划、自我反思和记忆结合起来，能够通过反馈和过往经验动态调整规划，逐步提升任务表现，从而改进决策和执行效果。

此外，TPTU（任务规划与工具使用）框架强调规划与工具使用的协同作用。该框架评估 LLM 在任务规划与工具调用上的有效性。AI 代理可以选择一步到位（one-step approach），即一次性规划全部任务，也可以采用逐步推进（sequential approach），将任务分解为子任务，每步完成后根据反馈动态调整。

在实际场景中，规划让 AI 代理能够灵活应对需要动态响应和专业知识的任务。例如，一个负责自动化家庭花园的 AI 代理可以规划出安装传感器、设置灌溉计划、监测植物健康、与手机应用集成等步骤。

虽然规划极大提升了 AI 代理的能力，但也带来了一定的不确定性——由于动态生成方案的复杂性，代理有时可能偏离预期行为。不过，随着相关技术的不断进步，AI 代理的规划可靠性和智能化水平有望持续提升。

Multi-agent Collaboration

多智能体协作利用多个大语言模型（LLM）协同完成复杂任务。这种方式类似于人类团队合作——每个代理专注于不同的子任务，以实现共同目标。例如，在市场营销活动项目中，不同的 AI 代理可以分别担任内容创作者、市场分析师、活动策划师和效果评估员等角色。

通过为一个或多个 LLM 分配不同任务，可以创建专门化的代理。例如，在营销活动中，负责内容创作的代理可以被提示：“你是一位擅长撰写引人入胜市场文案的专家。请为新产品推广活动撰写内容……”。这种方法充分发挥 LLM 的优势，同时保持对具体子任务的聚焦，从而提升整体性能和效率。

另一个代理可以负责市场分析，其提示词可能是：“你擅长分析市场趋势和消费者行为。请基于最新数据为活动策略提供见解。”

研究表明，多智能体系统往往优于单一代理。例如，麻省理工学院的相关研究显示，多个 AI 模型之间的协作互动能够显著提升推理和事实准确性。^12 通过开展协商式流程，这些代理能够相互批判输出结果，从而获得更准确、全面的解决方案。

自主性

AI 代理具备自主性，能够在无需持续人工干预的情况下独立做出决策并执行任务。这种自主性源自其对数据的处理能力、从经验中学习的能力以及对新情境的实时适应能力。先进的算法和机器学习技术使这些代理能够评估环境、识别模式、预测结果，从而采取与其既定目标一致的行动。例如，在自动驾驶车辆中，AI 代理必须不断解析传感器数据，导航道路、避开障碍，并做出确保安全与效率的驾驶决策。这些决策均需即时生成，充分体现了代理在动态环境下的自主能力。

此外，AI 代理通过持续学习和适应进一步提升其自主性。机器学习模型让代理能够从过往经验中学习，不断优化自身表现。学习过程包括分析以往的行为和结果，从而完善未来的策略。例如，在客户服务应用中，AI 代理可以根据以往的互动经历，为后续用户提供更为准确和个性化的响应。

然而，让 AI 代理完全自主往往并不明智。实际上，自治与控制之间存在一个光谱，需要权衡。许多场景下，人类监督依然至关重要，以确保代理的行为符合更广泛的伦理标准、安全规范和组织目标。通过在自主性和人工控制之间取得平衡，我们既能充分发挥 AI 的优势，也能降低无人监督带来的风险。

确实，设计一个代理涉及许多组件，但这并不意味着所有组件都必须使用。实际应用中，可能只需要其中的一部分，具体取决于场景需求。

UI and UX

用户界面（UI）和用户体验（UX）是软件应用中至关重要的组成部分，直接影响用户的满意度、参与度和生产力。良好的 UI 设计能够确保软件在视觉上具有吸引力且直观易用，使用户能够高效地导航和完成任务。优质的 UX 设计则关注用户整体的使用体验，包括易用性、可访问性和响应速度。UI 与 UX 的结合有助于降低新用户的学习成本，减少错误，提高软件的整体效率和效果。

这不仅提升了用户满意度，还能推动更高的采用率和客户忠诚度。据 Forrester Research 研究显示，优秀的 UI 设计可将网站转化率提升至 200%，而更好的 UX 设计则可带来高达 400% 的转化提升。^13 随着 AI 代理的发展，重新思考 UI 和 UX 设计变得尤为重要，以应对大语言模型（LLM）带来的独特挑战。由于 LLM 并非总是完美可靠，传统的聊天界面成为早期常见方案。这类界面让用户能够直观地看到 AI 的操作，接收流式回复，对 AI 进行纠正以及提出后续问题。这种交互式且透明的形式确保用户始终掌控流程，可随时做出调整。

然而，这种方式也有局限性——人类始终处于流程中的核心环节，使系统更像是“副驾驶”而非完全自主的操作员。为实现平衡，可以通过确保 AI 行为的透明度和可追溯性来提升信任度。例如，在家庭自动化场景中，详细记录代理执行的每一步操作，让用户能够随时回顾并在必要时进行修改。

这种回顾流程可以通过界面进一步简化，例如允许用户轻松调整灯光、恒温器和安防系统的计划。AI 可以自主管理这些设备，但用户依然可以介入调整设置或提供反馈，AI 随后可学习并在未来任务中加以改进。

此外，与 AI 代理的交互界面还可以设计得更具主动性，并集成到日常设备中。无需用户主动打开应用，AI 可在后台运行，并在需要时通过智能家居中心或可穿戴设备主动发出提醒。例如，AI 代理可能会通过消息告知：“您的今日能耗高于平常，需要我为您调整恒温器设置以节约能源吗？”

这种主动式设计让 AI 代理无缝融入用户的生活，按需提供帮助，无需用户频繁手动操作。

归根结底，面向 AI 代理的 UI 和 UX 设计需要在保持用户友好性的同时，赋予系统一定的自主性，并始终保证透明和可靠。这样才能让用户信任 AI 代理高效处理任务，仅在必要时介入干预，以确保达成预期目标。

New Approaches to Development

传统软件开发遵循相当确定性的工作流程。它基于结构化和顺序化的方法来创建软件应用程序。通常，这一过程从需求分析开始，明确软件的需求和目标。接下来是系统设计阶段，制定系统架构和详细的技术规范。之后进入实现或编码阶段，开发人员根据设计规范编写实际代码。编码完成后，软件将经过严格的测试环节，以发现并修复潜在的缺陷或问题。测试通过后，软件被部署到生产环境中。最后，开发团队会根据实际运行中出现的问题进行维护和更新。

传统软件开发的确定性体现在其可预测性和可重复性上。开发流程的每个阶段都定义明确，按线性顺序推进。清晰的文档和规范化流程使得大型团队协作和复杂项目管理变得更加高效和可控。

开发生成式 AI 代理与传统软件开发有着显著不同，因为它依赖概率性结果而非确定性流程。这对于开发者来说是一个重大转变。

让我们来看一下典型的开发流程。第一步是确定用例，这往往很复杂，因为某些场景对可预测性有较高要求，可能并不适合引入 AI。选定合适的用例后，接下来就是选择一个或多个模型。这一过程也很复杂，因为模型本身非常先进且更新频繁。

开发生成式 AI 代理时，成本是另一个关键因素。无论是通过 API 使用模型，还是在本地运行模型，费用都可能相当可观。本地运行模型可能需要采购昂贵的硬件设备，比如 GPU。此外，还需要充分评估整个工作流程的复杂性。由于大语言模型（LLM）的输出具有概率性，总是存在输出或决策不准确的风险。为了降低这些风险，开发中通常会加入防护措施，并考虑引入“人类参与环节”（human-in-the-loop），以确保安全性和准确性。

对生成式 AI 代理的测试也充满挑战，因为其响应结果具有不可预测性。测试阶段可能会耗时且细致，需要大量反复试验，以确保系统的可靠性和有效性。

据红杉资本合伙人 Sonya Huang 和 Pat Grady 表示：

```
现有的监控工具无法为 LLM 调用提供足够细致的溯源能力。测试方式在充满随机性的世界中也变得不同——你无法像“测试 2=2”那样做一个计算机能轻松验证的简单单元测试。测试变成了一个更为细致复杂的概念，
```
```
需要采用如成对比较（例如 Langsmith、Lmsys）和持续跟踪改进/回退等技术。所有这些都需要一套全新的开发者工具。^14
```
为了提升准确率，往往需要引入包含专有信息的数据库，这又增加了一层复杂性。这可能涉及微调模型，或采用 RAG（检索增强生成）等技术来提升模型表现。每一步都凸显了开发生成式 AI 代理的动态性与适应性，这与传统软件开发中更具确定性的工作流截然不同。

Flavors of AI Agents

AI 代理主要分为两类：具身代理和软件代理。每种类型都服务于不同的目的，并在各自的环境中运行，利用 AI 的独特能力来应对特定的需求和挑战。

具身代理是与物理世界或三维仿真环境互动的 AI 系统。它们常见于机器人领域，可执行装配线作业、仓库管理和自主导航等任务。在视频游戏中，具身代理用于控制非玩家角色（NPC），为玩家带来更具沉浸感和真实感的体验。开发具身代理需要复杂的算法，以便在动态环境中实现感知、决策和行动。这类代理通常依赖传感器、摄像头及其他输入设备来收集环境信息，实时处理数据并执行相应操作。

相较之下，软件代理则运行于数字环境中，处理与办公、工作流和数据管理相关的任务。这些代理能够自动化重复性工作、管理电子邮件、安排日程并推动复杂的业务流程。软件代理旨在通过充当智能助手，提高生产效率并简化操作，能够理解用户指令并执行各种命令。

这两类代理的开发面临不同的挑战和方法论。具身代理需要在真实或仿真环境中进行大量训练，以高效完成物理任务。这一过程通常采用强化学习，让代理通过不断试错优化自身行为。而软件代理则多通过在大规模数据集上训练大语言模型（LLM），以理解并生成类人响应。

本书将以软件代理为主要讨论对象。

Brief History

自人工智能诞生以来，AI 代理的概念便已出现。20 世纪 50 年代的早期程序为其发展奠定了基础。1955 年，艾伦·纽厄尔（Allen Newell）和赫伯特·西蒙（Herbert A. Simon）开发了“逻辑理论家”（Logic Theorist），这是最早的 AI 程序之一，旨在通过证明《数学原理》中的定理来模拟人类的问题解决能力。它利用自动推理与启发式方法，展示了机器执行智能任务的潜力。随后，纽厄尔和西蒙还开发了更通用的“通用问题求解器”（General Problem Solver, 1957），能够应用通用策略解决各类问题。该系统引入了手段—目的分析和分层问题求解方法，力求实现普适性，对人工智能和认知心理学领域都产生了深远影响。这些开创性的努力证明了机器能够模拟人类推理，并激发了后续 AI 技术的持续创新。

当然，生成式 AI 代理是人工智能领域中非常新的发展。突破性进展源于 2022 年 11 月 OpenAI 推出的 ChatGPT，它迅速成为增长最快的网络应用。OpenAI 后续发布的模型，包括 GPT-4o，极大提升了生成式 AI 的能力，使其能够实现更准确、更复杂的文本生成、推理和内容创作。这些进步让 AI 能够在客户服务、软件开发等各类应用中发挥作用。

LangChain 在生成式 AI 代理的发展中扮演了关键角色，它通过提供框架简化了 LLM 与各种数据源和工具的集成。这项技术大约在 2023 年中期出现，并开始为能够规划、执行任务并根据结果自适应的代理提供全面支持。

与此同时，BabyAGI 和 AutoGPT 等其他系统也开始构建生成式 AI 代理。它们最初在 AI 社区引发了极大关注。BabyAGI 由中岛阳平（Yohei Nakajima）创建，AutoGPT 由 Toran Bruce Richards 开发，这两者都试图利用 OpenAI 的 GPT-4 等 LLM，实现以最少人为干预自动化复杂任务的突破性能力。然而，最初的热情很快被其局限性所冷却。这些系统常常表现出脆弱性和泛化能力不足，容易陷入循环或无法连贯地完成任务。

但这其实无妨。创新过程本就如此，常常会有“伪起点”，这些早期尝试有助于发现亟需改进的关键领域。BabyAGI 和 AutoGPT 的经验为自主 AI 代理的完善和进化提供了宝贵的教训和启示。

如今，LangGraph、AutoGen 和 CrewAI 等新平台正在推动这一持续进化。LangGraph 提供了构建有状态、多智能体系统的框架，能够处理复杂工作流，并与各种工具无缝集成，增强了 AI 代理的可靠性和效率。AutoGen 利用最新机器学习与自然语言处理技术，具备更高的内容生成与任务自动化能力，实现更强的精确性和适应性。CrewAI 则聚焦于协作型 AI，使多个代理能够协同完成复杂项目，优化资源利用率并提升整体性能。这些开源平台代表了生成式 AI 发展的新阶段，基于以往经验，打造更加坚韧和多元的 AI 代理。

新兴的专有系统也在企业级应用领域取得重大进展。这些系统专为满足企业复杂需求而设计，具备强大的安全性、可扩展性和集成能力。微软、谷歌等公司正将先进的 AI 功能集成到企业解决方案中，为各类业务场景提供提升生产力、自动化日常任务和生成可操作洞见的工具。

需要强调的是，这一切尚处于早期阶段，但 AI 代理核心技术的创新和投资速度依然非常迅猛。

LLMs, Copilots, and RPA

生成式 AI 代理与通用型大语言模型（LLM），如 ChatGPT、Claude 和 Gemini，在多个关键方面存在显著区别。虽然 LLM 擅长根据提示生成文本，并且能够通过互联网搜索或 API 获取附加信息，但它们通常不会参与复杂的动作或规划。这类 LLM 主要为对话式交互而设计，不具备生成式 AI 代理常常需要的专业能力或领域知识。尽管 LLM 正在逐步引入更多代理特性，其核心功能仍然侧重于信息提供和对话交流，而不是执行任务或决策。

那么，copilot（副驾）又是什么？它们更加专注于具体任务，往往针对某一应用场景或垂直领域（如市场营销、法律或人力资源）量身定制。以市场营销 copilot 为例，它可以帮助撰写广告文案或分析活动表现数据。这类代理不仅能生成文本，还能从各种信息源（如邮箱或数据库）检索并整合相关信息以提升输出质量。用户可以与这些代理互动，接受、拒绝或修改建议，从而优化工作流并提升特定专业领域的生产效率。

而机器人流程自动化（RPA）则属于完全不同的类别。RPA 侧重于自动化传统上由人类完成的重复性、规则化任务。它们依赖预设规则和结构化数据，模拟人类操作界面、填写表单等动作。RPA 本身不具备 AI 决策能力，但可以与 AI 代理集成，从而提升其认知功能，如自然语言理解或模式识别，让 RPA 的应用范围扩展到更复杂的任务。

不过，随着技术发展，未来的主流可能会转向 AI 代理。最终，LLM、copilot 和 RPA 之间的界限也许会逐渐消失，趋于融合。

```
请注意，软件即服务（SaaS）市场的估值约为 2,611.5 亿美元。^15 然而，AI 代理有望彻底变革这一领域。一个主要变革点在于传统的订阅商业模式。毕竟，如果 AI 代理能够承担某些岗位的大部分工作，而且与人类员工的互动极少，那么按座位数或用户数收费似乎就没有意义了。更有可能的商业模式是基于生产力提升、成本节约和决策效果等可衡量的成果进行计费。这本质上是一种以结果为导向的定价模式。
```
Use Cases

Sandi Besen 是 IBM 的应用人工智能研究员。她表示：“我们专注于始终比 AI 曲线领先六个月，持续探索新兴 AI 技术及其在企业解决方案中的应用。过去六个月，我们的全部重心都放在了 AI 代理上。”^16
她观察到，AI 代理正逐步嵌入企业的运营流程，而不仅仅是作为“副驾”工具。这也催生了丰富多样的应用场景。她提到：

```
我们的客户在不同行业中感兴趣的一些用例包括：当航班取消时，代理帮助重新为乘客改签航班；代理自动识别新政策中与现有政策直接冲突的条款；生成带有验证和事实核查的长篇文档；研究型代理从多个渠道收集信息以协助完成任务，这类穷举式搜索对人类来说耗时过长。
```
接下来的章节将介绍企业是如何部署 AI 代理的。


Sierra

Bret Taylor 在科技行业拥有令人瞩目的职业生涯，他最初参与创建了 Google 地图。此后，他投身创业，联合创办了社交媒体聚合公司 FriendFeed，该公司后来被 Facebook 收购。FriendFeed 的“点赞”功能被整合进 Facebook，而 Taylor 也最终担任了 Facebook 的首席技术官。2012 年，Taylor 离开 Facebook，创办了旨在与 Google Docs 竞争的生产力工具 Quip。Quip 最终被 Salesforce.com 高价收购，Taylor 也一路晋升为 Salesforce.com 的联席首席执行官（co-CEO）。

在此过程中，他敏锐意识到 AI 的重要性。为抓住这一潮流，他与前谷歌 VR 负责人 Clay Bavor 共同创立了 Sierra。Sierra 专注于为企业客户打造提升客户体验的 AI 代理平台，强调高度的安全性、治理和隐私保护，并提供问答和审计工具。其知名客户包括 Weight Watchers、Sonos 和 OluKai。Taylor 强调普及先进技术的重要性，他表示：“我们最大的机遇在于让每家公司，无论技术多么复杂或专业，都能成功部署 AI。”

Sierra 的 AI 代理能够无缝集成到企业现有的业务基础设施中，利用企业数据为行动提供依据，并要求所有关键操作获得正式审批。这些代理足够智能，能够以同理心处理复杂的客户互动。平台采用多模型架构，有时会同时使用多达七个模型，其中包括一个“监督”模型，用于监控并确保响应质量。

此外，Sierra 的创始人在定价策略上也进行了创新，采用按结果付费的模式——客户只有在问题被解决时才需要支付费用，而不是传统的订阅或按用量计费。Sierra 已从 Sequoia 和 Benchmark 等顶级投资机构成功融资 1.1 亿美元，显示出投资者对其愿景和实力的高度信心。

Enso

Mickey Haslavsky 的父母经营着小企业，从小他就目睹了他们在采用新技术方面所面临的挑战。受这些经历的启发，Haslavsky 创办了 Enso，这是一家利用 AI 代理协助中小企业（SMB）的公司。他指出：

```
然而，我意识到挑战不仅仅源于代际差异；小企业由于要独自管理一切，常常因精力和资源有限而难以拥抱数字化工具和进步。^19
```

Enso 的 AI 代理以用户友好为设计宗旨，无需技术背景即可上手。它们大多在后台自动处理各类任务与流程，用户只需进行审批和少量调整。这些代理基于广泛的 API 集成，结合了大语言模型（LLM）和机器人流程自动化（RPA）。它们在医疗、金融服务、美容等多个行业经过训练，可为营销、内容创作和调研等场景提供多样化支持。

例如，Enso 的 AI 能够利用研究工具查找播客相关主题，借助 LLM 生成并润色脚本，使用语音生成工具录制音轨，借助 AI 音乐生成器制作片头片尾，并通过视频编辑工具完成视频制作。Enso 的服务定价在每月 29 美元至 79 美元之间。

2024 年 7 月，Enso 宣布完成 600 万美元的种子轮融资，领投方为 NFX，天使投资人包括 Google Research AI 负责人 Yossi Matias 以及前红杉资本合伙人 Shmil Levy 等。^20

Asana

Asana 是一款面向团队的网页和移动应用，旨在帮助用户组织、跟踪和管理工作。它由 Facebook 前员工 Dustin Moskovitz 和 Justin Rosenstein 于 2008 年创立。Asana 推出了名为 “AI Teammates” 的 AI 代理系统，强调“人的参与”在企业流程中的重要性。^21

AI Teammates 让组织能够创建自定义代理，自动化和管理工作流。这一创新至关重要，因为传统的工作流工具往往非常僵化，流程一旦变动就容易出错。例如，如果提交的工单信息不完整，AI Teammate 会自动退回，要求补充必要细节。这一过程可以借助生成式 AI 帮助员工完善描述，再交由 AI Teammate 进行分发和后续处理。

Asana 的一大优势在于其庞大的数据集，拥有超过 10 万家客户。Asana Work Graph 能够追踪任务之间的复杂关联，让 AI 不仅了解工作流程本身，还能理解每个具体场景下任务如何推进。因此，AI Teammates 能够被嵌入到企业实际工作流中，精准分配任务和访问所需信息，大大提升自动化决策的准确性。

```
Box 联合创始人兼 CEO Aaron Levie 指出：
“有了 AI 代理，形成了一个自我强化的飞轮效应，将在近期和远期极大提升其能力：GPU 的性价比、模型效率、模型质量与智能、AI 框架和基础设施的进步。综合来看，这些改进意味着我们今天看到的 AI 代理仅仅是冰山一角。现在无法实现或自动化成本过高的事情，可能只需下一轮性能提升就能变成现实。”^22
```

Conclusion

AI 代理的发展标志着人工智能领域的一个重要里程碑，其快速进步和行业领袖的广泛乐观情绪共同推动着这一变革。Andrew Ng 以及比尔·盖茨等愿景者都强调了 AI 代理的变革潜力，展望这些系统将在个人和专业领域变得不可或缺的未来。

对于软件开发者来说，这无疑带来了重大机遇。持续的技术进步有望重新定义传统工作流和软件范式，为开发者提供创新和打造下一代应用的机会。这一波新的 AI 技术将催生全新的方法和解决方案，对于那些希望突破软件边界的人来说，这是一个令人振奋的时代。


**CHAPTER 2**

**Generative AI**

**Foundations**

生成式 AI 是人工智能的一个分支，能够创造多样化的内容，比如博客、文章、代码、图片、视频和音乐。用户只需向聊天机器人系统输入提示词（prompt），系统便会根据指令生成类似人类的输出。访问生成式 AI 的主要方式之一是通过大型语言模型（LLM）。LLM 是一种经过海量数据训练的复杂系统，涵盖生物学、市场营销、历史、金融、医学、技术、文学、娱乐等各类主题。这种广泛的训练让模型能够完成诸如语言翻译、分类（将数据归入预设类别）和摘要等任务。

理解生成式 AI 对开发 AI 代理至关重要，因为它有助于深入了解这项技术的能力与局限。掌握其工作原理，可以更好地发挥其潜力，同时注意到其限制。本章将探讨生成式 AI 的基础知识，分析其在 AI 代理开发中的应用与意义。

```
注意 聊天机器人技术其实并不新鲜。其起源可以追溯到 1960 年代。麻省理工学院教授 Joseph Weizenbaum 创建了 ELIZA，它本质上是一个虚拟治疗师。用户可以通过电传打字机接口输入问题，聊天机器人则会给出回应。确实，ELIZA 的回答大多只是对问题的模仿，但它依然展现了强大的影响力，一些用户甚至认为它是真正的人类。
```

Pretrained Models

LLM 是预训练的。这意味着它们在海量数据上进行训练，通常涵盖维基百科、Reddit 以及互联网上的众多其他数据源。有观点认为，一些超大规模的 LLM 已经囊括了大部分在线内容，使其能够生成信息丰富、上下文相关性极强的输出。此外，一些预训练模型还引入了专有信息，例如 OpenAI 通过与 News Corp、Springer、Vox 等出版商签订协议获得内容授权。

在预训练阶段，模型会学习嵌入（embedding），即单词或标记的稠密向量表示。这些嵌入本质上是定长的数字数组，能够捕捉词语之间的语义关系，从而让模型基于上下文理解和生成类人文本。

传统的 AI 模型通常是在结构化、带标签的数据上训练，这便于信息处理和分类。而生成式 AI 的一大特点在于支持对非结构化数据的训练。这种灵活性让模型能够处理更为多样的输入，并生成更接近人类语言风格的输出。模型效果的提升还得益于“规模法则”，即 LLM 的性能会随训练数据量和模型规模的增长而提升。

预训练模型领域的一个重要发展是领域专用大语言模型（LLM）的出现。这类模型通过在特定行业或领域的数据（如法律文件、医疗记录或财务报告）上进行微调，从而针对特定任务变得高度专业化。这样的专门训练使模型能够更好地理解和处理该领域独有的语言和概念，提升其准确性和相关性。因此，领域专用 LLM 能够比通用 LLM 提供更精确、更贴合实际需求的输出，后者在面对专业术语和细微差别时往往力不从心。

尽管如此，预训练模型也存在一些不足。其中一个显著的限制是训练数据存在时间截止，导致 LLM 无法获取最新信息。此外，优质数据的可用性和质量也令人担忧，有观点认为企业正在耗尽有价值的数据资源。随着互联网上越来越多的内容由 AI 生成，可能会出现“腐蚀性反馈循环”，从而降低模型的整体质量。

为应对这些挑战，生成合成数据成为一项新兴趋势。合成数据是指通过算法人工生成、能够模拟真实世界数据的数据，而非源自实际事件的采集。这种方法降低了对公共互联网内容和专有数据的依赖，有望减少成本并规避授权问题。合成数据的生成因此有望在未来持续提升和维持 LLM 的性能方面发挥关键作用。

Transformer Models

Transformer（变换器）模型因其独特的架构和创新的注意力机制，成为自然语言处理（NLP）领域的革命性突破。2017 年发表于《Attention Is All You Need》的论文首次提出 transformer，显著超越了以往的循环神经网络（RNNs）等模型，因为它能够高效处理大规模数据集。与依赖序列处理的传统模型不同，transformer 采用并行处理方式，极大提升了处理速度和准确性，也让这类模型非常适合在 GPU 上运行。

transformer 的核心是注意力机制，尤其是自注意力（self-attention）。这种机制可以让模型根据上下文对不同 token 的重要性进行加权，从而理解它们之间的关系和依赖。例如，“bark”这个词既可以表示狗叫，也可以指树皮，transformer 能根据句中其他词语正确识别其含义。

transformer 主要有三种类型，每种适用于不同场景。自回归语言模型（如 OpenAI 的 GPT 系列）仅根据前文预测下一个 token，擅长文本生成任务。自编码语言模型（如 Google 的 BERT）则通过利用上下文的双向信息预测 token，因此非常适合文本分类、情感分析和命名实体识别等任务，能更准确理解句子的整体含义和意图。第三类模型结合了自回归和自编码方法，代表性的如 T5 模型，可针对多种任务进行微调，兼具两者优点，在 NLP 各类应用中表现出色。

除了这些基础类型，transformer 还不断演化，融入了稀疏注意力等机制，以降低计算复杂度，进一步提升性能和效率。

Transfer Learning
迁移学习是一种机器学习技术，即将已在某一任务上训练好的模型，重新用于执行另一项相关但不同的任务。该方法利用初始训练阶段所获得的知识，提升模型在新任务上的表现。

Transformer（变换器）模型尤其适合迁移学习，因为它们在预训练阶段能够学习和编码复杂的语言模式。这类模型通常在大规模、多样化的文本语料库上通过无监督学习进行训练，掌握语法、语义以及词语之间的上下文关系。一旦完成预训练，transformer 模型便可以通过微调（fine-tuning）适应特定的下游任务，例如文本分类、情感分析或问答系统。微调过程是在较小的、任务相关的数据集上进一步调整模型参数，使其能够将通用的语言理解能力转化为对特定任务细微差异的把握，从而实现更优异的表现。

```
注意：参数是指模型在训练过程中学习和调整的变量，用于提升预测的准确性。在 transformer 模型中，这些参数包括权重和偏置，它们帮助模型理解数据中的复杂模式和关系。例如，在大语言模型（LLM）中，参数决定了句子中每个词与其他词之间的关联强度，从而帮助模型捕捉上下文和语义。
```

检索增强生成（RAG）通过将预训练语言模型与外部知识检索系统相结合，进一步拓展了这一方法。RAG 能够在生成过程中检索来自大型语料库的相关信息，并将其整合进输出，从而提升特定任务的表现。这使得 RAG 尤其适用于需要最新知识或详细上下文的任务，进一步增强了 transformer 模型在各种自然语言处理（NLP）应用中的适应性和效率。

基于 transformer 的迁移学习方法具有多项优势。首先，由于模型在预训练阶段已经学习了大量信息，针对特定任务微调时所需的数据和时间大大减少，效率极高。经过微调的预训练 transformer 通常能够在多种 NLP 任务上取得业界领先的效果。此外，利用预训练模型还显著降低了计算资源的需求，使在数据和硬件有限的情况下也能训练出高性能模型成为可能。

Alignment in Language Models

语言模型的对齐性（Alignment）指的是模型生成的回答是否能够满足用户的期望和需求。这要求模型的输出具备连贯性、上下文相关性，并且与用户设定的目标一致。

人类反馈强化学习（RLHF, Reinforcement Learning from Human Feedback）是提升大语言模型（LLM）对齐性的主流方法。RLHF 通过引入人工评审者的反馈，来微调和优化模型表现。与仅依赖传统监督学习（通常受限于标注数据的质量和范围）不同，RLHF 利用少量高质量的人类反馈，对模型生成的输出进行反复迭代和改进。这一过程帮助模型更好地理解和满足用户的期望，从而输出更加准确和令人满意的回答。

RLHF 在现代大语言模型中的应用带来了显著提升。借助人工反馈，模型可以不断优化回答的相关性和上下文适应性，有效改善内容的安全性与伦理性，减少偏见，并提升整体用户满意度。

除了 RLHF，目前还在探索其他提升对齐性的方法。例如，AI 反馈强化学习（Reinforcement Learning with AI Feedback），即“宪法式 AI”（Constitutional AI）所采用的方法。该思路利用 AI 系统自身的反馈来辅助模型训练和微调。通过结合人类和 AI 的反馈，研究者希望进一步提升模型对用户期望的适应能力，使其持续稳定地产生高质量输出。

Multimodal LLMs

多模态大语言模型（Multimodal LLMs）是人工智能领域的前沿创新。它们能够处理和生成多种类型的数据，如文本、图像、音频和视频。通过融合不同的输入与输出形式，这些模型突破了传统仅能处理文本的语言模型的局限，使交互更加细致和多样。这一进步符合人工智能追求人类式理解与交互的目标——毕竟，人类的认知本就依赖多种感官。

近年来，多模态大语言模型在人工智能研究中取得了重要里程碑。例如，OpenAI 的 GPT-4o 和 Sora 强调了将图像等多种模态融入语言模型的重要性，并将其视为 AI 发展的关键前沿。DeepMind 的 Flamingo、微软的 KOSMOS-1 等模型，也在推动多模态 AI 的快速发展。

多模态 LLMs 的主要优势之一，在于它们能够同时处理和理解不同类型的数据。这提升了模型做出决策的能力，并带来更丰富的用户体验。例如，在电商领域，这些模型能够结合产品图片和用户评论文本，提供更精准的商品推荐。

不过，多模态大语言模型的部署也面临诸多挑战，包括训练的复杂性和伦理考量。训练此类模型需要海量且多样的数据集，以及强大的计算资源。同时，不同数据类型的集成也必须谨慎处理，以确保模型输出的连贯性和实用性。

Types of Models

OpenAI 的第一个 GPT 模型于 2018 年发布，拥有 1.17 亿参数，在自然语言处理领域实现了重大突破。该模型称为 GPT-1，采用了 Transformer 架构，并在大规模互联网文本语料库上进行训练。尽管能力有限，GPT-1 已经展现出生成连贯且具备上下文相关性的文本的能力。

在发布 GPT-1 后，OpenAI 快速推进了其语言模型技术。2019 年，GPT-2 推出，参数量提升至 15 亿，性能显著增强。2020 年 GPT-3 更是飞跃，参数量达到 1750 亿。模型规模的指数级增长使 GPT-3 能够以惊人的准确度完成更广泛的任务。

然而，开发这些先进模型需要巨大的计算资源和资金投入。训练如此大规模的模型必须依赖强大的硬件和海量数据。认识到这些模型的潜力和资源需求，微软于 2019 年向 OpenAI 投资 10 亿美元。这一合作使得这些先进语言模型的扩展和部署成为可能，推动了人工智能及其在各行业应用的进步。多年来，微软的总投资已超过 130 亿美元。

至于 GPT-4，OpenAI 并未公开参数数量，但有传言称其超过 1 万亿参数。这种不透明现象在其他 LLM 开发者中也越来越常见，目的是在激烈竞争中保护创新成果。

如今，LLM 领域日益丰富，新模型不断推出或升级。快速的发展节奏让开发者很难时刻跟进最新进展。LLM 大致可以分为多种类型，包括专有系统和开源项目，也有体量更小的平台，被称为小语言模型（SLM）。

下面我们来分别介绍这些类型。

Proprietary LLMs

专有 LLM（大型语言模型）是由私营机构开发、拥有和控制的先进 AI 系统。典型代表包括 OpenAI 的 GPT 系列、Anthropic 的 Claude，以及 Google 的 Gemini。
这些专有 LLM 具备如下优势：

- 资金雄厚与顶级人才：强大的资金投入使这些公司能够吸引经验丰富的数据科学家和 AI 专家，确保模型持续升级与优化，始终处于前沿。
- 领先的能力和性能：专有模型通常代表了 AI 技术的最前沿，能在各类自然语言处理任务中展现卓越表现。
- 健全的开发者生态系统：结构良好的 API 生态简化了集成流程，加快了开发进度。开发者可使用 Python 等主流编程语言，并借助 playground 等工具，便于测试和优化应用。
- 成本效益：通过 API 使用这些模型，无需自建昂贵的硬件基础设施。
- 全面的支持服务：雄厚的财力使这些公司能够为开发者提供详尽的文档、教程视频和高效的客户支持团队，帮助开发者顺利使用模型并及时解决遇到的问题。
- 伦理与安全：如 Anthropic 等公司高度重视 AI 的安全性和价值观对齐，积极应对 AI 滥用、隐私和公平性等社会关切。
- 可扩展性强：这些公司强大的基础设施支持大规模部署和高并发应用，非常适合企业级场景和高用户量服务。

那么，专有 LLM 也有哪些不足呢？请看下方总结：

- 定制化受限：用户对模型本身的修改空间有限，难以深度融合到特定系统或独特工作流中。
- 数据隐私和安全风险：使用专有 LLM 往往需要将敏感数据提交至第三方厂商，带来数据被误用、泄露或被用于其他目的的风险。
- 供应商依赖：过度依赖单一供应商可能导致风险，如服务中断、价格调整或业务变更，都会影响正常运营。例如 2023 年底 OpenAI 董事会突然解雇 CEO Sam Altman，尽管很快复职，但事件让客户对平台的稳定性产生担忧，也促使部分用户寻求替代方案。
- 透明度与控制权不足：用户通常难以获知模型的训练细节、数据来源和决策机制，导致信任和掌控感不足。
- 竞争劣势：高度依赖专有 LLM 的企业，若竞争对手获得了更优模型或自研能力，可能陷入被动。

Open Source LLMs and SLMs

2018 年，Arthur Mensch 在巴黎综合理工学院和 Télécom Paris 完成了机器学习与脑功能成像方向的博士论文。随后，他加入谷歌 DeepMind 担任研究员，专注于大型语言模型（LLM）。在此期间，他参与发表了一篇关于 Chinchilla 模型的论文，该模型挑战了“LLM 必须无限扩大的规模定律”。^1

Mensch 对科技巨头公司模型的不透明深感担忧，这促使他自主创业。2023 年 4 月，他与同为 Meta AI 实验室成员的 Timothée Lacroix 和 Guillaume Lample 在巴黎联合创立了 Mistral，致力于打造更高效、低成本且开源的模型。

Mistral 的策略迅速获得市场认可。成立 9 个月内，公司吸引了全球顶级投资者，融资 5 亿美元，估值 20 亿美元。2023 年 6 月又获得 6.46 亿美元投资，估值升至 60 亿美元，投资方包括英伟达和 Salesforce。当时 Mistral 仅有 60 名员工。^2

Mistral 的高速崛起点燃了开源模型和小型语言模型（SLM）的投资热潮。风险投资机构纷纷加码，新项目不断涌现。与此同时，开发者和研究人员大量涌向 Hugging Face 等平台，目前该平台已托管超过 40 万个模型，每天都有新模型上线，彰显了技术创新的高速迭代。

开源 LLMs 具有改变 AI 领域的许多优势：

- 透明度：开源模型允许研究人员、开发人员和用户检查架构、权重和训练数据，促进账户ability，并有助于识别和减少模型中的偏见。
- 社区协作：持续由多位贡献者参与改进模型、修复错误和添加新功能。这种协作推动了创新，确保模型不断演进以满足不同的需求。
- 民主化：开源提供了自由使用和定制的工具。这种可访问性鼓励实验和跨不同领域的应用程序的开发。
- 增强安全性：通过控制源代码，可以在本地或私有数据中心使用模型，提供更多控制权，减少与云部署相关的风险。

同样，SLMs 也具有自身的优势：

- 高效性：它们被设计为在受限资源环境中提供强大的性能，而无需昂贵的计算资源。例如，苹果在其智能手机上使用了SLMs，通过减少对云的访问延迟，降低了延迟。
- 可定制性：这也是相对于更大型模型的一个优势。除此之外，SLMs 还有更多的灵活性。
- 专注于特定任务：它们可以被专门优化，用于摘要生成、分类等特定任务，而不需要未使用的功能所带来的开销。这种目标化的方法确保企业不需要维护具有不必要功能的模型。事实上，企业是否需要能够写诗呢？当然不需要！
    
虽然开源 LLMs 和 SLMs 带来了诸多好处，但用户也需要注意它们存在的一些缺点。事实上，安全问题依然不容忽视。从第三方网站下载模型可能引入漏洞，比如模型投毒，恶意攻击者可能在模型中植入有害内容。这一风险提醒我们，在使用这些模型时必须采取强有力的安全措施。

使用开源 LLMs 和 SLMs 的成本也是一个重要考虑因素。虽然源代码是免费的，但运行这些模型往往需要复杂且昂贵的硬件设备，比如高性能 GPU 或专用 AI 加速器，否则难以高效训练和部署模型。这对于规模较小的组织来说可能负担较重。此外，这类模型的复杂性也决定了需要具备专业技能的数据分析师和数据科学家来管理和优化，从而进一步提高了运营成本。

透明性虽然是开源模型的一大优势，但现实中并不总是那么理想。尽管模型的架构和权重可以公开，训练所用的数据却常常未披露。这种“半透明”限制了我们对模型行为和潜在偏见的全面理解，而这些正是负责任 AI 应用的关键要素。

Prompt Engineering

在开发 AI 智能体时，理解提示工程（prompt engineering）至关重要。提示工程是高效使用大语言模型（LLM）的核心，它涉及设计输入，引导这些强大的 AI 系统生成准确且相关的回答。掌握这一技能，能够让开发者充分发挥 LLM 的潜力，使与 AI 的交互更加高效和精准。

提示工程属于机器学习和自然语言处理的一个子领域，致力于让计算机理解和解释人类语言。这一过程远不止于提出单一问题，往往需要与 LLM 进行多轮、迭代式的对话，根据模型的反馈不断调整和优化提示，直到获得所需的信息或答案。这样的反复试验有助于打磨模型的输出，实现有价值的洞察或解决方案。

近年来，关于提示工程的炒作不绝于耳，各种视频、博客和文章纷纷声称揭示其“秘密”。然而，我们需要警惕这些说法。实际上，提示工程归结为少数几个核心概念。理解这些基础比执着于所谓的“隐藏技巧”更有价值。

提示工程既是一门艺术，也是一门科学。由于 LLM 复杂的概率机制，同样的提示可能产生不同的结果。这种不确定性意味着试错是常态。开发者常常需要多次调整提示以获得理想输出，这需要耐心和不断试验的精神。

此外，LLM 经常更新，功能和输出也随之变化。有时更新会提升某些方面，另一些方面则可能下降，这进一步增加了提示工程的复杂性。

综上所述，接下来让我们看看成功提示工程的一些关键因素。

Be Clear
在与大语言模型（LLM）交互时，提示的清晰性对于生成准确且相关的回答至关重要。LLM 只有充分理解你的请求细节，才能提供有用的信息。通过明确且详细地表达需求，你可以让模型的输出更贴合你的期望。
为了让提示具备足够的清晰度和上下文，可以采用多种实用的方法。

Details

为了让大语言模型（LLM）生成相关的回答，必须在请求中提供足够的细节和上下文。如果缺乏这些信息，模型只能自行猜测你的真实意图。更有效的方法是，在提示中明确具体需求并包含关键信息。例如，与其简单问“解释重力”，不如这样提问：“用适合高中生理解的简单语言，解释重力如何影响地球绕太阳的轨道。” 这种层次的细节能够引导模型生成更贴合你实际需求的答案。

Persona

系统消息（System Message）在与大语言模型（LLM）交互时非常重要，它能够让模型以特定的角色或身份进行回应，从而提升回答的针对性和专业性。

系统提示示例：“当我请求建议时，请以一位拥有 20 年科技行业经验的资深商业顾问的身份答复。”


Use Delimiters

分隔符在与大语言模型（LLM）协作时非常有用，因为它们可以清晰地标示文本中需要特殊处理的不同部分。这一技巧有助于提升模型处理信息时的聚焦度与准确性。常见的分隔符包括三引号（"""）或章节标题。

例如，在处理需要摘要的文档时，可以使用类似“请总结被三引号包围的文本”这样的提示，然后将待处理的文档内容用三引号括起来。这种做法能有效地指示 LLM 只关注被指定分隔符圈定的内容，从而确保只总结相关文本，忽略无关信息。

Steps for a Task

在使用大型语言模型时，将复杂任务拆解为一系列明确的步骤，有助于提升模型对指令的理解和执行能力。这种方法为模型处理信息和生成响应提供了清晰的操作路径。以下是一个示例：

```
请按照以下步骤创建一个简单的 Python 函数：
步骤 1：用户提供对所需函数的简要描述。根据描述，生成一个函数签名，包括合适的函数名和参数，并以“函数签名: ”为前缀输出。
步骤 2：实现函数体，编写完成任务所需的逻辑。使用清晰的变量名，并为复杂部分添加注释。将完整的函数（包含第 1 步的签名）以“实现: ”为前缀输出。
步骤 3：提供一个调用该函数的简单示例，包括示例输入和期望输出。以“用法示例: ”为前缀输出代码片段。
```

另一种常用方法是递归摘要。当文档过长，超出 LLM 的上下文窗口时，可以先对不同部分分别摘要，再对各部分的摘要进行整合。

Time to Think

当遇到复杂的问题或计算时，逐步思考往往会带来更好的结果。这一原则不仅适用于人类，同样适用于大语言模型（LLM）。如果在提示中要求模型先解释推理过程再给出最终答案，通常会获得更准确的结果。这种方法被称为“思维链（chain of thought）”，让模型像人类一样，有条理地推导问题的解决方案。

在提示中加入逐步推理的要求，可以提升模型解决问题和决策的能力。通过明确地要求“逐步推理”或“分步骤思考”，为模型提供了更系统的思考框架。这不仅提高了回答的质量，也让问题解决的过程更透明、更易于理解。

当然，其他类型的提示同样有助于优化模型输出。例如，询问“如何改进这个回答？”可以促进对结果的批判性审视，发现提升空间。类似地，提示“还有哪些内容可以补充？”有助于发现被忽略的要点或补充考虑。再如，“我有哪些假设？”、“有哪些潜在的反对意见？”等提示，则能引导模型进行更全面、细致的分析。

通过灵活运用多种有针对性的提示，不仅能引导人类思考，也能提升 AI 的回答质量，使其在各类任务与决策中更加周到、平衡与深入。

Length of Output

在使用大语言模型时，你可以要求输出特定长度的内容。你可以用词数、句数、段落数或项目符号等不同单位进行指定。不过，需要注意的是，模型对这些单位的遵循程度有所不同。比如，要求生成特定词数时，模型往往难以精确控制；而让模型生成指定数量的段落或项目符号时，其表现会更加稳定可靠。  
请将三引号包围的文本总结为一段话。


Going Beyond the Transformer

尽管 Transformer 在生成式 AI 方面取得了巨大进展，但业界仍在积极探索更高效的模型。其中两种有前景的替代方案是 Test-Time Training（TTT）和状态空间模型（State Space Models, SSMs）。

Test-Time Training（TTT）正在斯坦福大学、加州大学圣地亚哥分校、加州大学伯克利分校和 Meta 的研究人员推动。TTT 模型能够处理比 Transformer 更多的数据，同时能耗更低。与依赖不断扩展查找表的 Transformer 不同，TTT 模型通过机器学习模型将数据编码为具有代表性的变量（即权重），从而实现不随数据量增长而扩大的模型体积。TTT 可应用于文本、图像、音频、视频等多种数据类型。

另一种替代方案——状态空间模型（SSM）也因其计算效率和可扩展性而备受关注。与 TTT 类似，SSM 能够比 Transformer 更高效地处理大规模数据集。

尽管 TTT 和 SSM 具有巨大潜力，但目前仍处于早期阶段。现阶段，Transformer 依然是生成式 AI 的主流模型。不过，相关研究持续推进，未来这些新模型有望进一步提升效率和能力，甚至有可能超越 Transformer。

Conclusion

随着我们结束本章对生成式 AI 基础的探讨，可以清晰地看到，这项技术代表了人工智能领域的一次巨大飞跃。生成式 AI 能够自动创作多样化内容，从文本、图像到音乐和视频，为各行各业带来了全新可能性。这一技术的核心——大语言模型（LLM）——展现了 AI 的进步，能够基于海量训练数据生成类人输出。这种能力为 AI 智能体的开发奠定了基础，让它们能够完成过去只有人类才能胜任的任务。

回顾生成式 AI 的演变，我们可以看到技术从早期的聊天机器人实验（例如 ELIZA）不断发展，进化到如今能够进行细致入微、具备上下文理解的复杂模型。这一进步强调了 AI 领域持续创新和灵活应变的重要性。展望未来，领域专用模型、合成数据生成、以及 Transformer 替代技术等新方法，有望进一步提升 AI 系统的能力与效率。


© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 47

https://doi.org/10.1007/979-8-8688-1134-0_3

**CHAPTER 3**

**Types of Agents**

人工智能（AI）智能体代表了一个多样且不断演变的技术领域。这些智能体从具备有限能力的简单系统，到能够进行复杂决策和自我学习的高级实体，涵盖了广泛的类型。主要的 AI 智能体包括简单反射型智能体、基于模型的反射型智能体、目标驱动型智能体、效用型智能体，以及学习型智能体。每种类型都有独特的特征和适用场景，能够满足不同的需求和挑战。

然而，随着技术的快速发展，区分这些不同类型的智能体变得越来越困难。智能体类型之间的界限往往变得模糊，难以进行严格分类。例如，一个用于优化供应链物流的智能体，可能同时采用目标驱动的规划和效用驱动的决策方法，以适应库存和需求的实时变化。这种混合型智能体反映出现代 AI 应用的复杂性和高度智能化。

此外，随着 AI 技术的不断进步，新的能力和集成方式不断涌现，促使智能体融合多种 AI 技术。这些混合型智能体能够结合不同方法的优势，例如将学习型智能体的适应性与目标驱动型智能体的战略规划能力相结合。这种融合趋势使得理解每种类型的基础概念变得尤为重要，有助于深入认识它们各自的贡献及其协同潜力。

在本章中，我们将深入探讨 AI 智能体的主要类型，分析它们的独特特征、应用场景以及相互之间的细微差别。

Simple Reflex Agents

简单反射型智能体是人工智能中最基础的一类智能体。它们根据预先设定的规则，对环境中的特定感知输入做出响应。这类智能体不存储过去的经验，也没有任何内部记忆，而是仅仅依赖当前的感知（percept）来做决策。它们的决策过程非常直接，通常基于简单的“如果-那么”条件来确定应采取的行动。

例如，在温度控制系统中，一个简单反射型智能体可能会被编程为：“如果室温超过45摄氏度，则开启空调。”这个规则使智能体能够通过传感器监测温度，并在条件满足时通过执行器（actuator）启动空调。这种简单的机制非常适合不需要复杂决策或从经验中学习的任务，比如基于关键词重置密码，或操控像扫地机器人、恒温器等只需响应温度变化的基础物理设备。

简单反射型智能体的主要优势在于易于设计和实现。它们对计算资源的需求极低，并且只要传感器准确、规则设计合理，通常非常可靠。然而，这类智能体也有明显的局限性：如果输入传感器出现故障，或者预设规则无法覆盖所有可能的情况，就容易出错。此外，在部分可观测或环境变化较大的场景中，简单反射型智能体无法应对未编程的突发情况，因此在动态或不可预测的环境下效果有限，需要更复杂的决策能力。

Model-Based Reflex Agents

基于模型的反射型智能体是一类更为先进的智能体，它们通过引入环境的内部模型来提升决策能力。与仅依赖当前感知输入做出反应的简单反射型智能体不同，基于模型的反射型智能体不仅考虑当前的感知（percept），还结合代表环境中不可直接观测部分的内部状态进行决策。在这里，“感知”指的是智能体通过传感器在特定时刻从环境中获取的数据或信息，反映了环境的当前状态，是智能体做出决策的基础。通过感知，智能体能够理解并与外部世界互动，实时获取影响其行为的输入信息。

基于模型的反射型智能体的决策过程包含多个步骤。首先，它们通过传感器感知环境，收集当前状态信息；随后，利用内部模型更新对环境的理解。这个内部模型不仅包含环境如何自主变化的知识，还包括智能体自身行为将如何影响环境。借助这一模型，智能体能够在采取行动前预测可能的结果，从而做出更为复杂和科学的决策。

这类智能体的核心在于其推理机制，它会结合传感器数据和内部模型进行分析决策。推理方式可以是基于规则的系统、逻辑推理，或更高级的机器学习方法，如大型语言模型（LLM）。决策完成后，智能体通过执行器（actuator）来执行具体动作，这些动作可以是机器人中的物理运动，也可以是软件系统中的虚拟操作。执行器负责将智能体的决策转化为实际影响环境的操作，推动环境状态发生变化，从而完成“感知—行动”循环。

基于模型的反射型智能体的优势在于，它们能够利用内部模型快速、高效地做出决策，更好地理解外部世界。这种机制让它们能持续根据新感知动态更新模型，具有更强的环境适应性。然而，这类智能体通常计算资源消耗较大，维护和更新内部模型需要较高的成本。而且，准确建模复杂真实环境本身也极具挑战。

在实际应用中，基于模型的反射型智能体常被用于制造系统。例如，它们可以通过预测机器故障或材料短缺，优化生产流程。通过维护详细的生产环境内部模型，这些智能体能够主动发现并解决潜在问题，从而提升效率，减少停机时间。

Goal-Based Agents

目标驱动型智能体，也称为基于规则的智能体，是旨在通过考虑未来结果和规划来实现特定目标或任务的 AI 系统。它们与基于模型的智能体有相似之处，但在决策方式上有所不同。基于模型的智能体利用历史和当前数据进行预测，而目标驱动型智能体则以明确的目标为驱动，采用搜索算法来确定实现目标的最优路径。这通常涉及对一系列可能行动进行评估，即“搜索与规划”，以朝向理想结果前进。

目标驱动型智能体的能力不仅仅体现在被动响应上，更体现在主动规划和优化方面。它们具有面向未来的特性，能够利用决策算法评估各种潜在场景，并根据新信息和环境变化动态调整策略。这种适应性在参数变化迅速的环境（如机器人技术、自动驾驶和复杂游戏 AI）中尤为重要。

目标驱动型智能体的突出价值在于其高度自主性、预测能力和高效性。它们能够在极少人工干预的情况下自主调整行为以达成目标，预测未来场景，并寻找实现目标的最优路径。这不仅节省了资源和时间，还能确保系统在面对新挑战和机遇时能够灵活应对。

此外，目标驱动型智能体已广泛应用于各类高级场景。在生成式 AI 领域，它们被用于内容创作、游戏设计、自动化设计和原型开发、个性化营销、智能助手和金融交易等。这类智能体擅长于需要复杂决策和战略规划的任务，因此在精度和适应性需求极高的领域中不可或缺。

Utility-Based Agents

效用型智能体是利用复杂推理算法，通过评估不同情景以实现最优结果的高级 AI 系统。这一评估过程依赖于效用函数，该函数为各种状态分配“期望值”或“效用值”，用于衡量它们的优劣。智能体随后会选择能带来高效用状态的行动，从而有效平衡多个目标，或优化特定标准（如成本、质量或时间）。

效用型智能体的主要优势之一是能够适应动态环境。它们会根据新数据和不断变化的条件不断调整策略。这使得它们在许多领域都非常有效。例如，在金融交易领域，效用型智能体通过评估不同投资策略及其潜在结果，帮助实现收益最大化。在物流领域，它们通过权衡成本、交付时间和资源可用性，优化供应链运营。此外，在客户服务应用中，这类智能体能够根据用户的偏好（如价格、质量和送货速度等因素）推荐最合适的产品或服务。

然而，效用型智能体的实现也面临一定挑战。这类智能体需要准确的环境模型才能做出可靠决策。如果模型不准确或不完整，就可能导致次优决策，甚至产生错误。此外，评估多种情景并计算期望效用的过程对计算资源的需求较高，使得这类智能体的运行成本也较为昂贵。

Learning Agents

学习型智能体是人工智能领域的基石，旨在通过不断从以往经验中学习来提升自身的表现。这类智能体依靠感知输入和反馈机制，能够动态地优化其行为与决策。学习型智能体通常以基础知识为起点，并通过机器学习技术不断适应和提升能力。它们的架构通常包含四个关键组成部分：学习模块、评估模块、执行模块和问题生成器。学习模块负责更新智能体的知识库，评估模块通过评估智能体的表现提供反馈，执行模块负责具体的决策制定，而问题生成器则引入新的挑战以激发持续学习。

尽管如此，学习型智能体也存在一些显著的缺点。开发和维护这类智能体往往成本较高且资源消耗大。此外，它们通常需要大量的数据才能高效运行，这在数据稀缺或获取成本高昂的场景下成为了一项重大限制。

学习型智能体在各行各业中有着广泛的应用，展现出其强大的适应性和影响力。一个典型的应用场景是个性化推荐系统。通过分析用户行为和偏好，学习型智能体为社交网络和电子商务平台提供推荐引擎。在医疗领域，学习型智能体通过协助药物研发、个性化治疗方案制定、医学诊断和患者健康数据监测，为医疗从业者提供支持。通过分析海量的医疗数据，这些智能体能够识别模式和洞察，促进更准确的诊断和更有效的治疗，从而提升患者的健康结果。

Hierarchical Agents

分层智能体是人工智能领域中由多个智能体按照层级结构组织的系统。在这种体系中，高层智能体负责设定总体目标和约束条件，并将这些要求传递给下层智能体。下层智能体则专注于完成高层分配的具体任务，以推动目标的实现。分层结构可以很简单，只包含高层和低层两个级别；也可以很复杂，包含多个中间层级，用以协调不同层之间的任务和资源。

分层智能体的主要优势之一，是能够减少重复劳动并提升资源利用效率。通过层层分工与委派，决策过程得以加快，因为下层智能体可以在高层设定的约束内独立执行任务。这种流程化的结构有助于更高效地利用计算资源，从而加快任务的响应和执行速度。

当然，分层智能体系统也存在一些不足。固定的层级结构可能导致系统适应性不足，尤其是在动态环境下，系统难以及时调整以应对变化。此外，这类体系的设计通常紧密结合特定目标和任务，因而在应用到不同场景时可扩展性较差。

分层系统的训练也较为复杂。为了保证各层级智能体之间的良好协作，需要大量的数据标注，并精细设计各级智能体之间的依赖关系和交互方式。这些都使得系统的开发和训练工作量较大，对计算资源的需求也更高。

一个典型的分层智能体应用场景是在交通运输系统管理中。例如，高层智能体可以负责整体交通流量调控与优先级设定，下层智能体则处理单个车辆的具体路径规划。中间层智能体则可能协调特定区域或路段的交通，确保整个网络的高效运转。这种分层结构有助于优化路线规划和交通管理，减少拥堵，提高物流效率。


Conclusion
本章讨论的多种 AI 智能体类型，充分展示了人工智能在能力广度和深度上的巨大潜力。从对即时刺激做出反应的简单反射型智能体，到能够根据经验自我适应和进化的学习型智能体，每一种类型都在不同的应用场景中发挥着独特作用。理解这些不同类型的智能体，对于有效利用人工智能具有重要意义。

随着 AI 技术的不断进步，不同智能体类型之间的界限将会进一步模糊，出现更多融合多种方法优势的混合型智能体。这一演变过程强调了扎实理解各类智能体基础的必要性，因为只有这样，我们才能真正把握未来混合型智能体带来的创新与协同效应。

© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 57

https://doi.org/10.1007/979-8-8688-1134-0_4

**CHAPTER 4**

**OpenAI GPTs and the**

**Assistants API**

OpenAI 的 CEO 兼联合创始人 Sam Altman 指出，人工智能将在我们的生活中变得比智能手机还要普及。他还表示，AI 智能体将成为下一个“超级杀手级应用”。在他看来，AI 智能体将能够“真正实现你想要的事情”。^1
为此，OpenAI 推出了多种智能体系统，包括 GPTs 以及 Assistants API。
本章将介绍这些工具。在此之前，我们先说明如何注册 OpenAI 账号并获取 API 密钥。

注册 OpenAI API 密钥

要使用 OpenAI Assistants API，您需要先在 OpenAI 上注册账号。请访问以下网址：
https://platform.openai.com/docs/overview
点击右上角的“Sign Up”按钮。您可以输入电子邮件地址和密码进行注册，或者使用已有的 Google、Microsoft 或 Apple 账号注册。
注册后，您将获得 5 美元的免费额度，有效期为三个月。额度用完后，您需要为账号绑定信用卡。

(^1) https://www.technologyreview.com/2024/05/01/1091979/sam-altman-says-
helpful-agents-are-poised-to-become-ais-killer-function/


GPTs

GPT 是对 ChatGPT 的定制化。它可以结合说明、文件和 API 来实现特定功能。
可以把 GPT 类比为 iOS App Store 或 Google Play 上的应用。你可以在以下网址找到它们：
https://chatgpt.com/gpts

**图 4-1.** _这是 OpenAI 的 GPTs 主界面，GPT 是 ChatGPT 的定制版本_



如图 4-1 所示，界面上有一个搜索框，方便你发现各种 GPT。此外，页面还设有不同的分类，如写作、生产力、生活方式和编程等。
只要拥有 ChatGPT 的免费账户，就可以使用 GPT，不过每日消息数量有限。如果需要更多功能，可以选择每月 20 美元的订阅服务。
使用 GPT 十分简单。点击 GPT 图标后，会弹出详细信息窗口。点击“开始聊天”即可与该 GPT 进行对话。你创建和收藏的 GPT 也会显示在 ChatGPT 左上角。
但如果想要创建自己的 GPT，则需要付费账户。付费后可通过以下链接进入 GPT Builder：
https://chatgpt.com/gpts/editor

**图 4-2.** _这是 GPT Builder 的仪表盘，可以在此创建属于自己的 GPT_

如图 4-2 所示，左侧为 GPT 创建区域，右侧可实时预览效果。
下面我们来创建一个 GPT。

你需要先为你要创建的 GPT 编写一个提示词（prompt），可以是一两句话。例如：

- 产品调研：收集产品信息、比较功能并提供测评
- 活动策划：建议主题、创建灵感板、查找供应商和场地
- 时尚顾问：提供穿搭建议、生成穿搭灵感、追踪最新潮流

GPT Builder 会为你的 GPT 自动推荐名称、头像和一些默认提示词。当然，你可以自行添加或随时修改这些内容。

接下来，GPT Builder 会提出一些问题来进一步完善你的 GPT。你可以在界面右侧实时预览效果。完成后，点击界面右上角的“Create”按钮。弹出菜单后，你可以选择分享链接。点击“Save”即可创建 GPT，然后你就可以在 ChatGPT 中使用它了。

此外，你还可以为 GPT 添加其他功能。在界面右侧选择“Configure”选项卡，可以更改头像、提示词建议，或修改“Instructions”（即 GPT 的详细提示词）。

还有“Knowledge”功能，可以上传文档（如 PDF），为你的 GPT 增加专属数据，让其更专业化。

你还可以选择启用网页浏览、图片生成、代码解释器（通过 Python 解决问题）等能力。

最后，还有“Actions”功能，可以将 GPT 与 Slack、Notion、Zapier 等第三方 API 连接，实现更多扩展功能。




但有几点需要注意：

- GPTs 只能通过 ChatGPT 访问。如果你想在自己的网站集成相关能力，需要使用 Assistants API。
- 目前 GPTs 尚不支持创作者变现，但 OpenAI 有相关计划。
- GPTs 的开发者无法访问用户的对话内容。
- ChatGPT 企业版支持创建仅供内部使用的 GPTs。

价格与 Token

无论是在 Playground 还是通过 Assistants API，每次调用 LLM 都会产生费用，这取决于消耗的 token 数量。
随着各大 LLM 供应商之间的竞争，价格正在持续下降，未来或将进一步降低。
token 可以代表一个词、词的一部分，或者一个字符，具体取决于 LLM 的结构。模型正是通过 token 来处理文本的。
要更直观地理解 token 的工作方式，可以使用 OpenAI 提供的 Tokenizer 工具：
https://platform.openai.com/tokenizer



**图 4-3.** _这是 OpenAI 的 Tokenizer_

如图 4-3 所示，页面顶部有一个输入框用于输入文本。我们输入了如下内容：
Acquiring knowledge continuously invigorates the intellect and
maintains curiosity!
在下方，Tokenizer 会用编码方案标示出不同的 token。例如，“acquiring”由两个 token 组成，“knowledge”是一个 token（包含前导空格），“invigorates”由三个 token 组成，感叹号是一个 token，emoji 则由三个 token 构成。

关于价格，最新详情可在此查看：
https://openai.com/api/pricing/

页面会列出各可用模型，并按性能排序。截至目前，性能最强的是 GPT-4o。其 prompt 的费用为每百万 token 5 美元；LLM 响应的费用为每百万 token 15 美元。

GPT-4o 有多种使用方式。例如 Batch API，可批量收集 token 并在一天内处理 LLM 响应，价格有 5 折优惠，适用于高吞吐量场景。

GPT-4o 具备多模态能力，支持识别和生成图像。此类价格更复杂，OpenAI 提供了基于图像宽度、高度和分辨率的计算器。

下一个高性能模型是 GPT-4o-mini。它体积更小，但依然强大，非常适用于原型开发。GPT-4o-mini 的费用显著更低，prompt 为每百万 token 0.15 美元，LLM 响应为每百万 token 0.60 美元。Batch API 也享有 5 折优惠。

还有一类重要模型是用于 embedding 的模型，主要应用于搜索、主题建模、分类和聚类等场景。embedding 模型的价格在每百万 token 0.020 至 0.10 美元之间。

此外，还有用于微调的模型，包括 GPT-40-mini、GPT-3.5-turbo、davinci-002、babbage-002，价格从每百万 token 0.30 美元到 12 美元不等。

最后，Assistants API 的定价取决于所用工具。例如，Code Interpreter 每会话 0.03 美元，File Search 每 GB 每天 0.10 美元。


```
Note there is a rule of thumb: roughly 1,000 tokens are about
750 words.
```
OpenAI API

OpenAI API 是用于构建生成式 AI 应用的系统，与 Assistants API 不同。了解 OpenAI API 的基础很重要，通过它可以自行开发智能体，从而对应用实现更精细的控制。不过，相比于使用智能体框架，直接用 OpenAI API 通常需要编写更多代码。

本书主要聚焦于利用智能体框架，而不是原生开发智能体。为了帮助理解，这里简单演示一下 OpenAI API 的用法。下面是一个推文生成器的示例程序：用户首次输入 API 密钥后，程序会反复提示输入推文主题，并调用 GPT-4o-mini 生成带有表情符号的单句推文，直到用户选择退出。

首先需安装 OpenAI API：

pip install openai

```
Then we have the following:
```

```python
import openai
import os
from getpass import getpass
```

首先，我们导入 OpenAI 库，它为与 OpenAI API 服务交互提供了 Python 接口。

接下来，我们导入 os 和 getpass 模块。这两个模块用于将 OpenAI API 密钥设置为环境变量，以保证密钥的安全性。这样可以防止他人获取密钥，从而避免被恶意使用造成费用损失。

该函数会提示你输入 API 密钥：

```python
def get_api_key():
    return getpass("Enter your OpenAI API key: ")

def generate_tweet(client, topic):
    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a social media expert skilled at creating engaging tweets."},
                {"role": "user", "content": f"Write a one-sentence tweet about {topic}. Include relevant emojis."}
            ]
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"An error occurred: {str(e)}"
```

该函数接收两个参数：client（OpenAI API 客户端实例）和 topic（推文主题）。函数内部通过 try-except 结构进行异常处理。它调用 chat completion 接口，请求使用“gpt-4o-mini”模型，包含两条消息：一条 system 消息用于定义 AI 的身份为社交媒体专家，另一条 user 消息则要求就指定主题生成一句带有表情符号的推文。如果 API 调用成功，则返回生成的推文内容；如遇异常，则捕获错误并返回相应的错误信息。
最后，我们还有如下函数：

```python
def main():
    print("Welcome to the Tweet Generator!")

    # Get the API key once at the start
    api_key = get_api_key()
    client = openai.OpenAI(api_key=api_key)

    while True:
        topic = input("Enter a topic for your tweet (or 'quit' to exit): ")
        if topic.lower() == 'quit':
            break
        tweet = generate_tweet(client, topic)
        print("\nGenerated Tweet:")
        print(tweet)
        print("\n" + "-"*50 + "\n")
```

程序首先打印欢迎信息，然后通过安全输入方式获取用户的 API 密钥，并初始化 OpenAI 客户端。接下来进入循环，反复提示用户输入推文主题。每输入一个主题，就调用 generate_tweet 函数生成推文，随后打印结果，并输出分隔线。循环会一直持续，直到用户输入“quit”，此时跳出循环，程序结束。

Assistants API

2023年11月，OpenAI 发布了 Assistants API。根据官方介绍：

_“Assistant 是一种专用的 AI，可以根据特定指令运作，利用额外知识，并能调用模型与工具来执行任务。全新的 Assistants API 提供了包括代码解释器、检索（Retrieval）以及函数调用等新能力，从而大幅减轻开发者的工作量，让你能够构建高质量的 AI 应用。”_^2

本质上，这其实是对 OpenAI API 的一层封装，使得生成式 AI 应用能够轻松具备智能体（agentic）能力。事实上，GPTs 的底层技术正是基于该 API。

目前，Assistants API 仍处于 beta 阶段，因此本章的部分操作可能会随着时间推移有所变动。我们会在本书的 GitHub 仓库持续更新相关内容。

Assistants 系统包含两个部分：Playground 和 API。二者遵循相同的工作流，如下图 4-4 所示。

**图 4-4.** _这是 OpenAI Assistants API 的工作流程_

首先是 Assistant，即智能体本身。它拥有唯一的 ID，并配置了特定的 OpenAI LLM。此外，你还可以为 Assistant 配置多种工具，目前包括三个：代码解释器（Code Interpreter）、文件检索（File Search）和自定义函数。

(^2) https://openai.com/index/new-models-and-developer-products-announced-at-devday/



接下来是线程（thread）。用户与 Assistant 的所有对话都会记录在该线程中，消息会依次追加保存。最终，这些消息将一并传递给 LLM，实现“记忆”功能。毕竟，LLM 本身是无状态的。比如我们本例的线程中，用户询问要让投资翻倍所需的年化收益率，Assistant 则给出相应的回答。

线程的执行过程由 Run 段（run）负责。它会接收所有消息，并调用工具（如代码解释器、文件检索等），实现整体流程编排。此过程可以多轮往返，直到 Assistant 达成既定目标。

使用 Assistant 运行时会产生费用，具体如下：

- 代码解释器：可运行 Python 代码，支持计算、数据分析和可视化。OpenAI 收费为每次会话 0.03 美元。
- 文件检索：可加载并检索外部文件。按存储量计费，每日每 GB 0.1 美元，OpenAI 提供 1 GB 免费额度。

模型本身的调用也会计费，后续章节会详细说明。

接下来让我们看看 Playground 的使用。

Playground

借助 Playground，你可以在低代码环境下体验和测试 Assistants API。访问地址如下：
https://platform.openai.com/assistants

**图 4-5.** _这是 Assistants API Playground 的介绍界面_

如图 4-5 所示，界面左侧会显示你已创建的所有 Assistant，右侧则展示各 Assistant 的详细信息。右上角可以点击“Create”按钮新建 Assistant。

创建 Assistant 时，首先输入名称，可自定义。接下来填写 instructions，相当于 OpenAI LLM 的“系统消息”，即为 Assistant 设定角色和风格。

然后选择模型，默认是最先进的模型。点击模型图标可下拉选择其他模型类型。

接下来可选择所需工具，包括 File Search（文件检索）、Code Interpreter（代码解释器）和自定义函数。File Search 和 Code Interpreter 均可添加多个文件。

在 Model Configuration（模型配置）部分，可设置 Assistant 输出为 JSON 格式，并调整以下参数：

- Temperature：控制生成内容的随机性或创造力，范围为 0 到 2。数值越低，输出越确定。
- Top P：通过累计概率阈值 P 控制输出多样性。例如设为 0.9 时，模型仅从累计概率达到 90% 的最可能词汇中采样，使输出更具动态性和上下文相关性。

还可选择 API 版本，通常建议使用默认的最新版本。你也可以删除或克隆已有的 Assistant。

配置完成后，点击右上角的 Playground，即可进入如图 4-6 所示的构建界面。



**图 4-6.** _这是 Assistants API Playground 的构建器_

屏幕左侧为配置选项区域。中间部分显示对话线程，展示所有消息。要创建消息，只需在底部输入框输入文本。还可以添加文件和图片。

假设有如下消息：
假定我的投资年均回报率为 5%，每年投入 5,000 美元。要攒到 100,000 美元需要多久？

如图 4-6 所示，Assistant 会调用 Code Interpreter，自动生成用于计算投资金额的 Python 程序。随后给出结果——需要 14 年才能达到 100,000 美元。

屏幕右侧会显示 Assistant 的日志，便于查看执行情况，也方便调试。线程右上方会显示 token 数量，还可以清空线程和查看当前使用的文件列表。



Assistants API

为展示 Assistants API 的工作方式，我们将创建一个用于计算投资回报率的程序。  
首先导入 OpenAI 类，并创建名为 client 的实例：

```python
from openai import OpenAI

client = OpenAI()

assistant = client.beta.assistants.create(
    name="Investing Bot",
    instructions="You are an expert in calculating investments.",
    tools=[{"type": "code_interpreter"}],
    model="gpt-4o-mini",
)
```
调用 `client.beta.assistants.create()` 方法来创建一个新的 Assistant（智能体），此方法目前处于 beta 阶段。主要参数说明如下：

- Name（名称）：可自定义任意字符串。
- Instructions（说明）：即 Assistant 的系统消息，用于设定角色和任务。
- Tools（工具）：可配置多个，此处仅用代码解释器（Code Interpreter）。
- Model（模型）：本例使用 gpt-4o-mini。


We will create a thread and a message:

```python
thread = client.beta.threads.create()

message = client.beta.threads.messages.create(
    thread_id=thread.id,
    role="user",
    content="You have $10,000 to invest. You want to double your money in 20 years. What average return will you need to get?"
)

run = client.beta.threads.runs.create(
    thread_id=thread.id,
    assistant_id=assistant.id,
    instructions="Provide detailed analysis."
)
```

thread_id=thread.id 指定了 Assistant 要处理的对话线程，这样 Assistant 就能获取该线程下之前的全部消息，实现上下文记忆。
assistant_id=assistant.id 则指定了用于本次 run 的 Assistant，即我们前面创建的智能体。
instructions="Provide detailed analysis" 作为额外指令，会传递给 Assistant，让其在本次 run 中给出更详细的分析。

由于 Assistant 需要一定时间处理请求，因此我们需要如下代码来轮询状态，直到完成处理为止：

```python
import time

while run.status != "completed":
    run = client.beta.threads.runs.retrieve(
        thread_id=thread.id,
        run_id=run.id
    )
    print(run.status)
    time.sleep(5)
```

导入 time 是为了引入 Python 的时间模块，用于在每次状态检查之间添加延迟。while 循环会持续执行，直到 run.status 变为 “completed”，也就是智能体处理完请求后才会跳出循环。

以下代码片段用于检索该线程中的所有消息：

```python
messages = client.beta.threads.messages.list(
thread_id=thread.id
)
```

thread_id=thread.id 指定要检索哪个线程的消息。
以下代码片段会按时间顺序处理并打印该线程中的所有消息，最早的消息先输出：

```python
for thread_message in messages.data[::-1]:
    print(thread_message.content[0].text.value)
    print('\n')
```

([::-1]) 表示反向遍历消息列表。对于每一条消息，可以通过 thread_message.content[0].text.value 访问文本内容。
下面这个函数用于从文本响应中提取百分数：

```python
def extract_rate_of_return(response):
    import re
    match = re.search(r'(\d+(\.\d+)?%)', response)
    if match:
        return match.group(1)
    return None
```

该函数使用正则表达式，从给定的文本响应中查找并提取百分比数值。它会匹配一个或多个数字（可带小数点），并以百分号结尾的模式。如果找到该模式，函数会将匹配到的百分数字符串返回，否则返回 None。
我们接下来将打印响应内容：

```python
for thread_message in messages.data[::-1]:
    if thread_message.role == "assistant":
        rate_of_return = extract_rate_of_return(thread_message.content[0].text.value)
        if rate_of_return:
            print(f"The average rate of return will need to be at least {rate_of_return}.")
        else:
            print("Could not extract the rate of return from the response.")
        break
```

该代码会逆序遍历对话消息，查找 Assistant 的回复。一旦找到 Assistant 消息，会尝试用前面定义的函数提取收益率。如果提取成功，则打印结果；否则提示提取失败。循环在处理完第一条 Assistant 消息后立即结束，确保只分析最新的回复。

随着 API 的使用，你可能会创建多个 Assistant。可以用以下代码查看它们的详细信息：

```python
my_assistants = client.beta.assistants.list(
    order="desc",
    limit="20",
)
print(my_assistants.data)
```

这将按降序显示前 20 个 Assistant。



This will show the Assistants in descending order and limit to 20.
Also, if you want to delete an Assistant, you can use the following:

```python
response = client.beta.assistants.delete(my_assistants.data[0].id)
print(response)
```

my_assistants.data[0].id 指的是 Assistants 列表中第一个 Assistant 的 ID。

最新进展

OpenAI 最近发布的文章《用 LLM 学会推理》^3 介绍了 o1 模型，这是一代采用强化学习（reinforcement learning）实现推理能力大幅提升的新型大模型。总体来看，它展示了通用大模型如何实现智能体能力的演进。
o1 模型的关键在于能够“先思考再作答”，类似于人类解释问题的过程。这与传统 LLM 仅依赖训练数据生成答案的做法有本质区别。
具体来说，o1 会进行深度推理，将复杂任务拆解为更简单的子任务，从而给出最优解答。
这种能力在需要复杂问题求解的领域（如竞赛编程、数学推理和科学问题）中表现尤为出色。
文章还强调了 o1 模型的诸多成就。例如，在 Codeforces 竞赛编程平台的排名达到第 89 百分位，并跻身美国数学奥林匹克前 500 名学生之列。

(^3) https://openai.com/index/learning-to-reason-with-llms



qualifier. On expert-level knowledge tasks such as the GPQA benchmark,
o1 outperformed human PhD-level performance in physics, biology, and
chemistry.

(^4) https://openai.com/index/learning-to-reason-with-llms/#:~:text=
their%20daily%20work.-,Appendix%20A,-Dataset
**Table 4-1.** _Performance of OpenAI o1 and Other Models in Various
Competitions_^4
Dataset Metric gpt-4o o1-preview o1
Competition Math aIMe (2024) cons@64 13.4 56.7 83.3
pass@1 9.3 44.6 74.4
Competition Code
CodeForces
elo 808 1,258 1,673
percentile 11.0 62.0 89.0
GpQa diamond cons@64 56.1 78.3 78.0
pass@1 50.6 73.3 77.3
Biology cons@64 63.2 73.7 68.4
pass@1 61.6 65.9 69.2
Chemistry cons@64 43.0 60.2 65.6
pass@1 40.2 59.9 64.7
physics cons@64 68.6 89.5 94.2
pass@1 59.5 89.4 92.8
Math pass@1 60.3 85.5 94.8
MMLU pass@1 88.0 90.8 92.3
MMMU (val) pass@1 69.1 n/a 78.1
MathVista (testmini) pass@1 63.8 n/a 73.2



那么，o1 的主要技术创新是什么？核心在于强化学习（Reinforcement Learning）的应用。这是一种机器学习方法，智能体（agent）通过与环境交互、接收奖励或惩罚反馈来学习决策。智能体的目标是在不断试错和总结经验的基础上，优化自己的行为，从而最大化长期累计奖励。对于 o1 模型而言，训练过程就是通过不断试错来提升表现。引入“链式思维”（chain-of-thought）推理，使得模型可以通过见到更多数据，或投入更多算力，获得更深思熟虑、更准确的答案。

OpenAI 还强调了 o1 模型在安全性和对齐性方面的提升。通过将人类价值观融入“思维链”之中，模型能够更有效地拒绝不良请求或操纵性行为。这在面对“越狱”与极端场景模拟时表现尤为突出。

总体来看，OpenAI 声称 o1 模型相比前代 LLM 拥有无与伦比的优势。随着模型持续微调，批判性思维与对人类价值观的对齐将带来更多实际应用场景，进一步增强其实用性。这也体现了 OpenAI 在智能体（agentic）方法上的持续投入。

事实上，Box 的 CEO 兼创始人 Aaron Levie 就曾在推特上这样评价 o1：
在 Box，我们已经看到 OpenAI 最新的 o1 模型在复杂企业数据推理方面取得了极具说服力的成果。例如，它能够遵循合同中的多步逻辑规则来给出答案，这是以往从未见过的。这非常具有突破性。^5
(^5) https://x.com/levie/status/1835537106195918918?s=43&t=cS1w1V
Zsy- iY3t91NeeUSw



Conclusion

通过注册 OpenAI 账号并获取 API 密钥，用户可以开始探索强大的 AI 工具。GPTs 支持个性化定制，让用户能够根据特定需求创建专属的 AI 助手，无论是提升生产力、改善生活方式，还是应用于商业场景。而 Assistants API 则为应用集成 AI 能力提供了更全面的解决方案，内置如代码解释器、文件检索等工具，能够处理复杂操作和数据管理任务。
OpenAI 平台强大的功能与灵活性，以及其易用的界面，使开发者和企业比以往任何时候都更容易释放 AI 的潜力。



© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 81

https://doi.org/10.1007/979-8-8688-1134-0_5

**CHAPTER 5**

**Developing Agents**

在本书的下一部分，我们将深入探索构建 AI 智能体的热门框架，包括 CrewAI、LangGraph、AutoGen 和 Haystack。这些框架为开发者提供了强大工具，使其能够创建能够自主执行各种任务的复杂智能体。然而，在详细介绍这些框架之前，首先建立坚实的基础知识至关重要——了解开发资源和方法，将为我们的学习之旅指明方向。这些背景知识将确保你能够充分准备，顺利掌握后续更高级的概念与技术。

我们将从梳理用于 AI 智能体开发的各类工具、库和平台开始。无论是 API 还是云服务，这些资源在简化开发流程方面都起着关键作用，让你能够专注于智能体的逻辑和行为设计，而不用陷入繁琐的技术细节中。此外，我们还会探讨诸如模型微调、集成外部知识源等开发方法，这些对于打造健壮且高效的 AI 智能体同样必不可少。

为了辅助你的学习，本书还配套了一个 GitHub 代码仓库，地址为 https://github.com/ttaulli/agents-book。 仓库中包含了代码示例、项目样例以及更多拓展资源，帮助你把书中讲解的知识应用到实际开发中。随着章节的推进，你可以边学习边动手实践，构建属于自己的 AI 智能体项目。


Jupyter Notebook、VS Code 和 Google Colab

开发环境的选择对实验、原型设计和部署 AI 模型及代理的效率有重大影响。Jupyter Notebook、VS Code 和 Google Colab 是可用的流行且多功能的工具。以下是它们的概览。

Jupyter Notebook

Jupyter Notebook 是一个多功能的基于 Web 的应用程序，可以创建包含实时代码、可视化、方程式和描述性文本的文档，所有内容均在一个界面中。数据科学家和 AI 从业者尤其青睐这种交互式环境，因为它能够无缝地将代码执行与丰富的媒体支持相结合。其在探索性数据分析和迭代模型构建中的效用尤为突出，使其成为开发和记录 AI 项目的首选工具。此外，轻松共享笔记本增强了协作性和透明度。Jupyter Notebook 允许用户以交互方式执行代码，结果显示在行内；支持图像、视频和数学表达式等多种多媒体内容；能够轻松集成流行的数据科学库；并提供导出为 HTML 和 PDF 格式的选项，便于共享。

Visual Studio Code (VS Code)

Visual Studio Code (VS Code) 是由微软开发的一款强大且免费的代码编辑器，以其在生成式 AI 应用开发中的灵活性和功能性而广受认可。其强大的优势在于支持多种编程语言，并通过各种扩展实现广泛的自定义。VS Code 提供了一个完整的集成开发环境（IDE）的功能，包括调试、Git 集成和集成终端。丰富的扩展生态系统让开发者可以根据自己的具体需求定制编辑器，包括与 Jupyter Notebook 的无缝集成以及对云环境中远程开发的支持。这使得 VS Code 成为 AI 开发的强大工具，具备广泛的语言支持、庞大的扩展市场、内置终端和调试工具，并能够直接在编辑器中处理基于云或容器化的项目。

Google Colab

Google Colab 是一个云托管的 Jupyter Notebook 环境，以其便捷性和计算资源而闻名。通过提供对强大 GPU 和 TPU 的免费访问，Google Colab 尤其适合于深度学习模型的训练和测试，且无需任何本地设置。Colab 完全在浏览器中运行，与 Google Drive 无缝集成，便于文件存储和共享。其内置的协作功能允许多个用户同时在同一个笔记本上工作，使其成为协作 AI 项目的绝佳选择。Google Colab 还提供免费的浏览器访问高性能硬件，不需要安装，直接与 Google Drive 集成，支持实时协作编辑，并预装了诸如 TensorFlow 和 PyTorch 等流行的 AI 库，大大减少了开发人员的设置时间。

How to Use Jupyter Notebooks

鉴于 Jupyter Notebook 在这些工具中的核心地位，理解它们的功能至关重要。因此，让我们进行一个演示。启动 Jupyter Notebook 后，您将在 Web 浏览器中被引导至 notebook 仪表板。在右上角，点击“新建”按钮。从下拉菜单中，选择“Python 3”（或根据您使用的编程语言选择其他内核）。
一个新的 notebook 将在新标签页中打开。最初 notebook 是未命名的，如图 5-1 所示。

**图 5-1.** _这是新建 Jupyter Notebook 的初始屏幕_

要重命名您的 notebook，请点击 notebook 顶部的“未命名”文本。
在出现的对话框中输入 notebook 的新名称。
点击“重命名”以保存新名称。
Jupyter Notebook 由单元格组织而成，这些单元格可以包含代码或文本。让我们从代码单元格开始：

- 默认的单元格类型是代码单元格，您可以在其中编写
  Python 代码或其他支持语言的代码。
- 要执行单元格中的代码，您可以按
  Shift+Enter 或点击工具栏中的运行按钮。
假设您在三个单元格中输入以下代码：

# Calculate the sum of the first 10 natural numbers
sum_of_numbers = sum(range(1, 11))
sum_of_numbers

运行最后一个单元格后，输出将是 55。您可以在图 5-2 中看到这一点。

**图 5-2.** _这显示了在 Jupyter Notebook 的单元格中输入的代码_

您还可以使用 Markdown。这样可以在代码旁边添加解释性文本、
文档或其他描述性内容。要创建 Markdown 单元格，请单击工具栏中的下拉菜单
（通常显示为“代码”）并选择“Markdown”。然后，您可以输入文本以及标题、列表、链接等格式。写完内容后，运行单元格以渲染格式化文本。
这是 Markdown 示例：

# 结果总结
上面的代码计算了前 10 个自然数的和。

### 关键点：

- 使用 Python 的内置 `sum` 函数计算总和。
- `range(1, 11)` 生成从 1 到 10 的数字。
- 最终结果，如代码输出中所示，为 55。

```
运行此 Markdown 后，您将在图 5-3 中获得输出。
```

**图 5-3.** _这显示了 Jupyter Notebook 中的 Markdown_

当然，定期保存工作很重要。您可以通过单击工具栏中的软盘图标或按 Ctrl+S（或在 Mac 上按 Cmd+S）来保存您的笔记本。笔记本以 .ipynb 格式保存，您可以稍后从 Jupyter 仪表板中打开。
您可以将笔记本导出为不同格式以便于共享或演示。转到笔记本中的文件菜单，选择“下载为”并选择所需的格式（例如，HTML、PDF、Markdown）。

Google Colab

要使用 Google Colab，您需要一个 Google 帐户。该平台位于 colab.research.google.com。
免费的“Colab Free”提供对标准计算资源的访问，允许用户在云中运行 Jupyter Notebooks，无需任何费用。然而，这一层有某些限制，例如对计算资源的优先级较低、GPU/TPU 可用时间较短以及在不活动后会话超时。

对于需要更强大计算能力的用户，Google Colab 提供“Colab Pro”和“Colab Pro+”订阅计划。Colab Pro 计划每月收费 9.99 美元，通过提供更快的 GPU 和 TPU、更长的会话持续时间和更多内存来增强用户体验。此计划对需要可靠和更快处理速度以进行诸如机器学习模型训练等任务的用户非常理想。Colab Pro+ 计划每月收费 49.99 美元，提供更多资源，包括对高端 GPU（如 NVIDIA V100 和 A100）的最高优先访问、扩展会话以及执行更多密集计算任务的能力，干扰更少。这些付费层旨在满足依赖一致和高性能资源的专业人士和高需求用户的需求。
但就本书而言，我们将使用免费版本。图 5-4 显示了启动 Colab 时您将看到的屏幕。

**图 5-4.** _这显示了启动 Colab 时的初始屏幕_

您将看到最近使用的文件，并有一个搜索框来定位它们。
以下是其他选项卡：

- 示例：这里有帮助开始使用 Colab 的资源
    并帮助了解各种功能。
- Google Drive：您可以从 Google Drive 导入笔记本。
- GitHub：您可以从 GitHub 导入笔记本。
- 上传：您可以从计算机加载文件。
要开始，请选择新建笔记本按钮。图 5-5 显示了您得到的内容，即 Jupyter Notebook 以及特定于 Colab 的功能。

**图 5-5.** _这是 Colab 中的笔记本_

在顶部，您可以点击 Untitled0.ipynb 并输入您想要的文件名称。
然后，您可以在单元格中输入代码或文本。文本单元格支持处理 Markdown。Colab 使用 marked.js，与 Jupyter Notebooks 或 GitHub 使用的 Markdown 相似但不完全相同。


Streamlit, Gradio, and Jupyter Widgets
在创建 AI 代理时，工具如 Streamlit、Gradio 和 Jupyter Widgets 在使开发过程更加互动、便捷和用户友好方面扮演着重要角色。这些工具旨在帮助开发人员构建直观的界面，使他们能够快速原型设计、测试和展示 AI 模型，从而更轻松地与他人分享他们的工作，无论是出于研究、协作还是部署目的。

- Streamlit：这是一个强大的工具，可以用最少的努力创建自定义 Web 应用。它允许开发人员只需几行代码就能将 Python 脚本转变为交互式应用。这在生成式 AI 中尤为有用，因为可视化模型的结果（如文本生成或图像创建）对于理解和完善模型的输出至关重要。Streamlit 的简单性和灵活性使开发人员能够专注于他们的 AI 模型，而不是 Web 开发的复杂性，使得在想法上进行迭代和与他人分享结果（包括非技术人员）变得更容易。

- Gradio：这是另一个简化构建机器学习模型用户界面的工具。它允许开发人员只需几行代码就能为他们的生成式 AI 模型创建基于 Web 的演示。Gradio 的特别之处在于它能够与模型进行实时交互，允许用户输入数据、调整参数并立即查看输出。这种互动性对于测试和完善生成模型至关重要，因为它提供了即时反馈并帮助识别需要改进的区域。此外，Gradio 使得与他人分享这些演示变得简单，促进了更广泛的受众之间的协作和反馈。

- Jupyter Widgets：它通过允许开发人员在他们的笔记本中添加交互元素（如滑块、按钮和文本框）来扩展 Jupyter Notebooks 的功能。这种交互性在生成式 AI 开发过程中是非常宝贵的，因为它使开发人员能够调整参数并实时观察模型行为的变化。例如，在处理文本生成模型时，Jupyter Widgets 可以允许用户动态调整温度设置或修改输入提示，从而更深入地了解不同输入如何影响模型的输出。这种动手的方法不仅增强了实验性，还有助于教育过程，使得向他人解释复杂概念变得更容易。

Hugging Face

Hugging Face（https://huggingface.co）是一个在人工智能（AI）领域中具有重要影响力的平台和开源社区，尤其是在自然语言处理（NLP）和生成式AI方面。自2016年成立以来，Hugging Face 已成为开发者和研究人员的首选资源，提供了一系列旨在简化AI应用创建和部署的工具、模型、数据集和库。其中最重要的产品之一是 Transformers 库，该库包括用于各种任务的预训练模型，如文本生成、翻译和摘要。这些模型，包括知名的GPT、BERT和T5，可以轻松集成到项目中，使开发人员无需进行大量训练和计算开销。

Hugging Face还拥有一个全面的模型中心，用户可以在这里访问和分享数千个预训练模型，促进了AI解决方案的快速试验和部署。这种协作环境鼓励开发人员根据其特定需求微调现有模型或向社区贡献增强功能，加快生成式AI应用的整体开发进程。

**图5-6.** _Meta-Llama-3.1-8B-Instruct 模型的推理API_

此外，Hugging Face 提供了如图5-6所示的推理API等工具，这些工具简化了在生产中部署模型的过程，而无需庞大的基础设施，以及数据集库，提供了对各种训练和评估模型所需数据集的便捷访问。通过提供这些资源，Hugging Face 使开发人员能够更多地专注于创新解决方案和特定应用问题，而不是从头开始。对于任何从事生成式AI应用开发的人来说，Hugging Face 是一个加速开发、促进协作并提供便捷访问前沿模型和工具的重要资源。

Languages

AI 智能体开发有多种语言可供选择。R 语言因其在统计分析和数据可视化方面的优势，在 AI 项目的探索性数据分析阶段非常有用。Java 和 C++ 因其在性能和可扩展性方面的优势而闻名，这对于在生产环境中部署需要速度和效率的 AI 系统至关重要。Julia 凭借其高性能能力和易用性，在 AI 的数值和科学计算任务中逐渐获得关注。尽管有这些语言可用，Python 通常仍然是开发生成式 AI 应用的首选。之所以如此，主要原因之一是 Python 对机器学习和深度学习库的广泛支持，如 TensorFlow、PyTorch、Keras 和 Hugging Face 的 Transformers。这些库提供了预构建模块，简化了复杂的 AI 任务，使开发人员能够快速构建原型、进行实验和优化模型。Python 的语法也很友好和简洁，使其对初学者和有经验的开发人员都很容易上手，从而加速了学习曲线并缩短了开发时间。

此外，Python 的强大社区支持和庞大的第三方包生态系统使其对不同的 AI 相关任务具有高度的适应性。无论是数据预处理、模型训练还是部署，Python 都提供了涵盖整个 AI 开发流程的工具和库。此外，Python 能很好地与其他语言和系统集成，实现与 API、数据库和 Web 框架的无缝交互，这对于在实际应用中部署生成式 AI 模型至关重要。

Python 的多功能性和广泛的采用也意味着有大量的资源可用，包括教程、文档和论坛，使开发人员更容易排除问题并找到解决方案。社区驱动的支持尤其重要，特别是在可能需要协作和知识共享的前沿 AI 项目中。

至于本书，我们将使用 Python。

使用大型语言模型 (LLM)

作为开发者，您有多种选择来利用大型语言模型 (LLM)。这些选项包括以下内容。

使用来自 LLM 提供商的 API

许多公司，如 OpenAI、Anthropic 和 Cohere，提供 API，使您能够访问他们的 LLM。您可以将这些 API 直接集成到您的应用程序中，以生成文本、回答问题等。或者，您可以使用像 LangChain 这样的框架。
使用 API 的优点很多。首先，它提供了易用性，使您无需了解模型架构或部署的复杂性即可访问强大的 LLM。此外，它具有高度的可扩展性，因为提供商负责流量管理，确保您的应用程序能够支持大量请求而不会出现停机。此外，这些 API 通常具有内置的安全功能，包括数据加密和符合行业标准的合规性，这可以在保护您的应用程序方面节省大量时间和精力。

然而，也有一些缺点需要考虑。主要的缺点之一是对模型及其环境缺乏控制。您受限于 API 提供的配置和功能，这可能无法满足特定的定制需求。此外，依赖第三方服务意味着您受到他们定价模式的制约，随着使用量的增加，可能会变得昂贵。还有数据隐私的担忧，因为您的数据被发送到外部服务器，这可能不适合处理敏感或专有信息。最后，延迟可能是一个问题，因为每个请求都必须传输到提供商的服务器并返回，这可能会在对延迟敏感的应用程序中导致响应时间变慢。

Using a Service like Ollama

有多种工具可以轻松地在本地运行大型语言模型（LLM），包括在像笔记本这样的个人设备上。Ollama 就是这样一个库，兼容 Windows、Mac 和 Linux 系统。使用 Ollama，你可以加载大型模型，例如具有 130 亿参数的模型，前提是你的机器至少有 16GB 的 RAM。该库支持多种开源模型，包括 Mistral、Llama 2 和 Gemma。此外，Ollama 提供了一个用于运行推理的 REST API，使你能够创建由 LLM 驱动的应用程序。它还具有各种终端和用户界面集成，简化了用户界面应用程序的开发。然而，使用 Ollama 在本地运行 LLM 也有几个缺点。这些模型的资源密集型特性可能会显著影响你的机器性能，可能会减慢你同时尝试运行的其他任务或应用程序的速度。这在较不强大的硬件上或尝试多任务处理时尤为明显。另一个需要考虑的是维护模型更新的手动工作量。与通常会自动使用最新版本的云解决方案不同，Ollama 用户需要主动管理和更新他们的模型，以确保他们使用的是最新且改进的版本。如果不定期维护，这可能会耗费时间，并可能导致使用过时的模型。


Using a Cloud Service like Azure, Google

Cloud, or AWS

主要的云服务提供商在其平台上提供包含大型语言模型（LLM）的AI服务。例如，Azure 提供 OpenAI 服务，Google Cloud 提供 Vertex AI，AWS 提供 Amazon Bedrock 和其他 AI 服务。使用云服务部署 LLM 的优点非常显著，尤其在可扩展性和集成方面。 这些平台可以处理企业级的工作负载，因此能够轻松扩展以满足高流量应用的需求。此外，它们提供了广泛的互补服务，如数据存储、安全、分析和 DevOps 工具，这些服务可以无缝集成到您的 LLM 工作流中。这使得构建复杂的端到端解决方案变得更加容易，而不仅仅是使用 LLM。云服务提供商还提供强大的安全性和合规性功能，帮助您管理数据隐私并遵循行业标准，这在受监管的行业中特别重要。

然而，也存在一些缺点。主要缺点之一是成本。虽然云服务提供按需付费的定价模式，但费用可能快速上升，特别是在高使用量或需要额外云服务的情况下。有效管理这些成本需要仔细的规划和监控。此外，尽管这些平台提供了高度的控制和定制，但它们也伴随着陡峭的学习曲线。开发人员需要熟悉云提供商的生态系统，这可能是复杂的，并需要大量时间来掌握。另一个潜在的缺点是供应商锁定的风险，您的应用程序可能会与特定的云提供商紧密集成，这使得在需要时迁移到另一个平台变得具有挑战性。最后，尽管这些平台提供强大的安全性，但在第三方服务器上存储和处理数据总是存在一定程度的风险，这可能是处理高度敏感信息的组织所关心的。


Setting Up and Using Ollama

Ollama 可用于 Windows、Linux 和 Mac 系统。您可以通过以下 URL 下载：ollama.com/download。安装过程很简单。
安装完成后，打开终端并输入 ollama。如果您获得了关于如何使用该服务的相关资源，那么说明您已成功安装该程序。
此 URL 显示了 Ollama 上可用的本地模型：ollama.com/library。其中一些可以下载到标准 PC，但另一些可能需要具有大量 RAM 和 GPU 的系统。
要使用模型，请使用此命令：

ollama pull [模型名称]

然后要运行它，您可以使用：

ollama run [模型名称]

您可以与模型进行交互：

```python
from langchain_community.llms import Ollama
llm = Ollama(model="[模型名称]")
response = llm.invoke("2 + 2 等于多少？")
print(response)
```

然而，如果您使用的是标准 CPU 机器，速度可能会很慢。实际上，LLM 生成响应可能需要几分钟。因此，您可能会考虑在 Google Colab 中使用 Ollama，因为这样可以访问更强大的 GPU 和 TPU。有多种方法可以实现这一点，例如使用 ngrok 等服务。这使您能够将 Colab 上运行的本地 Ollama 服务器暴露到 Internet，从而使您的本地机器能够通过公共 URL 与其交互，利用云资源，同时与 LLM 进行本地运行的交互。


Using Ollama with Google Colab

在 Google Colab 中使用 Ollama 是一种有效的方法。您可以利用他们的 GPU 和 TPU 来运行本地模型。对于概念验证，这可能是免费的。
以下是使用这种方法的步骤。首先，InfuseAI/colab-xterm 是一个在 Google Colab 中运行终端的实用工具。我们通过以下方式设置它：

pip install colab-xterm
%load_ext colabxterm
%xterm

我们通过在 colab-xterm 实例化的 shell 中输入以下代码来运行本地 Ollama 系统：

curl -fsSL https://ollama.com/install.sh | sh
ollama serve & ollama pull llama3 & ollama pull nomic-embed-text

curl 实用程序下载 Ollama。是的，就是这么简单。然后，您可以为您的 AI 代理使用本地模型。
为什么要使用本地模型？与使用像 OpenAI 这样的 API 相比，有几个好处。一个是改进的隐私性，因为所有数据都保留在您的机器上。由于简单的设置，您可能也会更具成本效益，因为不需要支付任何使用费用。本地模型也可以更快，因为没有对互联网连接的依赖，这在离线或实时应用中是一个巨大的优势。
至于本章的其余部分，我们将研究定制 LLM 的技术。


Customizing LLMs

大型语言模型（LLM）的真正潜力常常体现在其能够根据特定用例和领域进行定制的能力上。定制化使得LLM能够超越通用应用，更准确、高效地解决专业化任务。
为了促进这种定制化过程，已经出现了两种关键技术：微调和检索增强生成（RAG）。
这些方法为增强LLM提供了不同的途径，使组织能够根据其特定的需求和资源选择最佳方案。

Fine-Tuning

微调过程始于一个通用的 LLM，该模型已在大量多样化的文本语料库上进行过训练，然后使用较小的、特定任务的数据集对其进行优化。这通常涉及几个步骤：首先，收集和预处理与任务或领域相关的数据。然后，将 LLM 在此数据集上进行训练，调整其参数以更好地理解和生成符合应用程序特定上下文的文本。最后，对微调后的模型进行评估和优化，以确保其达到所需的性能标准。
微调 LLM 的优点是显著的。它允许您利用通用 LLM 中编码的广泛知识，同时将其定制为在特定任务中表现出色。例如，回答客户服务询问、生成法律文件或撰写技术内容等。这一过程可以产生更准确和相关的输出，使模型在专业应用中更为有效。微调还减少了从头开始的广泛训练需求，从而节省时间和计算资源。

然而，也有一些缺点需要考虑。微调需要访问高质量的、特定领域的数据集。这些数据集可能并不总是容易获得或创建。此外，微调过程可能需要大量计算资源，特别是在处理非常大的模型时。微调还存在过拟合的风险，即模型变得过于专业化，从而失去对新数据的泛化能力。最后，微调可能会使模型的部署和维护变得复杂，因为它需要不断地调整和更新以保持与不断变化的数据和用例的对齐。

微调方法主要分为两类：预训练微调和高级微调。

预训练微调利用已经在大量多样化数据集上训练过的大型语言模型（LLMs）。这种方法可以使用诸如 Hugging Face Transformers 之类的工具高效地进行，这些工具为微调各种预训练模型和数据集提供了全面的资源。另一个常用的工具是 PyTorch，这是一种流行的机器学习库，有助于训练和微调模型。此外，许多 LLM 提供商，如 OpenAI，提供 API 服务，允许用户在无需深厚技术知识的情况下微调模型。

另一方面，高级微调技术需要更多专业知识。其中一种方法是低秩适应（LoRA），通过简化模型的更新过程来减少计算需求和节省内存。QLoRA 是 LoRA 的一种变体，通过使用低精度提高了较大模型微调的效率和速度。另一种高级方法是来自人类反馈的强化学习（RLHF），通过根据人类反馈训练模型以确保其输出符合人类偏好。这是互动系统（如 ChatGPT）中使用的技术，模型请求用户反馈以优化其响应。RLHF 的一个更简单但有效的替代方法是直接偏好优化（DPO），该方法微调模型以匹配人类偏好，同时在情感控制、摘要和对话生成等任务中保持或提高性能。与 RLHF 不同，DPO 更易于实施和训练，同时实现具有竞争力或更优的结果。

Retrieval-Augmented Generation (RAG)

RAG 是一种先进技术，通过在生成过程中结合外部知识源来增强 LLM 的功能。RAG 不仅依赖于预训练模型中嵌入的信息，还涉及在收到查询时从外部数据库（通常是向量数据库）或知识库中检索相关数据。该过程通常包括两个主要组件：检索模型和生成模型。当收到查询时，检索模型会在大型数据集中搜索最相关的文档或信息。这些检索到的文档随后被输入到生成模型中，该模型利用这些外部知识生成更具信息性和上下文准确的响应。
RAG 的优点是显而易见的，特别是在需要最新或专业知识的场景中。通过为 LLM 补充实时或领域特定数据，RAG 可以生成更准确和相关的输出，使其在客户支持、研究和技术写作等应用中尤为有用。这种方法还可以减少“幻觉”问题，即 LLM 生成看似可信但不正确的信息，因为生成过程是基于实际数据源的。此外，RAG 使模型在不需要频繁重新训练的情况下依然有用，因为外部知识库可以独立于 LLM 更新。
然而，使用 RAG 也有一些缺点。由于需要集成和维护检索机制和生成模型，系统的复杂性增加。这可能会导致基础设施方面的额外挑战，尤其是在处理大规模部署时。RAG 还引入了潜在的延迟，因为从外部源中检索相关文档需要时间，这可能会影响实时应用中的响应速度。此外，RAG 的有效性高度依赖于外部数据的质量和相关性；如果检索过程获取了不相关或过时的信息，可能会对生成输出的质量产生负面影响。最后，实施 RAG 需要仔细调整和优化，以平衡检索和生成组件，这可能需要大量资源并需要专业知识。

Conclusion

在结束本章关于开发 AI 代理的内容时，很明显，AI 开发的领域充满了各种可能性，提供了多种工具、框架和方法来构建复杂的代理。从了解基础资源（如 API、云服务和本地部署选项）到探索高级定制技术（如微调和检索增强生成 RAG）的旅程，为创建强大、专业化的 AI 应用程序奠定了基础。

© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 103

https://doi.org/10.1007/979-8-8688-1134-0_6

**CHAPTER 6**

**CrewAI**

居住在巴西圣保罗的 João Moura 拥有 20 年的软件工程经验。他曾在 Clearbit、Urdog 和 Toptal 等初创公司工作。在此期间，他使用 Ruby、JavaScript、TypeScript、Elixir 和 Python 等语言开发了许多系统。他还在机器学习和 AI 领域有着深厚的背景。
2023 年，他发布了一个名为 CrewAI 的 Python 库，并将其发布在 GitHub 上。您可以在此处找到它：
https://github.com/crewAIInc/crewAI
激发他兴趣的是“由 AI 支持的全自动部门”这一概念。^1 CrewAI 将专注于构建依赖角色扮演的系统。
该框架很快就受到了欢迎。据 João 介绍：

```
我在过去几周亲自测试了 CrewAI，得到的结果令人印象深刻。这就像看到了拼图的拼合，每个代理都在为更大的图景做出贡献。^2
```
```
目前，该框架已经获得了超过 18,000 颗星标和 115 位贡献者。
在本章中，我们将介绍其背景。
```

The Basics

对于 AI 代理框架，CrewAI 是其中较为容易使用的一个。它设计周到且直观，但仍然非常强大。另一个关键优势是，CrewAI 建立在 LangChain 框架之上。这意味着它可以从其众多集成和功能中获益。此外，还有与 LangSmith 的连接，这允许对生成式 AI 应用进行测试和监控。至于 CrewAI，它有各种核心概念，如代理、任务、工具、流程、团队和记忆。我们将逐一进行介绍。

Agents

在 CrewAI 中，代理是一个自主实体，旨在执行任务、做出决策并与其他代理在协作团队环境中互动。每个代理都作为一个专业化的团队成员，具备与团队整体目标一致的特定技能。例如，代理可以是数据分析师、内容创作者或技术支持专家，每个角色都精心设计以有效地支持团队的目标。以下是一个代理的示例代码：

```python
agent = Agent(
    role='Content Creator',
    goal='Develop engaging marketing content',
    backstory="""You're a content creator at a digital
    marketing agency.
    Your main responsibility is to create compelling content that
    resonates with the target audience and drives engagement.
    You're currently working on a campaign to promote a new
    product launch across social media platforms.""",
    tools=[content_tool1, content_tool2],
    llm=my_llm,
    function_calling_llm=my_llm,
    max_iter=15,
    verbose=True,
    allow_delegation=True,
    callbacks=[callback1, callback2],
)
```

行为和能力由几个关键属性定义：

```
role: 定义了代理在团队中的具体职能。在这个例子中，代理是“内容创作者”，负责制作符合品牌信息和目标的营销内容。
goal: 指导代理行动的主要目标。在这里，目标是“开发引人入胜的营销内容”，这驱动代理专注于创建能够吸引观众注意并鼓励互动的内容。
backstory: 为代理的角色和目标提供叙述性背景。背景故事将代理定位为数字营销机构的内容创作者，目前的任务是推广新产品发布。这个背景帮助代理做出与其角色和职责一致的决策。
tools: 代理可以使用的特定能力或资源，以实现其目标。

llm: 支持代理生成和理解文本的语言模型。my_llm 代表像 GPT-4 这样的特定模型实例，代理使用它来生成内容和做出决策。
function_calling_llm: 专门负责处理代理使用工具或功能的语言模型。如果指定，该模型接管功能调用职责，确保代理能够有效利用其工具来生成内容。
max_iter: 设置代理在最终确定输出之前可以对任务迭代的次数限制。在这种情况下，代理最多有 15 次迭代机会来完善内容，然后再呈现最终版本。
verbose: 启用时，此属性可确保代理在运行过程中提供详细的反馈或日志。这对于跟踪代理的内容创建过程以及理解其如何得出结论非常有用。
allow_delegation: 确定代理是否可以将任务或查询委托给其他代理。允许委托=True 时，代理可以将某些任务委托给其他专业代理，如果它认为他们更适合该任务，以确保高效的内容创建。
callbacks: 在代理操作过程中特定点触发的功能。这允许调用方法或函数，以根据代理操作的结果执行通知或操作。
```


Tasks

任务是由代理管理的独立分配，设计有详细的说明以确保其成功执行。每个任务都提供代理完成工作所需的一切，包括描述、指定角色、所需工具和其他资源。这一综合设置允许代理以精确的方式处理不同复杂程度的任务。
在 CrewAI 中，任务也可以是协作的，通常涉及多个代理共同工作。这些任务的属性配置旨在促进有效的协作，Crew 的流程确保团队合作得以流畅高效地进行。
这是一个任务的代码：

```python
task = Task(
    description='Research and compile a list of best practices for cybersecurity in cloud environments',
    expected_output='A detailed report outlining the top 10 best practices for securing cloud environments, including explanations and examples.',
    agent=cybersecurity_agent,
    tools=[cloud_security_tool, research_tool]
)
```

任务结构属性的详细说明如下，并附有每个属性的解释：

description: 此属性提供了任务内容的简要但全面的概述。
它概述了任务的主要目标或目的，确保代理能够理解需要完成的工作。

expected_output: 此属性定义了任务的期望结果或成果。
它详细列出了成功完成任务应具备的条件，确保代理知道预期的结果。

agent: 代理是负责执行任务的特定实体或个人。
这可以是一个指定的代理，或通过系统内部过程确定的代理。
与代理类似，您还可以设置 max_iter、verbose、allow_delegation 和 callbacks 属性。但还有其他一些属性：

async_execution: 此属性允许任务异步运行，这意味着它可以在不阻止其他进程的情况下执行。
当任务需要长时间运行或需要并行进行多个任务时，这很有用。

context: 此属性添加其他任务，其输出可以作为执行任务的额外上下文提供。

config: 此属性允许额外的配置细节，以便进一步自定义任务。

output_json: 此属性使任务能够生成 JSON 对象形式的输出。
这对于需要易于处理或传输的结构化数据非常有用，并且需要 OpenAI 客户端。

output_pydantic: 类似于 JSON 输出，此属性允许任务生成 Pydantic 模型对象形式的输出，
这对于需要遵循特定数据模型的任务特别有用。这也需要 OpenAI 客户端。

output_file: 此属性使任务的结果可以保存到文件中。
如果与 JSON 或 Pydantic 输出结合使用，它决定输出的存储方式和位置，使其可以用于将来的使用或审查。
只能设置一种输出格式。

human_input: 指定任务完成后是否需要人工反馈，对于需要人工监督的任务非常有用。
默认情况下，此设置为 False。

callback: 调用方法或函数以根据任务的操作输出执行通知或操作。

Tools

在 CrewAI 中，工具是代理用来执行各种任务的能力或功能，从简单搜索到复杂交互，同时支持无缝团队合作。这些工具是增强代理协作能力的基本组件，来自 CrewAI 工具包和 LangChain 工具的选项。这些工具专为特定任务设计，例如网络搜索、数据分析、内容生成和代理协作，使其非常有用且多功能。
这些工具直接集成到代理的工作流程中，显著提升了代理的能力，使他们能够更高效地执行任务。此外，这些工具提供了高度的可定制性，允许开发人员创建自定义工具或利用现有工具以满足代理的特定需求。为了确保顺利运作，它们配备了强大的错误处理机制，并具有智能缓存功能，通过减少冗余任务来优化性能。这种实用性、集成性、可定制性和性能优化的结合使工具成为 CrewAI 生态系统的重要组成部分。本书使用 CrewAI 版本 0.51.0。
以下是 CrewAI 的一些工具：

- BrowserbaseLoadTool: 用于与网络浏览器交互并从中提取数据的工具
- CodeDocsSearchTool: 优化用于探索代码文档和技术手册的搜索工具
- CSVSearchTool: 专门用于搜索 CSV 文件，旨在有效处理结构化数据
- DALL-E Tool: 使用 DALL-E API 生成图像的工具
- DOCXSearchTool: 用于搜索 DOCX 文件的工具，使处理和检索 Word 文档信息变得容易
- PDFSearchTool: 专门用于搜索 PDF 文档的工具，适用于处理扫描或复杂文件
- ScrapeWebsiteTool: 用于抓取整个网站的工具，非常适合从网络收集全面数据
- XMLSearchTool: 专为搜索 XML 文件而设计的工具，针对结构化数据格式进行优化


Crews

一个团队是由多个代理协同工作以完成一组任务的合作集体。每个团队负责定义任务执行的策略，协调代理之间的交互，并管理整体工作流程，以确保高效和有效的操作。
以下是一个团队的示例代码：

```python
project_team = Crew(
    agents=[data_analyst, report_creator],
    tasks=[data_analysis_task, generate_report_task],
    process=Process.sequential,
    full_output=True,
    verbose=True,
)
```

我们有一些属性可以设置运行的代理和任务，还有一个用于指定流程的属性。这是运行这些代理的顺序。我们将在下面更详细地讨论这一点。
接下来是 full_output 属性。此属性控制团队是否返回所有任务输出或仅返回最终结果。
以下是其他一些属性：

- share_crew: 此选项允许您与 CrewAI 团队共享团队的执行数据和结果。
    共享此信息可以帮助改进库并有助于模型训练。

- output_log_file: 如果您希望保存团队输出和执行的完整日志，可以将其设置为 true
    或提供一个路径，以指定日志应保存到的特定文件。

- planning: 启用时，此属性使团队能够在每次迭代之前进行规划。
    您还可以使用 planning_llm 属性设置用于此目的的 LLM。

Processes

在 CrewAI 中，流程就像任务管理的支柱，就像项目经理在团队中组织和分配工作一样。这些流程确保任务按照设定策略有效分配和执行。
以下是流程的类型：

- 顺序流程：任务按照设定顺序一个接一个地执行。这确保每个任务都以特定顺序完成。
- 层级流程：任务在结构化的层级中进行管理。一个经理（可以是语言模型 manager_llm 或自定义代理 manager_agent）负责任务的分配和监督。此设置允许经理根据需要创建和分配任务，确保它们与团队的整体目标一致。
- 协商流程：这种流程旨在使代理能够就任务执行做出协作决策。它在 CrewAI 中引入了民主的任务管理方式，但目前计划用于未来开发，在现有代码中尚不可用。


The following is the code for a sequential process:

```python
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.sequential,
    manager_llm=ChatOpenAI(model="gpt-4"),
    memory=True,
    planning=True
)
```

```python
crew = Crew(
    agents=my_agents,
    tasks=my_tasks,
    process=Process.hierarchical,
    manager_llm=ChatOpenAI(model="gpt-4")
)
```

记忆

CrewAI 框架包含一个先进的记忆系统，大大增强了 AI 代理记忆、推理和从过去经验中学习的能力。这个记忆系统由几个关键元素组成，每个元素都旨在以特定方式提高代理的性能：

- 短期记忆：临时存储最近的交互和结果，允许代理在当前任务中访问和应用相关信息。这种即时回忆对于在持续操作中保持连续性和相关性至关重要。

- 长期记忆：保留过去执行的有价值见解，使代理能够随着时间的推移建立知识库并优化其决策过程。这种积累的智慧允许代理利用过去的经验来指导未来的行动。

- 实体记忆：专注于捕捉和组织任务中遇到的实体（如人、地点和概念）的信息。这增强了代理对复杂场景的理解和导航能力，为他们提供有关关键元素的详细知识。

- 上下文记忆：整合短期、长期和实体记忆的功能，以在多个任务或对话中保持一致的上下文。这确保了代理即使在交互范围扩大时也能提供连贯且上下文相关的响应。

通过结合这些记忆组件，CrewAI 系统为代理提供了上下文意识、积累和学习经验的能力，以及对关键实体的更深入理解。这个全面的记忆系统使代理在交互中更加有效和智能，使他们能够以更高的复杂性和适应性处理复杂任务。在本章的剩余部分，我们将通过多个 CrewAI 应用程序来说明这些核心概念。


```
注意：CrewaI+ 是 CrewaI 的企业版。它允许快速将任何团队转变为 API，并通过挂钩、REST、gRPC 和其他方法与应用程序集成。虽然，在撰写本文时，CrewaI+ 处于私人测试阶段。
```

Financial Planning Agent

我们将创建一个预算代理，通过分析用户的收入和支出来帮助用户制定详细的月度预算，确保涵盖所有必要费用并优化储蓄。
这涉及多代理协作。首先是预算代理。它通过分析用户的收入和支出，帮助用户制定详细的月度预算。接下来是投资顾问代理，它根据用户的财务目标和风险承受能力提供量身定制的投资建议，旨在通过明智的决策帮助用户增加财富。最后，债务管理代理专注于帮助用户管理和减少债务，通过制定有效的还款策略并提供有关债务合并和利率谈判的建议。
让我们来看一下代码：

!pip install crewai
!pip install crewai crewai-tools

我们首先安装核心 CrewAI 包，其中包括在 Python 中创建和管理多代理系统所需的基本类和函数。然后我们安装工具包。这些工具包括用于管理特定类型代理、连接到外部 API 或在多代理框架中实现高级功能的专用组件。

接下来我们导入以下内容：

```python
from crewai import Agent, Task, Crew
```

代码清单的下一部分是定义不同的代理。以下是预算代理的定义：


```python
budgeting_agent = Agent(
    role="Budgeting Advisor",
    goal="Create a monthly budget to assist users in effectively managing their income and expenses.",
    backstory=(
        "You are an experienced financial advisor specializing in personal finance. "
        "Your mission is to guide users in allocating their income efficiently, ensuring all necessary "
        "expenses are covered while also prioritizing future savings."
    ),
    allow_delegation=False,
    verbose=True
)
```

Agent 类的实例化包含几个关键参数，这些参数确定了代理的角色、目标和行为。在这个例子中，代理被赋予“预算顾问”的角色，目标是创建一个月度预算，以帮助用户有效地管理他们的收入和支出。backstory 参数为代理提供了背景和叙述，描述其为个人理财的经验丰富的财务顾问。这个背景故事帮助代理在响应和行动时，与作为财务顾问所期望的专业知识保持一致。allow_delegation=False 参数确保此代理不会将其任务委派给其他代理，保持其特定职责的责任。最后，verbose=True 启用代理操作的详细日志记录，提供代理处理信息和做出决策的见解。此设置允许预算代理在多代理系统中有效运行，有助于实现全面个人财务管理的总体目标。接下来是投资顾问代理：

```python
investment_agent = Agent(
    role="Investment Advisor",
    goal="Recommend suitable investment options based on the user's financial goals and risk tolerance.",
    backstory=(
        "You are an investment expert with years of experience in the financial markets. "
        "Your goal is to help users grow their wealth by providing sound investment advice "
        "tailored to their risk tolerance and financial objectives."
    ),
    allow_delegation=False,
    verbose=True
)
```

backstory 参数在塑造代理的响应和行动方面至关重要，将其描绘为具有深刻金融市场理解的投资专家。这种叙述帮助代理提供的建议不仅相关，而且符合经验丰富的金融专业人士所期望的专业水平。最后，是债务管理代理的创建：

```python
debt_management_agent = Agent(
    role="Debt Management Specialist",
    goal="Assist users in managing and reducing debt through effective strategies.",
    backstory=(
        "You specialize in helping individuals overcome debt by creating personalized repayment plans. "
        "Your focus is on reducing interest payments and improving the user's financial health."
    ),
    allow_delegation=False,
    verbose=True
)
```

backstory 参数通过将其塑造成专注于创建个性化还款计划的专家来提升代理的能力，这些计划旨在减少利息支付并改善用户的整体财务健康。 这种叙述有助于代理提供针对用户独特财务状况量身定制的建议和解决方案，确保指导既相关又可操作。 对于下一组代码，我们将为代理建立三个不同的任务。 我们从这个开始：

```python
budgeting_task = Task(
    description=(
        "1. Analyze the user's financial data, including income and expenses.\n"
        "2. Develop a detailed monthly budget highlighting essential expenses, savings, and discretionary spending.\n"
        "3. Offer strategic tips for optimizing spending and boosting savings."
    ),
    expected_output="A comprehensive budget plan with actionable recommendations for spending optimization and savings enhancement.",
    agent=budgeting_agent
)
```

代码片段适用于预算任务。这涉及全面的方法，从分析用户的收入和支出开始。description 参数概述了代理应采取的关键步骤：分析用户的财务状况；创建一个包含必要支出、储蓄和可自由支配开支的详细月度预算；最后，提供优化支出和增加储蓄的实用建议。expected_output 参数指定任务应产生的结果——一个完整的月度预算，包括改进财务管理的建议。通过将此任务链接到 budgeting_agent，程序确保代理的财务规划专业知识直接用于为用户生成个性化且可操作的预算。接下来是投资任务：

```python
investment_task = Task(
    description=(
        "1. Assess the user's financial goals and risk tolerance.\n"
        "2. Recommend suitable investment options such as stocks, bonds, mutual funds, or ETFs.\n"
        "3. Provide a brief overview of each recommended investment's potential risks and returns."
    ),
    expected_output="A personalized investment plan with recommendations and risk assessments.",
    agent=investment_agent
)
```

description 参数概述了代理应遵循的步骤：首先，评估用户的财务目标和风险承受能力，以理解其独特的投资需求；其次，推荐符合这些目标的合适投资选项，如股票、债券、共同基金或ETF；最后，提供每个推荐投资的潜在风险和回报的简要概述。expected_output 参数指定任务应产生个性化的投资计划，包括根据用户财务状况量身定制的建议和风险评估。通过将此任务链接到 investment_agent，程序利用代理在金融市场的专业知识来提供合理的投资建议，帮助用户做出与其财务目标和风险偏好一致的明智决策。第三个任务是债务管理：

```python
debt_management_task = Task(
    description=(
        "1. Analyze the user's current debts, including interest rates and balances.\n"
        "2. Develop a repayment plan that prioritizes paying off high-interest debt first.\n"
        "3. Suggest strategies for faster debt reduction, such as consolidation or negotiating lower rates."
    ),
    expected_output="A comprehensive debt management plan with actionable steps to reduce and eliminate debt.",
    agent=debt_management_agent
)
```

description 参数概述了代理将采取的关键步骤：首先，分析用户当前的债务情况，包括利率和余额等详细信息，以全面了解其债务状况；其次，制定优先偿还高利率债务的还款计划，这通常是最有经济利益的策略；最后，提供有关债务合并或协商降低利率的建议，以进一步减轻用户的财务负担。
expected_output 参数指定任务应产生详细的债务管理计划，其中包含减少和最终消除债务的可操作步骤。通过将此任务分配给 debt_management_agent，程序确保代理在债务管理方面的专业知识应用于为用户创建个性化且实用的计划。
接下来，我们需要将代理与各个任务连接起来。我们通过以下代码实现：

```python
crew = Crew(
    agents=[
        budgeting_agent,
        investment_agent,
        debt_management_agent
    ],
    tasks=[
        budgeting_task,
        investment_task,
        debt_management_task
    ],
    verbose=True  # Set to True for detailed logging or False to reduce output
)
```

该 Crew 对象集合了之前定义的三个代理，并通过 tasks 参数将这些代理与各自的任务关联起来，确保每个代理都能完成分配给自己的具体工作，例如制定预算、推荐投资计划和制定债务管理方案。我们接下来用如下方式运行 Crew：

```python
user_financial_data = {
    "financialdata": {
        "income": 5000,  # Monthly income in dollars
        "expenses": {
            "rent": 1500,
            "utilities": 300,
            "groceries": 400,
            "transportation": 200,
            "entertainment": 150,
            "other": 450
        },
        "debts": {
            "credit_card": {
                "balance": 2000,
                "interest_rate": 0.18  # 18% interest rate
            },
            "student_loan": {
                "balance": 15000,
                "interest_rate": 0.045  # 4.5% interest rate
            }
        },
        "savings_goal": 500  # Monthly savings goal in dollars
    }
}

# Now run the crew kickoff with the defined data
result = crew.kickoff(inputs=user_financial_data)

# Extract the raw text from the result
raw_result = result.raw

# Display the result as markdown
from IPython.display import Markdown
Markdown(raw_result)
```

变量 user_financial_data 用于表示用户的财务状况，涵盖了财务规划所需的各项要素。用户的月收入为 5,000 美元，支出分为多个类别：房租（1,500 美元）、水电费（300 美元）、食品杂货（400 美元）、交通（200 美元）、娱乐（150 美元）以及其他杂项支出（共计 450 美元）。此外，用户还负有债务，包括信用卡欠款 2,000 美元（年利率 18%）和学生贷款 15,000 美元（年利率 4.5%）。用户每月的储蓄目标为 500 美元。将这些详尽的财务数据传递给 crew.kickoff 函数后，多智能体协作流程随即启动，为用户生成个性化的财务建议。最终的结果以原始文本形式提取，并通过 Markdown 格式进行展示，便于阅读和理解，如图 6-1 所示。

**图 6-1.** _这是 CrewAI Agent 的输出结果_

Product Launch Orchestrator

我们将创建一个更高级的 AI 智能体，命名为 LaunchMaster。它被设计为简化产品发布的复杂流程，确保每个环节都得到精细管理，助力发布取得成功。借助专业的子智能体，LaunchMaster 能够高效地完成关键任务，包括深入的市场调研（识别目标人群与竞争对手）、为各类营销渠道打造引人入胜且具说服力的内容，以及针对性地联系影响者和媒体资源进行推广。

本程序引入了 CrewAI 框架中的一些新概念。例如，我们将使用 SerperDevTool 和 ScrapeWebsiteTool 这类新工具，还会演示如何自定义工具。同时，智能体支持人类输入，并能将数据保存到本地电脑。

下面演示该程序的运行流程。
我们首先导入如下库：

```python
from crewai_tools import ScrapeWebsiteTool, SerperDevTool
from pydantic import BaseModel
```

ScrapeWebsiteTool 专为抓取网站数据而设计，使 AI 智能体能够动态收集和分析网页内容。SerperDevTool 用于在互联网上进行搜索。要使用该工具，你需要在 serper.dev 注册并获取 API 密钥。
pydantic 库中的 BaseModel 类用于定义具有验证规则的数据模型，为自定义工具提供结构。
接下来，我们创建三个智能体：

```python
market_researcher = Agent(
    role="Market Researcher",
    goal="Conduct thorough market research to identify target demographics and competitors.",
    tools=[search_tool, scrape_tool],
    verbose=True,
    backstory=(
        "Analytical and detail-oriented, you excel at gathering insights about the market, "
        "analyzing competitors, and identifying the best strategies to target the desired audience."
    )
)

content_creator = Agent(
    role="Content Creator",
    goal="Develop engaging content for the product launch, including blogs, social media posts, and videos.",
    tools=[search_tool, scrape_tool],
    verbose=True,
    backstory=(
        "Creative and persuasive, you craft content that resonates with the audience, "
        "driving engagement and excitement for the product launch."
    )
)

pr_outreach_specialist = Agent(
    role="PR and Outreach Specialist",
    goal="Reach out to influencers, media outlets, and key opinion leaders to promote the product launch.",
    tools=[search_tool, scrape_tool],
    verbose=True,
    backstory=(
        "With strong networking skills, you connect with influencers and media outlets to ensure "
        "the product launch gains maximum visibility and coverage."
    )
)
```

市场调研员智能体专注于收集和分析市场数据，识别目标人群和竞争对手，并利用搜索和网页抓取等工具。内容创作者智能体负责开发吸引人的内容，比如博客和社交媒体帖子，以激发受众的兴趣并提升产品发布的参与度。公关与外联专家智能体则以影响者和媒体为目标，通过强大的社交和网络技能，最大化产品发布的曝光和报道，同样借助搜索和抓取工具实现高效外联。
以下是基础类定义：

```python
class MarketResearchData(BaseModel):
    target_demographics: str
    competitor_analysis: str
    key_findings: str

market_research_task = Task(
    description=(
        "Conduct market research for the {product_name} launch, focusing on target demographics and competitors."
    ),
    expected_output="A detailed report on market research findings, including target demographics and competitor analysis.",
    human_input=True,
    output_json=MarketResearchData,
    output_file="market_research.json",
    agent=market_researcher
)
```

该任务根据 MarketResearchData 基础模型生成结构化的详细调研报告，确保输出格式一致且准确。同时，设置了 human_input 参数，允许在最终结果输出前进行人工反馈审核。输出将以 JSON 文件（“market_research.json”）形式保存，便于后续分享和与其他产品发布策略组件集成。
接下来是下一个任务：

```python
content_creation_task = Task(
    description=(
        "Develop a suite of engaging content assets for the {product_name} launch, "
        "including:\n"
        "- Blog articles tailored to the target audience\n"
        "- Social media posts for major platforms\n"
        "- Promotional video scripts\n"
        "Ensure consistency with the product's branding and messaging."
    ),
    expected_output="A complete set of content materials ready for publication across all designated channels.",
    human_input=True,
    async_execution=False,
    output_file="content_plan.txt",
    agent=content_creator
)
```
该任务要求内容创作者智能体为产品发布开发多种内容资产。任务目标是生成一套可直接发布的内容集合，有效推广产品。任务还设置了人工反馈参数。完成的内容会被保存为文本文件（“content_plan.txt”）。

最后，我们有如下任务：

```python
pr_outreach_task = Task(
    description=(
        "Coordinate outreach to influencers, media outlets, and key opinion leaders for the {product_name} launch.\n"
        "Document all engagement activities, including:\n"
        "- List of contacts reached\n"
        "- Methods and channels used\n"
        "- Responses and feedback received\n"
        "- Media coverage secured\n"
        "Ensure alignment with launch messaging and maximize positive exposure."
    ),
    expected_output="A comprehensive Markdown report summarizing outreach actions, responses from stakeholders, and resulting media coverage.",
    human_input=True,
    async_execution=False,
    output_file="outreach_report.md",
    agent=pr_outreach_specialist
)
```
该任务要求公关与外联专家智能体联系影响者、媒体和意见领袖，以推广产品发布。任务重点是提升品牌曝光度和媒体报道。预期输出为一份全面的报告，详细记录所有外联活动，包括被联系方的反馈和回复。最终报告将以 Markdown 文件（“outreach_report.md”）形式保存。
我们为智能体创建团队如下：

```python
product_launch_crew = Crew(
    agents=[market_researcher, content_creator, pr_outreach_specialist],
    tasks=[market_research_task, content_creation_task, pr_outreach_task],
    verbose=True
)
```

该团队由市场调研员、内容创作者和公关外联专家三个智能体组成。
接下来运行团队：

```python
launch_details = {
    "product_name": "SmartHome 360",
    "product_description": "一款可与所有设备集成的前沿智能家居系统。",
    "launch_date": "2024-10-01",
    "target_market": "科技型家庭用户",
    "budget": 50000
}

result = product_launch_crew.kickoff(inputs=launch_details)
```

```python
launch_details = {
    "product_name": "SmartHome 360",
    "product_description": "A cutting-edge smart home system that integrates with all your devices.",
    "launch_date": "2024-10-01",
    "target_market": "Tech-savvy homeowners",
    "budget": 50000
}

result = product_launch_crew.kickoff(inputs=launch_details)
```

launch_details 字典包含了 “SmartHome 360” 产品发布的关键信息。这是一款最前沿的智能家居系统，可与多种设备无缝集成。字典中包括产品名称、简要描述、发布日期（2024 年 10 月 1 日）、目标市场（科技型家庭用户）以及 5 万美元的预算。当这些信息作为输入传递给 product_launch_crew 并通过 kickoff 方法启动后，团队中的 AI 智能体会根据这些参数分别执行市场调研、内容创作和公关外联等任务。

输出内容非常丰富，我们实际运行时生成的报告超过 162 页！程序会访问互联网收集报告和分析所需的数据。随后，我们将这些海量信息提炼为更简明的形式：

```python
import json
from pprint import pprint
from IPython.display import Markdown, display

# Display the generated market_research.json file
with open('market_research.json', encoding='utf-8') as f:
    data = json.load(f)
pprint(data)

# Display the generated content_plan.txt file
with open('content_plan.txt', encoding='utf-8') as f:
    content = f.read()
print(content)

# Display the generated outreach_report.md file as markdown
with open('outreach_report.md', encoding='utf-8') as f:
    outreach_md = f.read()
display(Markdown(outreach_md))
```

首先，导入了 json 模块用于加载和解析 JSON 数据，同时从 pprint 模块引入 pprint 以便对复杂数据结构进行美观的格式化输出。

接下来，程序打开并加载了 market_research.json 文件，该文件包含了市场调研员智能体生成的数据，随后利用 pprint 对其进行结构化展示。紧接着，程序打开并读取 content_plan.txt 文件，该文件由内容创作者智能体生成，用于展示产品发布的内容策划方案。最后，程序使用 Markdown 函数渲染由公关与外联专家智能体生成的 outreach_report.md 文件，以美观的格式呈现外联报告，方便回顾智能体的外联成果。通过这一系列步骤，确保所有 AI 智能体的关键输出都能被友好、清晰地访问和展示。

客户呼叫中心处理

我们将查看使用 CrewAI 的一个更复杂的示例。它将自动化呼叫中心的任务。为此，我们将使用分层流程。
典型的客户服务中心构成了客户通过电话、电子邮件或聊天进行沟通的服务中心。客户的来电根据问题的性质（如账单查询、技术支持或一般咨询等）被转接给代理。代理为客户的问题提供直接解决方案，或者将问题升级给专家。复杂的问题将使用工单系统进行跟踪并跟进解决。在互动之后，通常会要求客户提供反馈，以进一步提高服务质量。
图 6-2 显示了层级结构。以下是代理：

- 客户服务经理：监督多个专职任务的专门代理
- 呼叫处理代理：管理呼叫路由、查询解决和升级等任务

- 技术支持代理：处理故障排除、远程协助和服务工单创建
- 账单和付款代理：处理发票生成、付款处理和争议解决
- 客户反馈和调查代理：管理调查分发、反馈收集和情感分析

**图 6-2.** _客户呼叫中心的组织结构图_

让我们看看程序如何工作。
我们引入以下库：

```python
from langchain_openai import ChatOpenAI
from crewai import Crew, Process, Agent

# 按照上文的组织结构，创建以下四个智能体：
call_handling_agent = Agent(
    role="Call Handling Agent",
    goal="Manage and resolve customer inquiries via phone, including call routing and query resolution: {call_action_taken}",
    tools=[],
    allow_delegation=True,  # 允许任务委派
    verbose=True,
    backstory=(
        "Skilled in handling incoming calls, routing customers to the right departments, and resolving basic queries efficiently."
    )
)
```

上述代码描述了系统中呼叫处理代理的功能。示例包括呼叫路由、响应简单查询和升级。这使用一个参数，该参数动态使用来自客户呼叫本身的操作详细信息{call_action_taken}。此代理还将任务传递给其他代理或部门以解决更复杂的问题。

我们有技术支持代理：

```python
tech_support_agent = Agent(
    role="Technical Support Agent",
    goal="Troubleshoot and resolve technical issues reported by customers: {technical_action_taken}",
    tools=[],
    allow_delegation=True,  # 允许任务委派或升级
    verbose=True,
    backstory=(
        "Experienced in providing remote technical assistance, troubleshooting various levels of problems, and managing service tickets through all stages to ensure efficient resolution."
    )
)
```

目标动态包含代理在解决过程中采取的操作{technical_action_taken}。该代理具有将任务委派或将问题升级给其他代理的能力（allow_delegation=True）。描述中提到，代理在远程技术支持、各级问题排查和涵盖所有流程阶段的服务工单管理方面具有丰富经验。
接下来是账单代理：

```python
billing_agent = Agent(
    role="Billing & Payments Agent",
    goal="Handle customer billing inquiries, process payments, and resolve payment disputes: {billing_action_taken}",
    tools=[],
    allow_delegation=False,  # This agent does not delegate tasks
    verbose=True,
    backstory=(
        "Expert in managing billing-related issues, ensuring accurate invoices, and processing payments quickly "
        "while addressing customer disputes or issues."
    )
)
```

目标动态包含有关客户账单在此交互期间所采取的操作{billing_action_taken}。与其他代理不同，此代理不能委派任务，正如 allow_delegation=False 所指示。代理的描述强调了在处理各种账单问题上的经验，例如正确开具发票、正确处理付款以及解决任何账单争议或问题。
接下来是反馈代理：

```python
feedback_agent = Agent(
    role="Customer Feedback & Surveys Agent",
    goal="Gather and analyze customer feedback through surveys and sentiment analysis: {customer_feedback}",
    tools=[],
    allow_delegation=False,  # This agent does not delegate tasks
    verbose=True,
    backstory=(
        "Specialized in collecting customer feedback, conducting surveys, and analyzing sentiment data to improve overall service quality."
    )
)
```

该代理使用 {customer_feedback} 分析客户反馈。此代理不允许任务委派。代理的背景故事包括专门从事客户反馈的收集、调查和情感数据分析，以提高客户服务质量。
以下代码展示了各种代理的任务：

```python
# Call Handling Task
call_handling_task = Task(
    description="Handle incoming customer calls, resolve basic queries, or escalate them if needed.",
    expected_output="A detailed report on calls handled, queries resolved, and escalations made.",
    human_input=True,
    output_json=CallHandlingData,
    output_file="call_handling_report.json",
    context={
        "priority": "high",
        "expected_resolution_time": "15 minutes"
    },
    agent=call_handling_agent,
    callback=lambda result: print(f"Task completed by {call_handling_agent.role}: {result}")
)

# Technical Support Task
tech_support_task = Task(
    description="Troubleshoot technical issues reported by customers and resolve or escalate as needed. Document steps taken.",
    expected_output="A report summarizing the technical issues handled and any open tickets.",
    human_input=True,
    output_json=TechSupportData,
    output_file="tech_support_report.json",
    context={
        "priority": "medium",
        "expected_resolution_time": "30 minutes"
    },
    agent=tech_support_agent,
    callback=lambda result: print(f"Task completed by {tech_support_agent.role}: {result}")
)

# Billing & Payments Task
billing_task = Task(
    description="Process customer invoices, handle payment issues, and resolve any disputes.",
    expected_output="A report detailing invoices processed, payments completed, and disputes resolved.",
    human_input=True,
    output_json=BillingData,
    output_file="billing_report.json",
    context={
        "priority": "low",
        "expected_resolution_time": "45 minutes"
    },
    agent=billing_agent,
    callback=lambda result: print(f"Task completed by {billing_agent.role}: {result}")
)

# Customer Feedback & Surveys Task
feedback_task = Task(
    description="Distribute customer satisfaction surveys and analyze the feedback for sentiment insights.",
    expected_output="A report summarizing survey results and customer sentiment analysis.",
    human_input=True,
    output_json=FeedbackData,
    output_file="feedback_report.json",
    context={
        "priority": "low",
        "expected_resolution_time": "60 minutes"
    },
    agent=feedback_agent,
    callback=lambda result: print(f"Task completed by {feedback_agent.role}: {result}")
)
```

呼叫处理代理负责处理客户来电、解决查询以及升级复杂问题，所有这些都应该在15分钟内解决。技术支持代理负责排除技术故障并准备报告，预计需要在30分钟内完成。账单代理负责发票处理、付款问题或争议。

整体优先级较低，解决时间约为45分钟。客户反馈代理通过调查收集客户反馈。任务的优先级也较低，预计完成时间为60分钟。
callback属性接受一个在任务运行后执行的函数，并通过记录一条消息来产生结果，表明代理已经完成了任务。这对于实时任务执行跟踪和管理、保持顺畅的工作流程以及适当记录结果非常有用。
为了存储与代理执行的任务相关的数据，我们可以创建如下的基类：

```python
from pydantic import BaseModel, Field

class CallHandlingData(BaseModel):
    call_summary: str = Field(description="Summary of all calls handled during the session")
    resolved_queries: str = Field(description="Details of customer queries resolved")
    escalated_issues: str = Field(description="Information about issues escalated to other agents or departments")

class TechSupportData(BaseModel):
    troubleshooting_steps: str = Field(description="Steps taken to troubleshoot technical issues")
    resolved_issues: str = Field(description="Technical problems resolved during the session")
    open_tickets: str = Field(description="List and status of any open technical support tickets")

class BillingData(BaseModel):
    invoice_details: str = Field(description="Information about invoices processed or generated")
    processed_payments: str = Field(description="Payments handled or completed")
    resolved_disputes: str = Field(description="Details of billing disputes that were addressed and resolved")

class FeedbackData(BaseModel):
    survey_results: str = Field(description="Results from customer satisfaction surveys")
    customer_feedback: str = Field(description="Collected feedback from customers")
    sentiment_summary: str = Field(description="Analysis summary of customer sentiment based on feedback")
```

The code snippet below is for creating a Crew that is composed of
four agents:

```python
customer_service_crew = Crew(
    agents=[call_handling_agent, tech_support_agent, billing_agent, feedback_agent],
    tasks=[call_handling_task, tech_support_task, billing_task, feedback_task],
    manager_llm=ChatOpenAI(temperature=0, model="gpt-4o"),
    process=Process.hierarchical,
    memory=True,
    planning=True
)
```

设置 memory=True 允许存储先前任务的信息，以便在任务执行时保持更好的连续性。属性 planning=True 允许系统通过资源分配进行战略规划。层级流程结构使团队能够像一个组织良好且协调一致的团队一样运作，其中每个智能体都执行其角色，系统组织整体工作流程和任务分配。接下来，我们获取用户输入：

```python
customer_service_details = {
    'call_handling': {
        'queries_to_resolve': [
            'Account update request, need to update phone number',  # Customer had issues with updating their account
            'Complaint about slow service on previous calls'
        ],
        'call_action_taken': 'Account update request is completed. Call transferred to technical support'
    },
    'escalations': {
        'technical_support': {
            'issue': 'Product malfunction after software update',
            'technical_action_taken': 'Noted the issues faced by the customer and ticket created for further investigation, call transferred to billing for resolution of overcharges'
        },
        'billing': {
            'issue': 'Overcharged on most recent invoice',
            'priority': 'High',
            'billing_action_taken': 'The overcharges are dropped and customer was sent to take survey with end of the call'
        }
    },
    'technical_support': {
        'troubleshooting_steps': [
            'Check for software compatibility issues',
            'Remote assistance to reinstall/update software'
        ]
    },
    'billing_payments': {
        'priority': 'High',
        'dispute_resolution_steps': [
            'Review the invoice for overcharges',
            'Calculate and issue refund if overcharge is confirmed'
        ]
    },
    'customer_feedback': {
        'feedback_sentiment': {
            'positive': '50%',   # The customer was satisfied with the billing resolution
            'neutral': '30%',    # Neutral on overall service quality
            'negative': '20%'    # Negative due to unresolved technical issue
        }
    }
}
```

Finally, we kick off our crew with the above user input:

```python
task_result = customer_service_crew.kickoff(inputs=customer_service_details)

def handle_task_completion(task_result):
    raw_result = task_result.raw
    from IPython.display import Markdown, display
    print("Task completed:")
    display(Markdown(raw_result))
```


检索增强生成 (RAG)

CrewAI 提供了用于检索增强生成 (RAG) 的各种类。
以下是一些示例：

- CSVSearchTool：允许代理高效地从 CSV 文件中检索特定数据。
- DOCXSearchTool：搜索 DOCX 文档，根据查询的上下文检索相关文本段落。
- PDFSearchTool：支持搜索 PDF 文件，提取并使用相关内容生成响应。
- WebsiteSearchTool：搜索指定网站，从网页中提取相关信息以增强生成过程。
下面是一个示例。我们将使用 WebsiteSearchTool。
首先进行以下导入：

```python
from crewai import Agent, Task, Crew, Process
from crewai_tools import WebsiteSearchTool
```

我们配置 WebsiteSearchTool 的网址：
WebsiteSearchTool(website='https://en.wikipedia.org/wiki/Alan_Turing')

这是艾伦·图灵的简介。
我们将创建一个执行搜索的代理：

```python
search_agent = Agent(
    role='Website Researcher',
    goal='Search and extract relevant information from a specific website.',
    verbose=True,
    memory=True,
    backstory='You are an expert in searching websites for the most relevant and up-to-date information.',
    tools=[search_tool]
)
```

该代理被指派为“网站研究员”，其明确目标是识别和检索网站上的相关数据。代理的背景故事将其确立为网络研究专家，强调其发现最相关和最新信息的能力。最后，代理配备了必要的工具，在这种情况下是 search_tool，以有效地执行其搜索任务。
我们为代理定义任务：

```python
search_task = Task(
    description=(
        "Utilize the specified website to collect information on the topic '{topic}'. "
        "Ensure a comprehensive gathering of all pertinent data available on the site."
    ),
    expected_output="A thorough summary of the information retrieved from the website.",
    tools=[search_tool],
    agent=search_agent,
)
```

search_task 指示代理使用 URL 收集给定主题（由 {topic} 表示）的信息。任务描述强调了收集网站上所有相关数据的重要性。此任务的预期输出是根据代理的发现编写的信息详细摘要。任务配备了必要的 search_tool 来执行搜索过程，并分配给 search_agent，由其利用其在网络研究方面的专业知识执行任务。
我们将创建团队：

```python
research_crew = Crew(
    agents=[search_agent],
    tasks=[search_task],
    process=Process.sequential  # Executes tasks one after the other
)
```

该团队配置为顺序执行任务。search_agent 的加入确保有专门的专家来进行研究，而 search_task 则提供了明确的任务说明。通过这种方式组织流程，研究团队能够有效地处理任务流。
我们用“人工智能”作为主题输入启动团队，然后打印出 RAG 的结果：

```python
task_result = research_crew.kickoff(inputs={'topic': 'Artificial intelligence'})

def display_task_result(task_result):
    from IPython.display import Markdown, display
    display(Markdown(task_result.raw))

display_task_result(task_result)
```

然后，我们会得到一个输出，从网页中检索出与主题相关的部分。

连接LLM

目前，CrewAI的默认LLM是GPT-4o。但该框架允许使用许多其他模型。

让我们首先看看如何使用来自Hugging Face的模型：

```python
from langchain.llms import HuggingFaceHub

# Creating an instance of HuggingFaceHub with the specified parameters
llm = HuggingFaceHub(
    repo_id="HuggingFaceH4/zephyr-7b-beta",
    huggingfacehub_api_token="<HF_TOKEN_HERE>",
    task="text-generation"
)
```

以下是参数说明：

- repo_id：指定要使用的 Hugging Face Hub 模型。
- huggingfacehub_api_token：在此处提供 Hugging Face 的 API 令牌。您可以在 HuggingFace.co 获取免费令牌。
- task：指定模型设计的任务类型。在这种情况下，“text-generation”表示模型将用于生成文本。
另一种选择是 Cohere。为此，您将导入此模块：

```python
from langchain_community.chat_models import ChatCohere
```

接下来，您将为 Cohere API 密钥设置环境变量（您可以在 cohere.com 找到它）：

```python
os.environ["COHERE_API_KEY"] = "your-cohere-api-key"

llm = ChatCohere()

from langchain_openai import AzureChatOpenAI

azure_llm = AzureChatOpenAI(
    azure_endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT"),
    api_key=os.environ.get("AZURE_OPENAI_KEY")
)
```

有多种方法可以使用本地 LLM。首选方法是使用 Ollama。
然后您将使用此导入：

```python
from langchain_ollama import ChatOllama

# Create an llm object with specified parameters
llm = ChatOllama(
    model="llama3.1",
    base_url="http://localhost:11434"
)
```

Conclusion

基于强大的LangChain框架，CrewAI通过专注于角色扮演场景简化了多代理系统的创建和管理，允许代理有效地协作以实现复杂目标。该框架的灵活性体现在其与各种工具的集成能力，包括网络搜索、数据分析和内容生成，使其在不同应用中具有高度的通用性。随着贡献者社区的不断壮大，CrewAI有望成为AI开发领域的重要角色。

© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 147

https://doi.org/10.1007/979-8-8688-1134-0_7

**CHAPTER 7**

**AutoGen**

2023年8月，来自微软、宾夕法尼亚州立大学、华盛顿大学和中国西安电子科技大学的研究人员发表了一篇题为“AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation”的论文。^1 该论文介绍了一种新的开源框架，AutoGen，供开发人员构建包含多个代理协作的LLM应用程序。
这些代理在解决复杂的数学问题、自动化编码过程和增强决策能力方面表现出色。通过利用多个代理的优势，AutoGen代表了LLM应用开发的重大进步，提供了一个可以针对各种场景进行定制的强大平台。自推出以来，其受欢迎程度大幅上升。目前，AutoGen的GitHub仓库上已有超过30,000颗星，并且有超过300名贡献者。^2
目前，我是一个首席软件工程师，领导一个由十人组成的团队，他们正在开发GenAI应用程序。我们确实使用代理通过AutoGen和微软的低代码/无代码助理工作室来解决财务问题，该工作室也支持代理工作流程。

(^1) https://arxiv.org/abs/2308.08155
(^2) https://github.com/microsoft/autogen


“AutoGen 为开发人员在定义多代理工作流及其自定义方面提供了更细致的控制，”微软首席软件工程师 Ravi Shankar Goli 说。他主要专注于生成式 AI。 “当我们需要人工干预时，该框架易于开发对话代理。” 在本章中，我们将了解 AutoGen 的核心组件以及如何创建多代理系统。

```
注意：本章基于 AutoGen 0.2。然而，预计该框架将进行重大更新。 但我们将在我们的 GitHub 仓库中提供更新。
```
ConversableAgent

ConversableAgent 是一种专门设计用于有效管理对话的智能体。它处理来自用户的输入，使用预定义的逻辑进行处理，并生成适当的响应。该智能体旨在理解和参与自然语言对话，使其在各种聊天机器人和虚拟助手应用程序中都很有用。它利用预定义的技能和上下文理解来提供相关且连贯的互动，确保用户获得流畅且有意义的对话体验。
让我们看看如何使用 ConversableAgent。以下是一个简单示例，展示了两个智能体 Alice 和 Bob 之间的对话，其中 Alice 是友好的 AI 助手，而 Bob 是一个充满好奇心的学习者。对话将专注于简单的问答交流，我们将在之后打印出对话的详细信息。


We will have this setup:

pip install --upgrade pyautogen
```python
from autogen import ConversableAgent

llm_config = {"model": "gpt-4o-mini"}

# Initialize agents Alice and Bob
alice = ConversableAgent(
    name="alice",
    system_message="Your name is Alice, and you are a friendly AI assistant ready to help with any questions.",
    llm_config=llm_config,
    human_input_mode="NEVER",
)

bob = ConversableAgent(
    name="bob",
    system_message="Your name is Bob, and you are a curious learner who loves asking questions.",
    llm_config=llm_config,
    human_input_mode="NEVER",
)
```

第一个智能体，Alice，被设置为友好的AI助手。她的系统消息定义了她的角色，表明她随时准备回答用户可能有的任何问题。配置（llm_config）指定了她用于生成响应的语言模型，并且human_input_mode设置为“NEVER”，这意味着Alice在没有直接人类输入的情况下自主操作。

第二个智能体，Bob，被描述为一个好奇的学习者，他喜欢提问。与Alice相似，Bob的行为和反应由他的系统消息塑造，强调了他的好奇本性。与Alice一样，Bob使用相同的语言模型配置，并且独立操作。
然后我们用这个来开始对话：

```python
chat_result = bob.initiate_chat(
    recipient=alice,
    message="Hi Alice! Can you tell me how photosynthesis works?",
    max_turns=2,
)
```

Bob 开始与 Alice 的对话，询问关于光合作用的问题。使用 initiate_chat 方法启动此对话，Bob 作为发送者，Alice 作为接收者。Bob 发送的初始消息是：“嗨，Alice！你能告诉我光合作用是如何工作的吗？” max_turns=2 参数指定了对话将持续两个回合（Bob 的一个回合和 Alice 的一个回应）。此设置允许 Bob 提问并从 Alice 那里获得信息性响应，展示了这些代理如何进行结构化且连贯的交流，Bob 寻求知识而 Alice 提供知识。此交互的结果，包括对话历史和任何生成的响应，存储在 chat_result 变量中，可以进一步分析或显示。

Reflection Agent

我们将通过创建一个用于创建和完善推文的多智能体系统来探讨反思的概念。在此上下文中，反思是指代理根据其他代理的反馈批判性地评估和改进其输出的过程。该程序将通过利用专门的代理来展示反思的实现——每个代理都有不同的角色，例如撰写初始推文、优化 SEO、确保符合法律要求以及提供最终批准。通过这个示例，您将了解到反思如何使这些代理能够迭代地完善他们的工作，提高最终产品的质量和连贯性。我们首先需要加载 AutoGen 库：

```python
import autogen

task = """
Write an engaging tweet to introduce a new AI tool for content creators.
Ensure the tweet is concise, includes relevant hashtags, and adheres to Twitter's character limit.
"""
```

基本上，我们希望推文简洁明了，有效地捕捉AI工具的精髓，同时符合Twitter的字符限制。此外，推文应包含相关的标签，以增强其在平台生态系统中的可见性和传播范围。此任务作为多代理系统的基础指令，指导后续步骤中的各个代理优化推文，以确保其符合指定标准并最大化其在社交媒体上的影响力。我们将设置各种代理：

```python
# Tweet Writer Agent

tweet_writer = autogen.AssistantAgent(
    name="TweetWriter",
    system_message=(
        "You are a tweet writer. You write concise and engaging tweets on given topics. "
        "Your tweets should be compelling, include relevant hashtags, and be within the character limit."
    ),
    llm_config=llm_config,
)

# Content Optimizer Agent

content_optimizer = autogen.AssistantAgent(
    name="ContentOptimizer",
    system_message=(
        "You are a content optimizer. You refine the tweet to improve its clarity, engagement, and impact. "
        "Your revisions should enhance the message while keeping the tweet concise and within the character limit."
    ),
    llm_config=llm_config,
)

# SEO Reviewer Agent

seo_reviewer = autogen.AssistantAgent(
    name="SEOReviewer",
    system_message=(
        "You are an SEO reviewer. You optimize the tweet for search engines and social media algorithms. "
        "Your suggestions should include relevant keywords and hashtags that increase visibility."
    ),
    llm_config=llm_config,
)

# Legal Reviewer Agent

legal_reviewer = autogen.AssistantAgent(
    name="LegalReviewer",
    system_message=(
        "You are a legal reviewer. You ensure that the tweet is legally compliant and free from any potential legal issues. "
        "Your review should be concise, ensuring that the content adheres to legal standards."
    ),
    llm_config=llm_config,
)

# Final Reviewer Agent (finalizes the tweet)

final_reviewer = autogen.AssistantAgent(
    name="FinalReviewer",
    system_message=(
        "You are the final reviewer. You aggregate all feedback and finalize the tweet, ensuring it is optimized, legally compliant, and engaging."
    ),
    llm_config=llm_config,
)
```

在这个多智能体系统中，每个智能体在工作流程中扮演着特定的角色，为创建和完善高质量的推文做出贡献。流程始于推文撰写代理（Tweet Writer Agent），负责起草初始推文。该代理为推文奠定基础，确保其传达核心信息并吸引目标受众。一旦创建了初稿，内容优化代理（Content Optimizer Agent）便介入。该代理通过提高推文的清晰度、参与度和整体影响力来进行优化。内容优化代理的角色是打磨推文，确保语言精练、信息明确，且内容能够很好地引起目标受众的共鸣。这个迭代过程帮助将初稿转变为更具吸引力的内容，同时不牺牲推特所需的简洁。
接下来，SEO 审核代理（SEO Reviewer Agent）从搜索引擎优化的角度评估推文。该代理确保推文包含正确的关键词和标签，以最大程度地提高其在社交媒体平台上的可见性。SEO 审核员针对算法优化内容，旨在通过提高推文的可发现性来增加其影响范围和参与度，使其更容易被正在搜索相关主题的用户找到。

然后，法律审核代理（Legal Reviewer Agent）审核推文，以确保其符合法律标准。此代理对于减轻任何潜在的法律风险至关重要，例如使用受版权保护的材料、误导性陈述或可能导致法律问题的其他内容。
接着，最终审核代理（Final Reviewer Agent）汇总所有先前代理的反馈并最终确定推文。该代理的角色是确保推文不仅符合法律合规和 SEO 优化要求，还要具有吸引力和精致。最终审核员整合所有其他代理的见解，在推文获得发布批准之前进行必要的调整。此最终步骤确保推文质量最高，满足在社交媒体上成功的所有必要标准。
我们将有一个函数来生成反思信息：

```python
def reflection_message(recipient, messages, sender, config):
    return f'''Review the following content.\n\n{recipient.chat_messages_for_summary(sender)[-1]['content']}'''

review_chats = [
    {
        "recipient": content_optimizer,
        "message": reflection_message,
        "summary_method": "reflection_with_llm",
        "summary_args": {
            "summary_prompt": "Return review as a JSON object only: {'Reviewer': '', 'Review': ''}. Here Reviewer should be your role"
        },
        "max_turns": 1
    },
    {
        "recipient": seo_reviewer,
        "message": reflection_message,
        "summary_method": "reflection_with_llm",
        "summary_args": {
            "summary_prompt": "Return review as a JSON object only: {'Reviewer': '', 'Review': ''}."
        },
        "max_turns": 1
    },
    {
        "recipient": legal_reviewer,
        "message": reflection_message,
        "summary_method": "reflection_with_llm",
        "summary_args": {
            "summary_prompt": "Return review as a JSON object only: {'Reviewer': '', 'Review': ''}"
        },
        "max_turns": 1
    },
    {
        "recipient": final_reviewer,
        "message": "Aggregate feedback from all reviewers and finalize the tweet.",
        "max_turns": 1
    },
]
```

review_chats 列表定义了在推文优化过程中各个智能体之间进行反思交互的顺序。此列表中的每个条目都指定了一个智能体（接收者），该智能体将接收到 reflection_message 函数生成的反思消息。内容优化者、SEO 审核员和法律审核员分别负责审查推文的内容，并在其专业领域内提供反馈。summary_method 使用 reflection_with_llm 来总结他们的反馈，智能体被指示以 JSON 对象的形式返回其评审，确保格式结构化和标准化。列表的最后一项指定最终审核员负责汇总之前智能体提供的所有反馈，并生成推文的最终版本。我们将注册嵌套聊天：

```python
tweet_writer.register_nested_chats(
    review_chats,
    trigger=tweet_writer
)

# Initialize the chat and get the final tweet
response = tweet_writer.generate_reply(
    messages=[{"content": task, "role": "user"}]
)
final_response = final_reviewer.initiate_chat(
    recipient=tweet_writer,
    message=task,
    max_turns=2,
    summary_method="last_msg"
)

print(final_response.summary)
```

流程始于 tweet_writer 代理根据提供的任务生成初始推文。这里使用 generate_reply 函数来生成作为草稿推文的响应。随后，final_reviewer 代理通过调用 initiate_chat 函数与 tweet_writer 发起聊天。该函数协调代理之间的对话，使 final_reviewer 能够收集并整合在早期反思阶段收到的所有反馈。max_turns=2 参数表示聊天可以往返最多两次，以进一步完善推文。summary_method="last_msg" 确保最终输出基于对话中的最新消息，这应代表最终定稿和完善的推文。最终结果，封装在 res.summary 中，打印出来，展示了经过所有参与代理优化和审核的推文。
图 7-1 显示了输出。

**图 7-1.** _这是 Tweet Creator 代理的输出_

工具使用

我们的下一个程序将用于处理员工请假请求的代理。该程序通过集成自定义函数并将其注册为代理内可调用工具，突显了工具的使用。通过模拟一个代理总结请假请求并由另一个代理基于该总结做出批准决定的工作流程，该程序展示了如何有效利用工具将复杂任务分解为代理可以自主执行的模块化、可管理组件。
我们将首先加载此库：

```python
from typing import Annotated

# Annotated 允许您向类型提示添加额外的元数据，
# 使您能够提供有关如何使用值的更多上下文或约束，
# 这在文档编制、验证或工具使用中可能非常有用。
# 然后我们有一个需要处理的请假请求：

leave_request_text = """
Employee: John Doe
Department: IT
Leave Type: Annual Leave
Leave Dates: 10/01/2024 - 10/05/2024
Total Days: 5
Reason: Vacation
Remaining Leave Balance: 10 days
Status: Pending Approval
"""
```

变量 leave_request_text 是一个 Python 中的多行字符串，包含请假请求的详细信息。它包括员工姓名、部门、请假类型、请假日期、请求的总天数、请假原因、剩余假期余额以及请求的当前状态（待批准）。
接下来我们有两个工具：

```python
def summarize_leave_request() -> Annotated[str, "Summary of the leave request"]:
    """Summarizes the provided leave request."""
    return (
        "Summary: Employee John Doe from the IT department has requested 5 days "
        "of annual leave from 10/01/2024 to 10/05/2024 for vacation. "
        "Remaining leave balance is 10 days. Status is Pending Approval."
    )

def approve_or_reject_leave(summary: Annotated[str, "Summary of the leave request"]) -> Annotated[str, "Approval or Rejection decision"]:
    """Approves or rejects the leave request based on the summary."""
    if "Remaining leave balance is 10 days" in summary and "5 days" in summary:
        return "Approved: The leave request is approved as it meets the company policy."
    else:
        return "Rejected: The leave request is rejected due to insufficient leave balance."
```

summarize_leave_request 函数根据提供的详细信息生成请假请求的摘要，例如员工姓名、部门、请假日期和请求状态。
approve_or_reject_leave 函数以之前函数生成的摘要为输入，评估请假请求是否应被批准或拒绝。它会将剩余假期与请求的天数进行比较；如果余额充足，请求会被批准；否则会被拒绝。这些函数展示了程序如何通过首先总结相关数据，然后应用业务逻辑来自动化决策过程。
之后，我们将创建两个智能体：

```python
# Leave Request Reviewer Agent
leave_request_reviewer = ConversableAgent(
    name="Leave Request Reviewer",
    system_message=(
        "You are responsible for reviewing the leave request. "
        "First, call summarize_leave_request() to get a summary of "
        "the leave request. Then, pass the summary to the Leave Approver for a decision."
    ),
    llm_config=llm_config,
)

# Leave Approver Agent
leave_approver = ConversableAgent(
    name="Leave Approver",
    system_message=(
        "You are responsible for approving or rejecting the leave request. "
        "Wait for the summary from the Leave Request Reviewer and make a decision by calling "
        "approve_or_reject_leave(summary)."
    ),
    llm_config=llm_config,
)
```

leave_request_reviewer 代理负责审查请假请求。其主要任务是调用 summarize_leave_request 函数生成请假详情的摘要，然后将其传递进行进一步处理。
另一方面，leave_approver 代理负责对请假请求作出最终决定。它等待 leave_request_reviewer 提供的摘要，并使用该摘要调用 approve_or_reject_leave 函数，该函数决定是否批准或拒绝请假请求。这些代理展示了如何将任务分配给不同的实体，每个实体都有特定的责任，以简化和自动化工作流程。




We will then register the tools with the agents:

```python
from autogen import register_function

register_function(
    summarize_leave_request,
    caller=leave_request_reviewer,
    executor=leave_request_reviewer,
    name="summarize_leave_request",
    description="Summarizes the leave request."
)

register_function(
    approve_or_reject_leave,
    caller=leave_approver,
    executor=leave_approver,
    name="approve_or_reject_leave",
    description="Makes a decision to approve or reject the leave request based on the summary."
)
```

对于 summarize_leave_request 函数，它被注册到 leave_request_reviewer 代理，使得该代理可以调用和执行此函数。同样地，approve_or_reject_leave 函数被注册到 leave_approver 代理。通过将这些函数注册为工具，代理能够在工作流程中执行其指定的任务，使它们能够自主处理并对请假请求做出决策。最后，我们有代码来运行多代理系统：

```python
summary_result = summarize_leave_request()
decision_result = approve_or_reject_leave(summary_result)

print(f"Summary: {summary_result}")
print(f"Decision: {decision_result}")
```

首先，调用 `summarize_leave_request` 函数以生成请假请求的摘要。然后将此摘要传递给 `approve_or_reject_leave` 函数，该函数根据摘要信息确定是否应批准或拒绝请假。函数的结果分别存储在 `summary_result` 和 `decision_result` 中，然后将其打印出来以显示请假请求的摘要和最终决定。此手动模拟演示了整个过程如何逐步执行，从而清晰了解代理及其相关工具如何交互以处理请假请求。然后我们得到以下输出：

摘要：IT部门的员工John Doe已请求从2024年10月1日至2024年10月5日的5天年假，原因是度假。剩余假期余额为10天。状态为待批准。

决定：批准：由于符合公司政策，请假请求已被批准。

群聊

AutoGen中的群聊指的是一个系统，其中多个代理通过自动化聊天框架协作执行任务。此功能为这些代理提供了一个动态和互动的环境，使其能够相互沟通以集体解决复杂任务。我们将查看一个用于Web聊天的代码示例。它将用于自动化处理客户支持票据的过程，方法是与专业代理进行群聊。代理将合作以理解问题，提出潜在的解决方案，并确定最佳行动方案。

我们首先进行以下设置：

```python
import autogen

llm_config = {"model": "gpt-4o-mini", "cache_seed": 42}

user_proxy = autogen.UserProxyAgent(
    name="Customer_Service_Rep",
    system_message="A human customer service representative.",
    code_execution_config={
        "last_n_messages": 2,
        "work_dir": "support_chat",
        "use_docker": False,
    },
    human_input_mode="TERMINATE",
)
```

system_message 属性提供上下文，表明该代理代表人类角色。code_execution_config 字典指定代理将考虑对话中的最后两条消息，并将在 "support_chat" 目录中操作。我们随后指出将不使用 Docker。然后，human_input_mode 被设置为 "TERMINATE"，这意味着代理的交互将在完成任务或满足某个条件时结束。

我们为技术支持专家和产品专家创建代理：

```python
tech_support = autogen.AssistantAgent(
    name="Tech_Support",
    system_message="An expert in technical troubleshooting.",
    llm_config=llm_config,
)

product_expert = autogen.AssistantAgent(
    name="Product_Expert",
    system_message="Knowledgeable in all product features and user issues.",
    llm_config=llm_config,
)

groupchat = autogen.GroupChat(
    agents=[user_proxy, tech_support, product_expert],
    messages=[],
    max_round=12
)
manager = autogen.GroupChatManager(
    groupchat=groupchat,
    llm_config=llm_config
)
```

GroupChat 实例与这些代理一起初始化，并且消息列表为空，表示聊天将从无先前对话历史开始。max_round 参数设置为 12，将对话限制为 12 轮。此聊天由 GroupChatManager 管理，该管理器协调代理之间的交互。最后，我们初始化聊天：

```python
user_proxy.initiate_chat(
    manager,
    message="A customer reported that the software crashes during the export function. Investigate and provide a resolution."
)
```



然后，将与不同的代理进行广泛的往返交流，以解决客户服务问题。

Web 搜索代理

在以下示例中，我们将展示如何使用 AssistantAgent 和 UserProxyAgent 进行网页检索。
AssistantAgent 是一个基于 LLM 的代理，可以编写 Python 代码。在我们的示例中，我们将使用它来抓取一个网站。
接下来，UserProxyAgent 是一个代理，它在执行 AssistantAgent 编写的代码时充当用户的代理。根据 human_input_mode 的设置，UserProxyAgent 可以从用户那里接收对 AssistantAgent 的反馈。如果 human_input_mode 是“TERMINATE”，那么 UserProxyAgent 将执行代码并返回执行结果（成功/失败）。如果有用户反馈，则 UserProxyAgent 会将其传递回 AssistantAgent。
以下是代码：

```python
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config=llm_config,
)

user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="TERMINATE",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={
        "work_dir": "web",
        "use_docker": False,
    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.
    llm_config=llm_config,
    system_message="""Reply TERMINATE if the task has been solved at full satisfaction.
Otherwise, reply CONTINUE, or the reason why the task is not solved yet.""",
)
```

Then we need to call the function initiate_chat() on the
UserProxyAgent to initiate the chat:

```python
user_proxy.initiate_chat(
    assistant,
    message=(
        "What this article is about: "
        "https://pureai.com/Articles/2024/03/01/autogen.aspx"
    ),
)
```

这将在每条消息的结尾提示用户是否要在助手代理发送“终止”信号时提供反馈。如果用户直接按下回车键，对话将立即结束。
使用此功能的优点是由 UserProxyAgent 生成的网页抓取器将识别网页的内容和结构，并修改需要在网页上抓取的代码。
图 7-2 显示了输出。


**图 7-2.** _这是 Web 搜索代理的最终输出_

检索增强生成（RAG）

我们将创建一个使用检索增强生成（RAG）的程序。场景将是通过将 LLM 与文档检索结合起来，协助企业家制定有效的商业计划。该程序初始化了两个代理：一个助手代理，旨在充当经验丰富的商业顾问，以及一个代理检索代理，负责获取相关的商业文档。检索代理访问特定资源，包括商业计划模板和来自可靠来源的指南，以确保助手提供准确的文档支持的建议。


Here’s the setup code:

```python
from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent
from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent

llm_config = {
    "model": "gpt-4o-mini",
    "timeout": 600,
    "cache_seed": 42
}
```

首先导入所需的模块，包括 RetrieveAssistantAgent 和 RetrieveUserProxyAgent，它们负责处理用于文档检索的助手代理和代理代理。llm_config 定义了语言模型的配置，指定使用“gpt-4o-mini”模型，设置超时为600秒，并添加“cache_seed”以确保可重复性。然后我们初始化助手代理：

```python
assistant = autogen.AssistantAgent(
    name="business_assistant",
    system_message="You are an experienced business consultant helping entrepreneurs.",
    llm_config=llm_config,
)
```

system_message 设置助手的角色和交互语调。
llm_config 被传递给代理以指定 LLM 和其他配置细节。
接下来，我们使用检索代理代理从互联网上获取与业务相关的文档：

```python
ragproxyagent = RetrieveUserProxyAgent(
    name="business_ragproxyagent",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=3,
    retrieve_config={
        "task": "business",
        "docs_path": [
            "https://www.sba.gov/business-guide/plan-your-business/write-your-business-plan",
            "https://www.score.org/resource/business-plan-template-startup-business",
            os.path.join(os.path.abspath(""), "..", "business_docs"),
        ],
    },
    code_execution_config=False  # No code execution for this business task
)
```

human_input_mode 设置为不需要人工干预，max_consecutive_auto_reply 允许代理自动响应多达三次，然后才需要进一步操作。retrieve_config 定义任务为“business”，并指定文档路径列表，包括外部 URL 和本地路径，代理可以从中检索与业务相关的信息。这些信息来自小企业管理局（SBA）。code_execution_config 设置为“False”，表示此任务无需代码执行，因为重点纯粹是为了商业咨询目的而进行文档检索。我们指定业务问题：

```python
business_problem = (
    "How can I create an effective business plan for a small retail store, "
    "and what should I include in the financial projections?"
)
```

Finally, we initiate the retrieval and conversation with the
assistant agent:

```python
ragproxyagent.initiate_chat(
    assistant,
    problem=business_problem,
    search_string="business plan, financial projections"
)
```

调用 ragproxyagent 上的 initiate_chat 方法，这将提示检索代理开始协助助手提供解决方案的过程。助手将利用检索到的文档和资源来帮助回答定义的 business_problem，该问题在这种情况下涉及创建有效的商业计划和提供财务预测。search_string 参数通过指定相关关键字（如“商业计划”和“财务预测”）进一步缩小检索的焦点，引导代理找到这些主题的适当资源。
运行此命令时，您将获得一个输入框以输入提示。您可以输入如下内容：
对于零售店的商业计划，撰写执行摘要。
然后 RAG 系统将搜索文档并提供响应。

使用 Ollama

您可以将本地 LLM 与 AutoGen 一起使用。对此的一种常见方法是使用 Ollama。
首先，您将为在本地运行的 Code Llama 模型创建配置列表，其中将包括模型运行所在的本地服务器的基本 URL（“http://localhost:11434/v1”）和 API 密钥：

```python
config_list = [
    {
        "model": "codellama",
        "base_url": "http://localhost:11434/v1",
        "api_key": "ollama",
    }
]
```

Then we can create an assistant that uses the local model
configuration:

```python
assistant = autogen.AssistantAgent(
    name="assistant",
    llm_config={"config_list": config_list}
)

user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    code_execution_config={"work_dir": "coding", "use_docker": False}
)

user_proxy.initiate_chat(
    assistant,
    message="Write a Python script to scrape the latest headlines from a news website like BBC."
)
```

AutoGen Studio

AutoGen Studio 是一款强大的工具，旨在帮助您以低代码方式创建生成式AI代理。您可以通过以下链接访问AutoGen Studio：

https://autogen-studio.com

首先，请确保您已安装Python 3.11或更高版本。您可以使用Conda轻松安装Python，Conda可通过以下链接获取：

https://anaconda.org/anaconda/conda

接下来，由于AutoGen Studio依赖于OpenAI的LLM，您将需要一个OpenAI API密钥。如果您使用微软Azure，也可以使用来自Azure的API密钥。
现在让我们看看如何设置您的环境。在Windows和macOS上，打开终端或命令提示符并运行以下命令：

```sh
conda create -n autogenstudio python=3.11

# Activate the environment:
conda init
conda activate autogenstudio

# Set up your OpenAI API key. On macOS or Linux:
export OPENAI_API_KEY=XXXX

# On Windows:
set OPENAI_API_KEY=XXXX

# Install the AutoGen Studio:
pip install autogenstudio

# Launch it:
autogenstudio ui
```
启动后，将提供的URL复制到浏览器以访问UI。图7-3显示了初始屏幕。



**图 7-3.** _这是 AutoGen Studio 的初始屏幕_

在屏幕的左上角，你有两个选项：
- 构建：在这里你可以创建你的AI代理。
- 操作台：此部分允许你测试和实验你的代理。
我们先来看构建。在屏幕的左侧，有各种菜单项。其中一个是技能。这让你可以为特定任务创建Python函数。你可以使用现有的函数，比如生成和保存图像或PDF，或者创建新的。当你定义这些技能时，相应的Python代码会自动生成和更新。你甚至可以将这段代码复制并粘贴到自己的IDE中。
在屏幕的右上角，你可以选择新技能。这让你可以创建自定义技能。
图7-4显示了这个屏幕。


**图 7-4.** _这允许你创建自定义技能_

你可以为其提供一个名称和描述，描述是一个提示，告诉LLM该做什么。然后你可以输入你想使用的LLM。当你输入这些参数时，左侧的代码会被更新。
所以对于名称，我输入tweet_creator，然后对于描述，我输入了“创建一个有趣的推文”。然后我点击保存技能。
下一个菜单选项是模型。是的，在这里你可以指定你想要使用的LLM。AutoGen Studio支持几个预配置的模型，如GPT-4。或者，你可以添加一个不在列表中的模型。你可以通过选择新模型并输入信息（如模型名称和API密钥）来完成此操作。然后你可以点击测试模型以查看是否有连接。图7-5显示了这对于gpt-4o的情况。

**图 7-5.** _这显示了新模型的选择_

接下来，我们有代理菜单项。通过这个，我们可以为你的工作流程配置一个代理。有不同的选项，比如用于规划的代理和用于语言助手的代理。你可以在图7-6中看到这些。

**图 7-6.** _这些是默认代理_

你可以通过选择新代理创建自定义代理。你有不同的模板。它们是

用户代理：这代表一个用户并执行代码。
助手代理：这是用于规划和生成代码以解决问题。
群聊：这是用于管理群聊交互。
最后，是工作流程的菜单项。在这里你可以连接多个代理以创建复杂的多代理交互。例如，你可以构建一个用于旅行规划的工作流程，其中各种代理进行通信和协作。
有了我们的代理，我们可以在操作台中测试它。我们将选择新建，这将创建一个会话。
然后你将选择工作流程的类型。我将选择默认的。
然后我将点击创建。
图7-7显示了这个屏幕。

**图 7-7.** _这是操作台的会话_

然后你可以通过编写提示或使用预定义的提示来测试它。

Conclusion

AutoGen 提供了一个强大的框架，用于构建多代理系统，这些系统可以在广泛的应用中高效地解决复杂任务。从生成引人入胜的社交媒体内容到自动化审批工作流，AutoGen 使开发人员能够创建紧密合作以实现精确结果的高度专业化代理。该平台的模块化和灵活性允许自定义工具的无缝集成、代理之间的增强协作以及处理各种场景的能力。随着多代理系统开发的不断发展，AutoGen 作为一个开创性的框架脱颖而出，为开发人员带来了强大的功能。


© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 179

https://doi.org/10.1007/979-8-8688-1134-0_8

**CHAPTER 8**

**LangChain**

LangChain 是一个开源框架，旨在简化由大型语言模型（LLM）驱动的应用程序的开发。它通过提供一整套工具、组件和预构建链来解决使用 LLM 的复杂性，使开发人员能够高效地创建复杂的、上下文感知的 AI 应用程序。LangChain 促进了 LLM 与外部数据源和计算资源的无缝集成。这允许更动态和交互的 AI 体验。

对于希望在 LangGraph 框架内创建 AI 代理的开发人员来说，了解 LangChain 是非常重要的。LangGraph 构建在 LangChain 之上，通过结合高级基于图的模型来扩展这些基础功能，从而增强 AI 代理的逻辑结构和决策过程。它允许开发人员创建能够导航复杂决策树、管理复杂状态转换和优化任务执行的代理，以更结构化和高效的方式进行操作。如果没有对 LangChain 的牢固掌握，开发人员可能会发现难以充分利用 LangGraph 的高级功能。

这种相互依赖性在 CrewAI 等框架中也很明显，我们将在第 6 章中介绍。它同样基于 LangChain 提供 AI 代理开发的专业能力。

虽然 LangChain 本身提供了创建 AI 代理的强大工具，实现了提示工程、数据集成和多代理协调等功能，但像 LangGraph 和 CrewAI 这样的框架将这些能力提升到了一个新的水平。它们允许更专业和高性能的应用程序，使 LangChain 成为任何从事此领域工作的开发人员的基础技能。理解 LangChain 的细微差别不仅可以使开发人员能够构建有效的 AI 代理，还可以使他们能够利用依赖其核心原则的更高级框架。

LangChain 适用于 Python 和 JavaScript。但在本书中，我们将专注于 Python。

Background

Harrison Chase 开发了 LangChain，以解决 AI 开发人员在构建基于 LLM 的应用程序时常遇到的挑战。创建这些应用程序的过程通常复杂、繁琐且耗时，需要集成各种组件和提示。LangChain 的设计初衷是通过允许开发人员将多个提示和组件“链接”在一起，简化这一过程，从而简化开发过程，并减少创建强大的 AI 驱动应用程序所需的时间和精力。协调 LLM 应用程序中不同元素的能力是其一大特色，这也是为什么 LangChain 常被称为编排工具。

LangChain 的发展与生成式 AI 的爆炸性兴趣相呼应，尤其是在 OpenAI 的 ChatGPT 于 2022 年 11 月底推出后。ChatGPT 展示了生成式 AI 的非凡能力，在短短几个月内迅速获得了超过 1 亿用户。当开发人员寻求利用这些大型语言模型的强大功能时，LangChain 成为了一种关键框架，它提供了一种更高效和结构化的方法来构建和扩展基于 LLM 的应用程序。

该框架的崛起反映了对能够简化和增强生成式 AI 应用程序开发的工具需求的增长，使其成为全球 AI 开发人员的重要资源。目前，LangChain 平均每月下载量超过 1500 万次。它还支持超过 10 万个应用程序，这个开源项目拥有超过 75 颗星，并且有超过 3000 名贡献者。其客户包括 The Home Depot、Instacart 和 Moody’s。^1

让我们来看看一个案例研究。它是关于 Ally Financial，这是一家美国的数字银行，拥有超过 1100 万客户。^2 该公司运营 Ally.ai，这是一个为 700 多名客户服务助理提供帮助的 AI 平台。该技术处理诸如总结对话等任务。

然而，由于金融服务行业的严格法规，Ally 需要一种方法来保护客户信息。该公司通过利用 LangChain 构建一种工具来屏蔽 PII（个人身份信息）来实现这一目标。Ally 有五名工程师在这个项目上工作了两个月。

结果非常显著。该系统每通电话节省了 2 分钟 30 秒，并且多达 85% 的通话摘要无需额外编辑。

The Components

LangChain 的一个关键优势在于其模块化。该框架由多个组件组成，每个组件都设计用于处理 AI 开发的特定方面。这种模块化方法允许开发人员根据其特定需求混合和匹配组件，使其能够构建从简单聊天机器人到能够进行复杂决策的复杂 AI 代理的各种应用程序。无论您是想创建一个可以进行多轮对话的模型、从外部来源检索信息，还是自主执行一系列任务，LangChain 都提供了实现您愿景所需的构建模块。在接下来的几节中，我们将仔细看看这些组件。

Models

聊天模型是 LangChain 的基本组件，专为处理对话而设计，通过将聊天消息作为输入并返回聊天消息作为输出，而不仅仅是处理纯文本。这使它们特别适合构建交互式和动态的 AI 驱动应用。LangChain 提供与多种模型提供商的强大集成，包括 OpenAI、Cohere 和 Hugging Face，确保开发人员可以通过标准化接口无缝地与不同模型交互。
除了基本功能，LangChain 通过支持多种操作模式（如同步、异步、批处理和流处理）增强了聊天模型的可用性。这种灵活性允许开发人员根据具体用例选择最佳模式，无论是实时交互还是处理大批量数据。此外，LangChain 提供了诸如缓存等附加功能，可提高应用的性能并减少延迟。
让我们来看一下如何使用聊天模型。首先，我们需要进行一些设置：

pip install langchain

```python
import openai
import os
import getpass

os.environ["OPENAI_API_KEY"] = getpass.getpass()
```

此代码片段旨在设置使用 OpenAI 的 API 的 LangChain 所需的环境。第一条命令 pip install langchain 会安装 LangChain 库。接下来的代码部分导入了必要的库，包括用于与 OpenAI 的模型交互的 openai，处理环境变量的 os，以及用于安全捕获 API 密钥等敏感信息的 getpass。os.environ["OPENAI_API_KEY"] = getpass.getpass() 提示用户安全地输入他们的 OpenAI API 密钥，而不会在屏幕上显示。然后这个密钥被存储为环境变量，使得代码可以在不暴露密钥的情况下认证对 OpenAI API 的请求。
然后我们有以下代码：

```python
from langchain_openai import ChatOpenAI

chat_model = ChatOpenAI(model="gpt-4o")
output = chat_model.invoke("What is LangChain?")
print(output.content)
```

从 langchain_openai 导入 ChatOpenAI 这一行从 langchain_openai 模块中导入了 ChatOpenAI 类，该类旨在简化与 OpenAI 语言模型的聊天式交互。
通过使用 chat_model = ChatOpenAI(model="gpt-4o") 实例化 ChatOpenAI，代码创建了一个配置为使用 OpenAI 的 GPT-4 "gpt-4o" 版本的聊天模型实例。此模型可以处理基于聊天的查询。invoke 方法用于向模型发送问题，在这种情况下是“什么是 LangChain？”。模型处理输入并生成响应，然后将其存储在 output 变量中。最后，print(output.content) 用于显示模型的响应，展示了聊天模型生成有意义且具有上下文相关的回复的能力。

Prompt Templates

LangChain 中的 ChatPromptTemplate 是一种工具，旨在简化为 LLM 生成动态提示的过程。此模板类允许开发人员创建灵活且可重用的提示结构，其中可以定义占位符，并在运行时用特定值填充。这在提示的内容需要根据用户提供的上下文或输入而更改的情况下特别有用。以下是一个代码示例：

```python
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template(
    "List 3 benefits of using this technology:\n{technology}"
)

formatted_prompt = prompt.format(technology="blockchain")
response = llm(formatted_prompt)

print(response.content)
```

该过程首先通过从 langchain_core.prompts 导入 ChatPromptTemplate，允许用户定义具有占位符（例如 {technology}）的模板，这些占位符可以在稍后用特定值填充。
在示例中，创建了一个提示模板，句子是“列出使用该技术的3个好处：{technology}。” 然后使用 format 方法将占位符 {technology} 替换为“区块链”，生成一个完全自定义的提示。此格式化后的提示传递给 LLM 以生成响应。最后，使用 print(response.content) 打印出包含 AI 生成文本的响应内容。

Output Parsers

输出解析器在将 LLM 生成的输出转换为更结构化和可用的格式方面发挥着重要作用。当任务涉及生成结构化数据（例如 JSON、XML 或 CSV 文件）时，此功能尤为重要。LangChain 提供了多种输出解析器，每种解析器旨在处理不同类型的输出和格式，确保生成的数据既准确又易于解释。
LangChain 的输出解析器的一个显著特点是支持流式处理，这允许在 LLM 生成数据时对其进行实时处理和格式化。此外，其中许多解析器附带格式说明，以确保输出符合指定的架构，尽管在架构定义在提示之外的情况下存在例外。一些输出解析器，尤其是那些处理复杂或可能出错的输出的解析器，甚至可以回调 LLM 以纠正任何格式错误的数据，从而进一步提高生成输出的可靠性和精确性。此功能使 LangChain 的输出解析器成为开发人员使用 LLM 从 AI 生成内容创建结构化、可操作数据的高度通用的工具。
我们将通过一个输出解析器的代码示例来了解这一点。这将通过使用 Pydantic 定义的自定义数据结构来实现。也就是说，我们可以确保 LLM 生成的内容被组织成特定的字段，例如产品名称、评分和评论详细信息。为此，我们将使用 JsonOutputParser。

First, we have some setup:
```python
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
# Initialize the ChatOpenAI model
model = ChatOpenAI(temperature=0)
```

我们导入了 JsonOutputParser 和 PromptTemplate。接着，我们
从 Pydantic 导入了 BaseModel 和 Field。我们将使用这些来定义
一个结构化的数据模型，以确保输出符合特定的数据类型和格式，
例如产品名称的字符串类型和评分的整数类型。之后，我们创建了
一个 OpenAI LLM 的实例。
然后我们创建这个类：

```python
# Define the desired data structure for the product review
class ProductReview(BaseModel):
    product_name: str = Field(description="The name of the product being reviewed")
    rating: int = Field(description="The rating given to the product, out of 5")
    review_text: str = Field(description="The text of the review")
    pros: str = Field(description="The positive aspects mentioned in the review")
    cons: str = Field(description="The negative aspects mentioned in the review")
```

此代码片段使用 Pydantic 的 BaseModel 定义了一个 ProductReview 类。 类的每个属性——例如 product_name、rating、review_text、pros 和 cons——都使用特定的数据类型（例如，“str”表示字符串，“int”表示整数）定义，并伴随着一个描述性字段。这些描述说明了每个字段的预期内容，确保当语言模型生成评论时，输出符合此预定义格式。

我们使用 ProductReview 类定义的自定义数据结构初始化一个 JsonOutputParser：

```python
parser = JsonOutputParser(pydantic_object=ProductReview)

prompt = PromptTemplate(
    template="Provide a detailed product review based on the user's input.\n{format_instructions}\n{query}\n",
    input_variables=["query"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)
```

模板字符串包含占位符 {format_instructions} 和 {query}，其中前者会被 JsonOutputParser 提供的关于如何根据 ProductReview 模型格式化输出的说明动态填充。input_variables 参数指定提示将接受用户提供的查询作为输入。通过将提示与格式说明和用户的查询结合起来，此设置确保 LLM 生成的输出既相关又根据预定义格式进行结构化，从而更容易解析并用于下游任务。
我们定义 LLM 生成产品评论的查询：

review_query = "请评论最新的智能手机型号 XYZ。"

我们将提示、模型和解析器链接在一起：

```
chain = prompt | model | parser
```

这使用了 LangChain 表达式语言 (LCEL)，开发人员使用它来构建和管理复杂的 AI 工作流。LCEL 提供了一种声明性的方式来组合 LangChain 组件，从而实现更直观和灵活的应用程序设计。借助 LCEL，开发人员可以轻松地将各种 LangChain 组件连接在一起，创建能够处理复杂任务的复杂管道，同时保持可读性和模块化。
在我们的代码示例中，管道运算符 (|) 允许您将不同的组件连接在一起——首先是生成提示的 PromptTemplate，将其传递给语言模型 (ChatOpenAI)，然后将模型的输出传递给 JsonOutputParser 进行结构化处理。LCEL 中的管道运算符创建了一个无缝且直观的数据流，从一个组件到下一个组件，增强了可读性并减少了对复杂样板代码的需求。
我们运行以下命令：

```python
parsed_review = chain.invoke({"query": review_query})
```

在这里，chain.invoke() 使用包含输入变量的字典调用，在本例中为 {"query": review_query}。
然后我们打印出响应，这将显示 JSON 输出：

print(parsed_review)

文档加载器

文档加载器允许从各种来源导入数据，并将其转换为称为文档的标准化格式。文档本质上是伴随元数据的一段文本，例如来源、创建日期或其他相关细节。这种统一格式允许进行一致的处理和分析，而不论文本的来源如何。文档加载器功能多样，可以处理一系列数据源，包括 .txt 文件、网页内容，甚至是 YouTube 视频的转录，使得将多样化的文本数据集成到 LangChain 工作流中变得简单。每个文档加载器都配备了一个加载方法，该方法促进从指定来源将数据转换为可以在工作流中使用的文档。此外，一些加载器提供“惰性加载”功能，仅在必要时加载数据，从而为较大的数据集优化内存使用。在处理不需要一次完全加载的庞大数据源时，此功能尤其有用。下面是如何使用文档加载器读取 CSV 文件内容的示例：

```python
from langchain_community.document_loaders.csv_loader import
CSVLoader
from tabulate import tabulate
```

CSVLoader 类旨在简化 CSV 文件的加载和处理。然后我们导入 tabulate 库。您还需要使用 pip install tabulate 来安装它。此库用于格式化和显示表格数据。
然后我们加载 CSV 文件并准备数据：

```python
loader = CSVLoader(file_path='books_output.csv', source_column="Book Title")
data = loader.load()
table_data = []
headers = ["Book Title"]
```

通过将 file_path 参数指定为 books_output.csv，并使用 source_column 参数为“Book Title”，该代码确保从 CSV 文件生成的每个文档都基于书名关联一个唯一标识符。
一旦数据加载完成，代码使用 tabulate 库准备数据以供显示。table_data 列表被初始化以保存格式化的数据，headers 被设置为 ["Book Title"] 以定义表格的列名。


Then we display the information:
```python
for document in data:
    table_data.append([document.metadata['source']])

print(tabulate(table_data, headers=headers, tablefmt="grid"))
```

for 循环遍历数据列表中的每个文档，该列表先前已使用 CSVLoader 从 CSV 文件中加载。对于每个文档，循环从 metadata['source'] 属性中提取书名，并将其附加到 table_data 列表中。
在收集完所有书名后，代码使用 tabulate 库将数据打印为格式整齐的表格。调用 tabulate 函数时传递了 table_data、headers 和 tablefmt="grid" 作为参数。headers 包含列名（“Book Title”），而 tablefmt="grid" 指定表格格式样式，使表格呈现网格状外观。

Text Splitters

在 LangChain 中处理长文档时，通常需要将其拆分为更小、更易于管理的部分。这一过程称为文本拆分，因为它确保文本适合模型的上下文窗口，从而实现高效的处理和分析。LangChain 提供了多种内置工具，允许用户根据特定的应用需求拆分、合并、过滤和操作文档。
文本拆分比看起来更复杂。目标是保持文本的语义完整性，将相关信息片段保留在一起。根据所处理文本的类型，“语义相关”可能有所不同。例如，在某些情况下，可能需要保持整句话或段落完整，而在其他情况下，可能需要更细粒度的拆分方法。LangChain 提供了多种方法来实现此目标，确保生成的文本块对于当前任务既有意义又有用。
在高层次上，LangChain 的文本拆分器通过首先将文本分解为较小的、语义上有意义的单位（通常在句子级别）来工作。然后将这些单位组合成更大的块，直到它们达到预定的大小，基于特定的测量标准。一旦块达到所需大小，它就被视为单独的文本片段，并开始新的块，有时为了在块之间保持上下文而包含重叠的内容。这个过程可以沿两个主要方向进行定制：文本如何最初拆分以及如何测量每个块的大小。
LangChain 提供了多种文本拆分器，每种都针对不同类型的文本和拆分需求而设计。例如，有些拆分器专注于特定字符或标记，以及针对特定格式（如 HTML 或 Markdown）的拆分器。更高级的拆分器，如 RecursiveCharacterTextSplitter 或 AI21SemanticTextSplitter，旨在通过递归拆分或识别文本中的不同主题来保持语义相关的文本在一起。像 Chunkviz 这样的工具可以帮助可视化这些拆分器的操作，使得更容易微调拆分过程以满足您的特定要求。
文本拆分只是 LangChain 中众多文档转换功能之一，还有其他工具可用于集成第三方服务和在文档被语言模型处理之前执行其他修改。
让我们看一个例子。HTMLHeaderTextSplitter 是一个专门的工具，旨在通过在元素级别（如标题）进行拆分来处理 HTML 内容，同时保留重要的结构信息。对于结构对于保持上下文至关重要的文档（如网页或结构化报告），这个拆分器特别有用。通过基于 HTML 标题拆分文本，拆分器不仅将内容分为可管理的块，还为每个标题添加元数据，使得更容易将相关的文本部分保留在一起并维护它们的语义意义。


We have some setup code:
pip install lxml

```python
from langchain_text_splitters import HTMLHeaderTextSplitter
```

要在 Python 中处理 HTML 内容，您可能需要安装“lxml”库，这是一个用于解析和操作 HTML 和 XML 文档的强大且高效的工具。安装后，您可以将其与 langchain_text_splitters 模块中的 HTMLHeaderTextSplitter 等工具结合使用。这个拆分器允许您通过特定的标题标签（如“<h1>”、“<h2>”等）将 HTML 内容分段，从而更容易分析和操作 HTML 文档中的结构化文本。
然后我们读取 HTML 文件：

```python
with open('sample_document.html', 'r', encoding='utf-8') as file:
    html_string = file.read()
```
此代码以读取模式（“r”）和 UTF-8 编码打开文件 sample_document.html，确保正确解释任何特殊字符。使用 with open(...) 结构打开文件，确保即使出现错误，文件也能在读取后正确关闭。file.read() 方法将文件的全部内容读取到变量 html_string 中，之后可以用于进一步处理，例如解析或拆分 HTML 内容。
接下来，我们定义要拆分的标题：

```python
headers_to_split_on = [
("h1", "Header 1"),
("h2", "Header 2"),
("h3", "Header 3"),
]
```

Then we work with the data:
```python
html_splitter = HTMLHeaderTextSplitter(headers_to_split_
on=headers_to_split_on)
html_header_splits = html_splitter.split_text(html_string)
print(html_header_splits)
```

首先，创建一个 HTMLHeaderTextSplitter 实例，并使用 headers_to_split_on 列表中定义的标题进行配置。该列表指定了哪些 HTML 标签（例如 “<h1>”，“<h2>”，“<h3>”）应作为文本拆分的断点。然后，调用 html_splitter 对象的 split_text 方法，并传入包含 HTML 内容的 html_string。此方法处理 HTML 内容，并在指定标题出现的地方将其划分为多个片段。生成的片段存储在 html_header_splits 中，然后打印出来以显示 HTML 文档的拆分部分。这种方法对于从 HTML 文件中提取和组织结构化内容非常有用，使分析或进一步操作数据更加容易。

Memory

在大多数 LLM 应用中，交互界面是关键，允许系统与用户进行有意义的对话。任何对话的重要方面是能够引用之前讨论中共享的信息。至少，一个对话系统应能够访问过去消息的一部分。对于更高级的系统，必须拥有一个不断更新的世界模型，以跟踪整个对话中的实体及其关系。

这种保留和利用先前交互信息的能力称为记忆。LangChain 提供了众多工具来将记忆整合到系统中。这些工具可以独立运行或顺利集成到一系列流程中。然而，LangChain 中的许多与记忆相关的功能目前仍处于测试阶段，因为它仍在开发中，可能尚不适合生产环境。大多数此类功能也在使用传统链而非 LCEL 语法。
一个显著的例外是 ChatMessageHistory 功能，它基本上已准备好投入生产并与 LCEL 兼容。ChatMessageHistory 允许系统存储和检索过去的消息，从而在交互中保持上下文。此功能支持读取和写入操作，这意味着系统可以根据之前的交互增强用户输入，并存储新交互以供将来参考。
在构建记忆系统时，必须做出两个主要设计决策：如何存储状态（或记忆）以及如何查询它。任何记忆系统的核心都是聊天交互的历史。这些交互需要存储，无论是内存中还是持久存储如数据库中。LangChain 的记忆模块提供了一系列用于管理聊天消息存储的集成，从简单的内存列表到更强大的数据库解决方案。
一旦消息被存储，挑战在于如何有效地查询这些存储的信息。一个基本的记忆系统可能返回最近的消息，而一个更复杂的系统可以总结过去的交互或提取先前对话中提到的特定实体。LangChain 的记忆模块旨在灵活，允许开发人员从简单的记忆系统开始，并根据特定应用的需要对其进行自定义。
让我们看一个使用记忆的代码示例。这将是一个设计用于记住用户职业目标和先前讨论的聊天机器人，帮助在未来的互动中提供更个性化的建议。


We will start with preliminary setup:
```python
from langchain_core.messages import SystemMessage
from langchain_core.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import LLMChain
```

我们导入了多种 LangChain 模板，如 SystemMessage、ChatPromptTemplate 和 HumanMessagePromptTemplate。 这些模板通过设置系统范围的上下文和定义用户输入的整合方式，帮助构建对话提示。 MessagesPlaceholder 用于将对话历史插入提示中，以实现交互的连续性。 ChatOpenAI 表示用于生成响应的基于聊天的语言模型，而 ConversationBufferMemory 管理之前聊天消息的存储，使模型能够引用过去的交互。 最后，LLMChain 将这些组件结合在一起，创建一个功能链，处理用户输入，通过记忆保持上下文，并在对话中生成连贯的响应。 然后我们设置聊天提示：

```python
prompt = ChatPromptTemplate.from_messages([
    SystemMessage(
        content="You are a career coach chatbot, helping users with their career goals."
    ),  # The persistent system prompt
    MessagesPlaceholder(
        variable_name="chat_history"
    ),  # Where the memory will be stored
    HumanMessagePromptTemplate.from_template(
        "{human_input}"
    ),  # Where the human input will be injected
])
```

此代码片段构建了一个用于聊天机器人的 ChatPromptTemplate，该机器人旨在充当职业顾问。SystemMessage 设置了一致且持久的上下文，表明聊天机器人的角色是帮助用户实现职业目标。MessagesPlaceholder 用于插入聊天历史记录，使聊天机器人能够在对话中记住和引用之前的互动。最后，HumanMessagePromptTemplate 被配置为动态注入用户的当前输入到提示中，确保聊天机器人能够在维护会话整体上下文的同时对每条新消息做出适当回应。此设置使聊天机器人能够提供个性化和上下文感知的职业建议。接下来，我们初始化内存以跟踪对话历史，然后初始化 OpenAI 模型：

```python
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

llm = ChatOpenAI()

chat_llm_chain = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True,
    memory=memory,
)
```

We then simulate a conversation, to see how the memory works with
the chatbot:
```python
response = chat_llm_chain.predict(human_input="I'm thinking about switching careers to data science.")
print(response)

response = chat_llm_chain.predict(human_input="What skills do I need to develop for a data science role?")
print(response)

response = chat_llm_chain.predict(human_input="I have started learning Python. What should I focus on next?")
print(response)
```

第一行将用户的输入“我正在考虑转行到数据科学”发送给聊天机器人，响应存储在response变量中并打印出来。这开启了对话，并为未来的互动设定了上下文。第二行通过询问“我需要发展哪些技能才能胜任数据科学角色？”继续对话。同样，聊天机器人基于当前输入和先前的上下文生成响应，也被打印出来。最后，第三行进一步发展讨论，指出“我已经开始学习Python。接下来我应该专注于什么？”聊天机器人记住了之前的交流，提供了针对用户持续进入数据科学旅程的建议，响应被打印。每个步骤都展示了聊天机器人如何利用记忆来提供越来越个性化和上下文感知的职业建议。

Key Concepts of LangChain Agents

在 LangChain 中创建 AI 代理涉及几个关键概念和组件，这些概念和组件允许在 AI 系统内进行动态决策和交互。LangChain 中的代理使用语言模型动态确定操作顺序。
以下是核心概念：

- AgentAction：这是一个关键组件，定义了 AI 代理在特定步骤应执行的操作。每个 AgentAction 包含代理应调用的工具和应传递给该工具的输入。这使代理能够与各种工具（如 API 或数据库）进行交互，并根据需要检索或操作数据。
- AgentFinish：当代理完成任务并准备返回结果时，它使用 AgentFinish 组件。此组件包含代理的最终输出，通常是结构化的键值映射。输出通常是一个字符串，表示代理对用户的最终响应，封装了交互期间采取的所有步骤。
- Intermediate Steps：这些表示代理当前运行期间的操作历史及相应的输出。通过维护此历史记录，代理可以跟踪已完成的工作，这对于确保未来步骤相关且不重复以前的工作至关重要。这表示为一个元组列表，每个元组包含一个 AgentAction 及其相关输出。

- Agent：代理本身负责根据当前上下文和迄今为止采取的中间步骤确定下一步要采取的行动。它通常依赖语言模型来做出这些决策，使用提示来编码输入，并使用输出解析器解释结果。代理可以通过不同的提示样式、输入编码和输出解析策略进行定制，以适应特定任务。
- AgentExecutor：代理执行器是代理运行的环境。它不断循环执行选择操作、执行操作和处理其输出的过程，直到代理得出结论。执行器处理复杂性，例如错误管理、工具选择和日志记录，以确保代理的顺利运行。

Types of Agents

LangChain 提供了多种代理类型，每种代理都旨在处理 AI 系统中的特定任务和工作流程。这些代理利用不同的决策和交互策略，使开发人员能够根据各种用例定制他们的 AI 解决方案。
这些代理包括工具调用代理、XML 代理、JSON 聊天代理、结构化聊天代理、ReAct 代理和自询搜索代理。

Tool Calling Agent

工具调用代理是一种多功能代理，允许 LLM 确定何时以及如何调用外部工具。通过定义一组代理可以使用的工具，模型可以根据接收到的输入智能地决定调用哪个工具。然后，代理生成结构化输出，例如 JSON 对象，指定调用这些工具所需的参数。与使用通用文本完成或聊天 API 相比，这种方法提高了工具调用的可靠性和准确性。工具调用代理支持包括 OpenAI、Anthropic、Google Gemini 和 Mistral 在内的广泛提供商，使其成为将工具使用集成到 AI 工作流程中的强大而灵活的解决方案。

XML Agent

XML 代理专为擅长使用 XML 格式进行推理和写作的 LLM（例如 Anthropic 的 Claude）而设计。当处理接受单个字符串输入的非结构化工具时，这种代理特别有用。通过将输出结构化为 XML，代理可以更有效地与某些模型和工具交互，为需要基于 XML 的推理的任务提供专业化解决方案。

JSON Chat Agent

JSON 聊天代理专为擅长生成 JSON 格式输出的语言模型而设计。当需要结构化数据交换的聊天模型时，此代理特别有用。通过使用 JSON 格式化输出，代理可以支持与聊天模型的复杂交互，从而更容易管理和处理多步骤对话或数据密集型任务。

Structured Chat Agent

结构化聊天代理能够处理多输入工具，使其在需要同时处理多条信息的场景中非常理想。这种代理类型支持更复杂的交互，允许它管理需要以结构化方式整合各种数据点或输入的任务。在代理必须根据输入组合协调多个操作或决策的应用中，这尤其有用。

Self-Ask with Search Agent

自我询问搜索代理专为需要迭代查询和信息检索的任务而设计。该代理使用自我提问的过程，即在进行必要的信息搜索之前，先自问澄清性问题以更好地理解任务。这种方法对于涉及复杂信息检索的任务或代理需要从外部来源收集数据以完成查询的情况特别有用。
接下来，我们将深入了解 ReAct 代理，并学习如何使用 LangChain 编写一个 ReAct 代理。

ReAct Agent

2022年10月，谷歌研究院和普林斯顿大学的研究人员发表了一篇题为“ReAct: Synergizing Reasoning and Acting in Language Models”的论文。^3 这确立了一种称为ReAct的新型代理，对LangChain至关重要。它旨在帮助大型语言模型（LLM）进行推理和行动以解决一般任务。
在ReAct出现之前，LLM进行这些活动的能力大多是单独研究的。但这导致了令人失望的结果。ReAct将推理和任务结合或协同起来，显著提升了代理的性能。

(^3) https://arxiv.org/abs/2210.03629



在论文中，研究人员使用了谷歌的PaLM-540B，并为其提供了特定的动作（例如“搜索”或“进入”）和推理路径（逻辑步骤或想法）来解决任务。根据任务的不同，模型在生成推理路径和动作之间交替进行，创建了解决任务的路线图或轨迹。ReAct根据新信息动态调整其计划，并与外部来源如维基百科互动以获取更多数据。使用了各种类型的推理路径，如创建行动计划、注入常识知识以及在遇到例外情况时调整计划。这样，模型不仅在思考任务，还在采取步骤解决任务。

Agent Program

该程序是一个项目管理助手，集成了任务状态检索和在线文档搜索工具。它采用结构化的方法，定义了特定工具来查询内部数据库中的任务状态或使用 DuckDuckGo 搜索相关文档。该程序利用 OpenAI 的 LLM 引导交互，输入根据自定义提示进行处理，指示代理的响应。代理能够执行诸如根据任务 ID 检索任务状态和搜索最佳实践或其他项目相关文档等操作，使其成为项目经理或团队成员快速访问任务相关信息的有用工具。
我们从以下导入开始：

```python
from langchain import PromptTemplate
from langchain.tools import StructuredTool, DuckDuckGoSearchResults
from langchain_openai import ChatOpenAI
from langchain.agents import create_tool_calling_agent, AgentExecutor
from pydantic import BaseModel
```

PromptTemplate 用于创建可定制的提示，指导语言模型的行为。StructuredTool 是一个类，允许您定义可以处理结构化输入数据的工具，从而更轻松地与特定功能或 API 交互。ChatOpenAI 是 OpenAI 语言模型的接口，使程序具备自然语言处理能力。Langchain.agents 中的 create_tool_calling_agent 和 AgentExecutor 用于创建和管理代理，使其能够根据用户输入决定何时以及如何使用定义的工具。DuckDuckGoSearchResults 提供了通过 DuckDuckGo 进行网络搜索的工具，可以集成到代理中以执行查找在线文档等任务。最后，来自 pydantic 的 BaseModel 用于定义数据模型，强制执行类型验证和结构化输入，确保工具接收正确格式的数据。
在此之后，我们定义任务状态检索工具：

```python
class TaskStatusRetriever:
    def __init__(self, task_database):
        self.task_database = task_database

    def get_status(self, task_id: str) -> str:
        return self.task_database.get(task_id, "Task not found")

task_database = {
    "task1": "In Progress",
    "task2": "Completed",
    "task3": "Not Started",
}

task_status_retriever = TaskStatusRetriever(task_database)

def task_status_lookup(task_id: str) -> str:
    return task_status_retriever.get_status(task_id)
```

此代码定义了一个 TaskStatusRetriever 类，用于模拟从项目管理数据库中检索任务状态的系统。该类使用 task_database 初始化，这是一个字典，存储任务 ID 作为键，其状态作为值。get_status 方法用于通过任务 ID 查找特定任务的状态，如果找到则返回状态，如果任务 ID 在数据库中不存在则返回“任务未找到”。task_database 字典包含具有预定义状态（“进行中”、“已完成”和“未开始”）的示例任务。task_status_retriever 对象是此类的实例，而 task_status_lookup 函数则作为接口，通过传入任务 ID 来检索任务状态，使得将此功能集成到更大型系统中变得简单。接下来，我们将定义 TaskStatusLookup 的输入模式：

```python
class TaskStatusInput(BaseModel):
    task_id: str

task_status_tool = StructuredTool.from_function(
    name="TaskStatusLookup",
    description="Look up the status of a task by its ID.",
    func=task_status_lookup,
    args_schema=TaskStatusInput
)
```

此代码使用 Pydantic 的 BaseModel 定义了一个 TaskStatusInput 类，
作为模式来强制执行任务状态查找工具输入数据的结构和类型。
TaskStatusInput 模型指定输入必须包含一个字符串类型的 task_id。
然后，使用 StructuredTool.from_function 创建 task_status_tool，
它基于 task_status_lookup 函数生成一个工具。
该工具被命名为“TaskStatusLookup”，并被描述为通过 ID 查找任务状态的工具。
通过使用 TaskStatusInput 模型作为 args_schema，工具确保其接收正确格式的输入，
从而在更大型基于 LangChain 的应用程序中促进结构化和验证的任务状态检索功能交互。
接下来，我们将使用在线文档搜索工具：

```python
duckduckgo_search = DuckDuckGoSearchResults()

def search_docs(query: str) -> str:
    return duckduckgo_search.run(query)
```

此代码初始化了一个 DuckDuckGoSearchResults 对象，它
提供了在 LangChain 应用程序中使用 DuckDuckGo
搜索引擎执行网络搜索的能力。search_docs 函数
被定义为接受一个搜索查询作为输入，由 query 字符串表示。
调用时，该函数使用 duckduckgo_search 对象通过调用其 run 方法执行
搜索，并提供查询。函数将搜索结果作为字符串返回。
我们为 DocsSearch 定义输入模式：

```python
from pydantic import BaseModel

class DocsSearchInput(BaseModel):
    query: str

docs_search_tool = StructuredTool.from_function(
    name="DocsSearch",
    description="Search for relevant documentation online.",
    func=search_docs,
    args_schema=DocsSearchInput
)
```

DocsSearchInput 模型包含一个字段 query，它是表示搜索查询的字符串。
然后使用 StructuredTool.from_function 创建 docs_search_tool，
该函数基于 search_docs 函数构建工具。
该工具被命名为“DocsSearch”，并被描述为在线搜索相关文档的工具。
通过使用 DocsSearchInput 模型作为 args_schema，工具确保输入经过验证并结构正确。
我们创建工具列表：

```python
tools = [
    task_status_tool,
    docs_search_tool
]

# Define the LLM and the prompt
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

prompt_template = """
You are a project assistant. You can look up the status of
tasks in a project management system and search for relevant
documentation online.
Respond based on the user's input using the appropriate tools.

User's input: {input}

{agent_scratchpad}
"""
prompt = PromptTemplate.from_template(prompt_template)
```

llm 变量被初始化为 ChatOpenAI 的一个实例，指定使用 OpenAI 的“gpt-4o-mini”模型。设置 temperature=0 参数以使模型的输出更加确定性，减少响应中的随机性。prompt_template 是一个字符串，定义了代理应如何表现的结构和指令。它将代理描述为能够在项目管理系统中查找任务状态和在线搜索相关文档的项目助手。模板包括 {input} 占位符用于用户输入，{agent_scratchpad} 占位符用于代理的内部推理或中间步骤。

最后，通过将 prompt_template 字符串传递给 PromptTemplate.from_template 创建 prompt 变量，该方法格式化提示以供语言模型使用。此设置确保代理通过利用语言模型和定义的工具，恰当地响应用户查询。然后我们创建代理以及代理执行器。接着，我们进行测试并创建响应：

```python
agent = create_tool_calling_agent(llm, tools, prompt)

agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

response = agent_executor.invoke({"input": "What's the status of task1?"})
print(response['output'])

response = agent_executor.invoke({"input": "Find documentation on project management best practices"})
print(response['output'])
```

首先，使用 create_tool_calling_agent 函数创建代理，该函数结合了语言模型 (llm)、工具列表 (tools) 和提示模板 (prompt)。该代理旨在解释用户输入，确定要使用的工具，并根据该工具的结果提供响应。
接下来，通过使用 AgentExecutor 类初始化 agent_executor。agent_executor 管理代理的执行，处理代理在响应用户查询时采取的操作序列。verbose=True 参数确保执行过程被记录下来，为调试或理解代理的行为提供详细的输出。

然后使用两个示例查询对代理进行测试。调用 invoke 方法时传入一个包含用户输入的字典，字典中“input”键下包含用户的输入。第一个查询请求特定任务 task1 的状态，并打印代理的响应。第二个查询请求有关项目管理最佳实践的文档，再次打印代理的响应。
代理的输出展示了其通过利用适当的工具处理用户查询的能力。在第一个实例中，代理成功检索特定任务 (task1) 的状态，确认其为“进行中”。在第二个实例中，代理搜索有关项目管理最佳实践的文档，并提供相关在线资源的列表。这些资源包括链接和来自知名来源的文章的简要描述，涵盖了各种项目管理技术和方法论。输出显示代理能够有效地在工具之间切换，并根据用户输入提供准确且有帮助的响应。

Conclusion

LangChain 的模块化设计以及对 Python 和 JavaScript 的支持，使其成为 AI 开发人员的基础工具。本章强调了 LangChain 的编排能力的重要性，其在生成式 AI 崛起后的快速增长，以及被大型公司采用的情况。本章还深入探讨了 LangChain 的组件，包括模型、提示模板、输出解析器、文档加载器和文本分割器，并提供了实际示例和代码片段来说明它们的使用。最后，本章以 LangChain 代理为结尾，解释了如何构建它们以在 AI 系统中处理动态决策和交互。


© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 209

https://doi.org/10.1007/979-8-8688-1134-0_9

**CHAPTER 9**

**Introduction**

**to LangGraph**

LangGraph is a popular open source framework—created by LangChain—
that helps developers use large language models (LLMs) to build
sophisticated, stateful, and multi-actor applications. This capability is vital
for crafting advanced agent architectures capable of context retention,
learning from interactions, and continuous evolution.
A key distinction of LangGraph lies in its departure from the limitations
of Directed Acyclic Graph (DAG) structures, which are common in many
LLM frameworks. They are based on a conceptual model used in computer
science and mathematics. It consists of a finite set of vertices (or nodes)
connected by directed edges, with the crucial constraint that there are no
cycles or loops within the structure. In other words, if you start at any node
and follow the directed edges, you can never return to the same node. This
structure is widely used in task scheduling, data processing pipelines, and
dependency resolution, where a clear, one-way flow of operations or data
is required.
While DAGs are useful for many applications, they have limitations
when it comes to creating truly dynamic and adaptive AI agents. This is
where LangGraph’s innovative approach comes into play. By enabling the
creation of cycles within the workflow, LangGraph opens up possibilities
for implementing iterative processes, feedback loops, and recursive
behaviors—all essential components of genuine agentic intelligence.


LangGraph’s architectural inspiration comes from established
frameworks like Pregel and Apache Beam, with its public interface drawing
from NetworkX concepts. This fusion results in a powerful yet accessible
AI development tool. While LangGraph is designed to work seamlessly
with LangChain and LangSmith, it maintains the flexibility to be used
independently, catering to developers with diverse toolchain preferences.
Regardless, it is still important to understand the fundamentals of
LangChain. This will be the focus of the first half of this chapter. After this,
we’ll dive into how LangChain works.

Benefits of Combining LangChain

with LangGraph

The integration of LangChain and LangGraph represents a significant
advancement in the field of AI development, creating a powerful
ecosystem that offers developers unprecedented capabilities. This synergy
combines LangChain’s extensive toolset for large language model (LLM)
interactions with LangGraph’s sophisticated stateful framework, resulting
in a comprehensive solution for building advanced AI applications.
At the core of this integration is the ability to handle complexity
with greater ease and efficiency. Developers can now create AI agents
capable of managing intricate, multi-step processes that were previously
challenging to implement. These agents benefit from improved context
awareness, maintaining state across interactions, learning from
experiences, and evolving over time. This dynamic adaptability leads to
more intelligent and responsive AI systems that can handle a wide range of
tasks with increased sophistication.
The combined framework offers a streamlined development
experience, particularly beneficial for those already familiar with
LangChain. The shared concepts and patterns between the two
systems reduce the learning curve, allowing developers to quickly

Chapter 9 IntroduCtIon to Langgraph


leverage LangGraph’s advanced features. This continuity accelerates
the development process, enabling faster creation and deployment of
complex AI agents. Furthermore, the integration provides developers with
increased flexibility, offering a broader palette of tools and approaches to
choose from when solving specific AI challenges.
One of the key strengths of this integration is the enhanced workflow
management capabilities. LangGraph’s cyclic workflows complement
LangChain’s robust language model utilities, enabling the implementation
of sophisticated feedback loops and iterative behaviors within AI agents.
This feature is crucial for creating AI systems that can refine their responses
and adapt their strategies based on ongoing interactions and outcomes.
The scalability offered by this combined approach is another
significant advantage. As AI applications grow in complexity and data
volume, the integrated framework provides the necessary tools and
structures to scale effectively. This scalability is complemented by
improved error handling mechanisms, enhancing the overall reliability
and robustness of AI systems. The modular nature of the combined
framework also facilitates easier maintenance and updates, allowing
developers to create more reusable components.
From a resource perspective, the LangChain-LangGraph integration
enables more efficient use of computational resources. This optimization
can lead to reduced costs in AI application deployment, making
advanced AI solutions more accessible to a broader range of projects
and organizations. The framework also expands the potential use cases,
enabling developers to tackle a wider spectrum of AI challenges, from
straightforward chatbots to complex decision-making systems that require
nuanced understanding and reasoning.
Testing and debugging complex AI systems become more manageable
with this integrated approach. The combined framework offers enhanced
tools for examining AI agent behaviors and troubleshooting intricate
workflows. This improvement in the development and quality assurance
process leads to more reliable and performant AI applications.

```
Chapter 9 IntroduCtIon to Langgraph
```

Lastly, the integration enhances interoperability, making it easier to
connect AI agents with external systems and data sources. This expanded
connectivity opens up new possibilities for AI applications, allowing them
to integrate more seamlessly into existing technological ecosystems and
leverage a wider range of data and functionalities.
In conclusion, the combination of LangChain and LangGraph provides
developers with a comprehensive toolkit that pushes the boundaries
of what’s possible in AI development. It enables the creation of more
sophisticated, adaptable, and context-aware AI applications, setting a new
standard for intelligent systems. As this integrated approach continues to
evolve, it promises to drive innovation in AI, opening up new frontiers in
machine intelligence and its practical applications across various domains.

Pros and Cons of LangGraph

One of the standout features of LangGraph is its emphasis on
controllability. As a low-level framework, it offers developers fine-grained
control over both the flow of operations and the state of the application.
This level of control is crucial for creating reliable and predictable AI
agents, especially in scenarios where precision and consistency are
paramount. Developers can define complex decision trees, implement
conditional logic, and orchestrate multi-step processes with a high degree
of specificity.
Persistence is another key advantage of LangGraph. The framework
includes built-in mechanisms for automatically saving the state after
each step in the graph. This feature opens up a world of possibilities for
advanced applications. It enables seamless implementation of human-
in- the-loop workflows, where human operators can intervene, provide
feedback, or make decisions at critical junctures. The persistence
capability also facilitates error recovery, allowing developers to pause and

Chapter 9 IntroduCtIon to Langgraph


resume graph execution at any point. This is particularly valuable for long-
running processes or in scenarios where reliability and fault tolerance are
critical.
LangGraph’s design philosophy draws inspiration from established
frameworks like Pregel and Apache Beam, while its public interface
borrows concepts from NetworkX. This blend of influences results in a
powerful yet accessible tool for AI development. While LangGraph is built
to integrate seamlessly with LangChain and LangSmith, it’s important to
note that it can be used independently, offering flexibility to developers
who may have different toolchain preferences.
The framework also shines in its support for streaming outputs. As
each node in the graph produces results, these can be streamed in real
time, including token-by-token streaming from language models. This
feature is invaluable for creating responsive, interactive AI agents that can
provide immediate feedback and engage in dynamic conversations.
In the broader context of AI development, LangGraph represents a
significant step forward in the creation of more sophisticated, stateful AI
agents. By providing tools for implementing cycles, ensuring persistence,
and offering fine-grained control, it empowers developers to create AI
systems that can handle complex, multi-step tasks, maintain context over
extended interactions, and adapt to changing conditions. This makes it
particularly well suited for applications in areas such as conversational AI,
task planning and execution, and multi-agent simulations.
As AI continues to evolve and find new applications across industries,
frameworks like LangGraph play a crucial role in bridging the gap between
the raw capabilities of large language models and the complex, real-world
requirements of AI systems. By providing a robust foundation for building
stateful, adaptive AI agents, LangGraph is poised to accelerate innovation
in the field of artificial intelligence and enable the creation of more
capable, reliable, and sophisticated AI applications.

```
Chapter 9 IntroduCtIon to Langgraph
```

Graphs

LangGraph models agent workflows as graphs, where the behavior of your
agents is defined by three essential components. First, the State represents
the current snapshot of your application, which can be any Python type,
though it often takes the form of a TypedDict or Pydantic BaseModel.
Next, Nodes are Python functions that encode the logic of your agents,
taking the current State as input, performing some computation or action,
and returning an updated State. Lastly, Edges are Python functions that
determine the next Node to execute based on the current State, guiding the
flow of operations through either conditional branches or fixed transitions.
By combining Nodes and Edges, you can create intricate, looping
workflows that allow the State to evolve over time. The real strength
of LangGraph lies in how it manages this State, with Nodes and Edges
functioning as Python code—whether incorporating an LLM or utilizing
standard Python logic.
In essence, Nodes perform the tasks, while Edges dictate the next
steps. LangGraph’s underlying graph algorithm employs message passing
to define a general program structure. When a Node completes its
operation, it sends messages along its Edges to subsequent Nodes, which
then execute their functions and pass the resulting messages onward.
This process continues in a pattern inspired by Google’s Pregel system,
advancing through discrete “super-steps.” Each super-step corresponds to
a single iteration over the graph’s nodes, where parallel operations belong
to the same super-step, while sequential ones are divided across separate
super-steps.
At the start of graph execution, all nodes are inactive, becoming active
only when they receive new messages (state) through their incoming
edges or channels. An active node runs its function and sends updates in
response. Once a super-step concludes, nodes without incoming messages
signal their inactivity. The graph’s execution completes when all nodes are
inactive, and no messages remain in transit.

Chapter 9 IntroduCtIon to Langgraph


The StateGraph class is the primary graph class used, parameterized
by a user-defined State object. On the other hand, the MessageGraph class
is a specialized type of graph where the State is merely a list of messages,
making it rarely used except in chatbot applications, where the State’s
complexity is minimal.
To construct your graph, you first define the State, then add nodes and
edges, and finally compile it. Compiling is a straightforward process that
performs basic structural checks on your graph, ensuring there are no
orphaned nodes, among other things. It also allows you to specify runtime
arguments such as checkpointers and breakpoints. Compiling is done by
calling the “.compile” method on your graph.
In the next few sections, we’ll take a deeper look at State, Nodes,
and Edges.

State

The State includes the schema and reducer functions that dictate how
updates are applied. The schema, which serves as the input for all Nodes
and Edges, can be a TypedDict or a Pydantic model. Nodes emit updates to
the State, which are then processed using the specified reducer functions.
The schema is typically defined using TypedDict, but a Pydantic
BaseModel can also be used to incorporate default values and additional
data validation. By default, the input and output schemas of the graph
are the same, but you can customize them if needed, particularly when
handling numerous keys with distinct roles.
Reducers play a crucial role in applying updates to the State. Each
key in the State has an independent reducer function, with the default
behavior being to overwrite the key with new updates. For instance, you
can use the Annotated type to specify a custom reducer, like operator.add,
which can append updates rather than overwrite them.

```
Chapter 9 IntroduCtIon to Langgraph
```

Context channels allow you to manage shared resources like database
connections that are maintained outside the nodes and excluded from
checkpointing. These resources are set up at the beginning of the graph
execution and cleaned up at the end, ensuring efficient management
throughout the graph’s run.
When working with messages in your graph’s State, particularly in
applications involving chat models, it’s beneficial to store conversation
history as a list of Message objects. By adding a key to the State for these
messages and using a reducer like operator.add, you can efficiently
manage message updates. Alternatively, the add_messages function can
be used to track message IDs and handle both new and updated messages
accurately, ensuring that manual updates don’t inadvertently append
messages but instead update them as needed.
For serialization, add_messages also facilitates the deserialization
of messages into LangChain Message objects, allowing seamless state
updates. You can easily access these messages using dot notation, like
state["messages"][-1].content.

Nodes

Nodes are typically Python functions, either synchronous or asynchronous,
where the first argument is the state and the optional second argument is
a “config” that holds configurable parameters, such as a session_id. You
add these nodes to a graph using the add_node method.
For example, consider a function process_data that logs a message
and returns a modified state:

from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph

builder = StateGraph(dict)

Chapter 9 IntroduCtIon to Langgraph


def process_data(state: dict, config: RunnableConfig):
print("Processing data for session:",
config["configurable"]["session_id"])
state["output"] = f"Processed: {state['input']}"
return state

def finalize_data(state: dict):
state["status"] = "complete"
return state

builder.add_node("process_data", process_data)
builder.add_node("finalize_data", finalize_data)

When these functions are added to the graph, they are automatically
converted into RunnableLambda objects, which provide features like batch
processing, asynchronous execution, and built-in tracing and debugging. If
you add a node without specifying a name, the function’s name is used as
the node name by default.
Special nodes such as START and END are crucial for controlling the
flow within the graph. The START node is used to designate the entry point
for user input, allowing you to specify which nodes are triggered first:

from langgraph.graph import START
builder.add_edge(START, "process_data")

The END node serves as a terminal point in the graph, marking where
no further actions will occur after the execution of its associated edges:

from langgraph.graph import END
builder.add_edge("finalize_data", END)

These special nodes help define the structure of your graph, ensuring
clear entry and exit points for the data flow.

```
Chapter 9 IntroduCtIon to Langgraph
```

Edges

There are several key types of edges:

- Normal Edges: Directly connect one node to the next
- Conditional Edges: Use a function to decide which
    node(s) to transition to next
- Entry Point: Specifies the first node to execute when
    user input is received
- Conditional Entry Point: Uses a function to determine
    the initial node(s) to execute based on custom logic
A node can have multiple outgoing edges, meaning all destination
nodes will execute in parallel in the next super-step.
For a normal edge, you will use the add_edge method:

graph.add_edge("step_one", "step_two")

For more complex routing, you can use a conditional edge. This uses a
method that requires a node name and a routing function, which uses the
current state of the graph to determine the next node or nodes:

def routing_logic(state):
return "step_two" if state["condition"] else "step_three"

graph.add_conditional_edges("step_one", routing_logic)

```
You can also map the function’s output to specific nodes:
```
graph.add_conditional_edges("step_one", routing_logic, {True:
"step_two", False: "step_three"})

For an Entry Point Edge, you connect the virtual START node to the
first node using add_edge:

Chapter 9 IntroduCtIon to Langgraph


from langgraph.graph import START

graph.add_edge(START, "initial_step")

Finally, with a Conditional Entry Point, you need to start at different
nodes based on some condition. For this, you can use add_conditional_
edges from the START node:

from langgraph.graph import START

def start_logic(state):
return "initial_step" if state["start_here"] else
"alternative_step"

graph.add_conditional_edges(START, start_logic, {True:
"initial_step", False: "alternative_step"})

This approach allows you to dynamically control the flow based on
the incoming data, ensuring that the graph starts in the most appropriate
place, depending on the situation.

Reflection Agent

The reflection agent in LangGraph is a specialized type of agent designed
to analyze and evaluate its own decisions and actions, enabling it to
improve performance over time. Unlike reactive agents that respond to
inputs in a straightforward manner, reflection agents incorporate a layer
of self-assessment, allowing them to learn from past interactions and
outcomes. This self-reflection capability is crucial for tasks that require
ongoing optimization, such as content creation or strategy development.
By iterating on its decisions and considering what worked well and what
didn’t, a reflection agent can refine its output to achieve higher-quality
results over time.
To demonstrate this, we’ll create a program that makes better tweets.

```
Chapter 9 IntroduCtIon to Langgraph
```

We will first need to install various libraries, including those for
OpenAI, LangChain, and LangGraph:

pip install --upgrade -q openai langchain langchain-openai
langchain-community langgraph

```
Next, we will have these imports:
```
from typing import TypedDict, Annotated, Sequence
from langgraph.graph import Graph, StateGraph
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

The import statement from typing import TypedDict, Annotated,
Sequence brings in important type hinting features from Python’s typing
module. TypedDict is used to create dictionaries with a predetermined
structure, where each key is associated with a specific type, ensuring that
data follows a consistent format. Annotated allows you to add metadata
or constraints to types, which can be useful for enhancing type hints and
making them more informative for tools or frameworks. Sequence is a type
hint that represents ordered collections, such as lists or tuples, allowing
you to specify the type of elements contained within the sequence.
From the LangGraph library, the imports from langgraph.graph
import Graph, StateGraph introduce two essential components, Graph
and StateGraph.
Then there are various libraries from LangChain, such as ChatOpenAI
for integrating OpenAI’s chat models, PromptTemplate for managing
structured prompts, and StrOutputParser for parsing string outputs.
We’ll then initialize the LLM:

llm = ChatOpenAI(model="gpt-4o-mini")

Chapter 9 IntroduCtIon to Langgraph


```
We will define the prompt templates:
```
reflection_template = PromptTemplate.from_template(
"""
Analyze the following tweet and provide a reflection on how
it can be improved:
Tweet: {tweet}

Consider aspects such as clarity, engagement, and brevity.
Provide specific suggestions.
"""
)

The template, named reflection_template, is designed to analyze
tweets and provide reflections on how they can be improved. It asks for
an analysis of a given tweet, focusing on aspects like clarity, engagement,
and brevity. By using the PromptTemplate.from_template method,
the template is created with placeholders, such as {tweet}, which can
be dynamically filled with specific tweet content during runtime. This
approach ensures that the prompt is consistently formatted, making it
easier to generate targeted and effective reflections for tweet improvement.
This function is to improve the tweet:

improve_tweet_template = PromptTemplate.from_template(
"""
Given the original tweet and the reflection, provide an
improved version of the tweet:

Original tweet: {tweet}
Reflection: {reflection}

Improved tweet:
"""
)

```
Chapter 9 IntroduCtIon to Langgraph
```

The placeholders {tweet} and {reflection} allow for dynamic
insertion of the original tweet content and the analysis provided by the
reflection, respectively. This template ensures that the process of refining
tweets is consistent and guided by specific feedback, making it easier to
produce more effective and engaging tweets.
We define the nodes:

def reflect(state: AgentState) -> AgentState:
chain = reflection_template | llm | StrOutputParser()
reflection = chain.invoke({"tweet": state['tweet']})
state['reflection'] = reflection
return state

The function takes an AgentState object as input, which holds the
current state of the agent, including the tweet to be analyzed. Inside the
function, a chain is created using the reflection_template, an LLM,
and a StrOutputParser. This chain processes the tweet by invoking the
reflection template and parsing the output to generate a reflection. The
resulting reflection is then stored back into the state object under the key
reflection, allowing the agent to use this reflection in subsequent steps.
This setup is integral to building a modular and reusable workflow that
systematically improves tweet content based on structured feedback.
There is the function to improve the tweet:

def improve_tweet(state: AgentState) -> AgentState:
chain = improve_tweet_template | llm | StrOutputParser()
improved_tweet = chain.invoke({"tweet": state['tweet'],
"reflection": state['reflection']})
state['improved_tweet'] = improved_tweet
return state

This also takes in the AgentState object as input. There is also the
same approach with the use of the improve_tweet_template, an LLM, and
a StrOutputParser as well as the use of state.

Chapter 9 IntroduCtIon to Langgraph


```
We define the graph:
```
workflow = StateGraph(AgentState)

We add some nodes for the reflection and the improvement of
the tweet:

workflow.add_node("reflect", reflect)
workflow.add_node("improve_tweet", improve_tweet)

```
The same goes for the edges of the graph:
```
workflow.add_edge("reflect", "improve_tweet")

```
Then we set an entry point for the graph:
```
workflow.set_entry_point("reflect")

```
We compile the graph:
```
graph = workflow.compile()

```
We create a function to run the graph:
```
def improve_tweet_with_reflection(tweet: str) -> str:
result = graph.invoke({"tweet": tweet})
return result['improved_tweet']

We invoke the graph with the original tweet passed as input. The
workflow processes the tweet through various nodes, including generating
a reflection and then improving the tweet based on that reflection. The
final output, an enhanced version of the tweet, is extracted from the result
and returned as the function’s output.
Then we use an example of this agent:

if __name__ == "__main__":
original_tweet = "I think AI is cool and will change
everything."

```
Chapter 9 IntroduCtIon to Langgraph
```

improved_tweet = improve_tweet_with_
reflection(original_tweet)
print(f"Original tweet: {original_tweet}")
print(f"Improved tweet: {improved_tweet}")

The original_tweet is defined with the text “I think AI is cool and
will change everything.” The function improve_tweet_with_reflection
is then called with this tweet, and the resulting improved_tweet is stored.
Finally, both the original and improved tweets are printed to the console,
allowing you to see the before-and-after results of the tweet enhancement
process.
In fact, we can create a visualization of this agent:

from IPython.display import Image, display

try:
display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
# This requires some extra dependencies and is optional
pass

The IPython.display module generates a graphic representation of the
workflow using Mermaid diagrams, rendered as a PNG image. The graph.
get_graph().draw_mermaid_png() function is called to create this visual,
and display(Image(...)) is used to show it within the environment. If
an error occurs, such as missing dependencies required for rendering the
image, the except block catches the exception and passes, allowing the
script to continue running without interruption.
Figure 9-1 shows what it looks like.

Chapter 9 IntroduCtIon to Langgraph


**Figure 9-1.** _A visualization of a reflection agent in LangGraph_

Persistence

Persistence is a critical feature in AI workflows, especially when it comes
to applications that need to maintain context across multiple interactions.
In the context of LangGraph, persistence refers to the ability to store and
retrieve the state of a graph after its nodes have been executed. This means
that an AI agent can “remember” what it has done in the past, allowing it to
pick up where it left off after an interruption or between different sessions.
This is particularly useful for applications where user input plays a
significant role, as the state of the agent can be saved and resumed without
losing any progress.
Using a feature called checkpointer, LangGraph provides a streamlined
way to store this state data in various persistent storage systems, such as
SQLite, Postgres, or MongoDB. When an agent pauses—whether waiting
for user input or due to another event—its state is saved and can be
retrieved later to continue processing from where it left off. This ability
to store state over time also enhances debugging, tracking history, and
supporting multiple user sessions, making persistence essential for robust,
production-grade AI applications. With LangGraph’s checkpointers, you

```
Chapter 9 IntroduCtIon to Langgraph
```

can ensure that no matter what happens during an interaction, your
application will be able to pick up right where it left off, seamlessly and
efficiently.
We’ll write a program that illustrates the use of persistence. The
scenario is for a travel booking assistant.
For the program, we have this setup:

from langgraph.graph.message import add_messages

add_messages, imported from langgraph.graph.message, is a function
used to append or combine messages, so as to handle the concatenation of
chat messages in a stateful way as the graph processes interactions.
Then we create different tools:

from langchain_core.tools import tool

@tool
def book_flight(destination: str):
"""Book a flight to the specified destination."""
return {"confirmation": "FL12345", "destination": destination}

@tool
def book_hotel(location: str):
"""Book a hotel in the specified location."""
return {"confirmation": "HT98765", "location": location}

@tool
def book_car_rental(location: str):
"""Book a car rental in the specified location."""
return {"confirmation": "CR56789", "location": location}

tools = [book_flight, book_hotel, book_car_rental]

The tool decorator from langchain_core.tools is used to define
functions that can be invoked by an AI agent as part of a workflow, turning
regular Python functions into callable “tools” within a LangChain or

Chapter 9 IntroduCtIon to Langgraph


LangGraph environment. In this case, three distinct tools are defined for
booking travel services: book_flight, book_hotel, and book_car_rental.
Each function takes a specific input—destination for flights and location
for hotels and car rentals—and returns a confirmation number along with
the requested information. These tools simulate actions that an AI agent
can perform.
Then we set up the OpenAI model:

from langchain_openai import ChatOpenAI

model = ChatOpenAI(temperature=0, streaming=True)
bound_model = model.bind_tools(tools)

```
We create two functions for the workflow:
```
from typing import Literal
def should_continue(state: TravelState) -> Literal["action",
"__end__"]:
last_message = state["messages"][-1]
if not last_message.tool_calls:
return "__end__"
return "action"

def call_model(state: TravelState):
response = model.invoke(state["messages"])
return {"messages": response}

The Literal import from typing is used to specify that a function’s
return value must be one of a few specific string options, providing more
precise control over the flow of logic. In the should_continue function, the
agent examines the state—specifically, the last message in the “messages”
list—to decide whether to continue with an action or finish the current
task. If no tool calls were made in the last message, it returns __end__,
indicating that the process is complete. Otherwise, it returns “action,”
signaling that further steps are needed.

```
Chapter 9 IntroduCtIon to Langgraph
```

The call_model function is responsible for invoking the AI model to
generate a response based on the current state (the list of messages). It
returns the generated message wrapped in a dictionary, allowing the agent
to use this output in the next step of its decision-making process.
We set up the workflows for the agents, tools, and edges:

from langgraph.graph import StateGraph, START
from langgraph.prebuilt import ToolNode

tool_node = ToolNode(tools)
workflow = StateGraph(TravelState)

workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)

workflow.add_edge(START, "agent")
workflow.add_conditional_edges("agent", should_continue)
workflow.add_edge("action", "agent")

The imports from langgraph.graph bring in the StateGraph class,
which is used to define a workflow that maintains the state across
different nodes, and the START constant, which defines the starting point
of the graph. Additionally, ToolNode from langgraph.prebuilt is a
preconfigured node responsible for executing tools (in this case, the travel
booking tools).
In this code, tool_node is instantiated with the predefined tools, such
as flight, hotel, and car rental booking functions, making them executable
within the workflow. A StateGraph object is created to manage the state
of the travel agent (represented by the “TravelState”), and two main nodes
are defined: the “agent” node, which invokes the model via the call_model
function, and the “action” node, which runs the tool when the model
decides to take an action. The workflow is set up by adding edges: it starts
with the “agent” node, which is linked to the “action” node based on

Chapter 9 IntroduCtIon to Langgraph


conditions. This structure allows the workflow to cycle between decision-
making (agent) and action execution (tools), dynamically progressing
based on real-time inputs and tool calls.
We then set up the memory:

from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
app = workflow.compile(checkpointer=memory)

The MemorySaver class from langgraph.checkpoint.memory is
imported to provide in-memory storage for the workflow’s state, enabling
persistence across interactions. By creating an instance of MemorySaver,
called memory, the state of the agent can be stored in memory, ensuring
that previous interactions are saved and can be accessed later.
The memory object is then passed as a checkpointer when compiling
the workflow using workflow.compile(checkpointer=memory). This step
ensures that after each node execution in the graph, the state is saved,
allowing the agent to “remember” what has already been processed.
Finally, we create the chat for the human and AI:

from langchain_core.messages import HumanMessage

config = {"configurable": {"thread_id": "2"}}
input_message = HumanMessage(content="Hello, I want to book a
flight to New York?")
for event in app.stream({"messages": [input_message]}, config,
stream_mode="values"):
event["messages"][-1].pretty_print()

input_message = HumanMessage(content="I also want to book a
hotel room.")
for event in app.stream({"messages": [input_message]}, config,
stream_mode="values"):
event["messages"][-1].pretty_print()

```
Chapter 9 IntroduCtIon to Langgraph
```

The HumanMessage class from langchain_core.messages is imported
to represent user input in the form of human-readable messages.
The config dictionary includes a key “configurable” that specifies a
thread_id, which ensures that the agent can track the conversation within
the same session. In this case, the thread_id is set to “2,” allowing the
agent to maintain context throughout the interaction.
In the first part of the interaction, an instance of HumanMessage is
created with the content “Hello, I want to book a flight to New York?”, and
it is passed to the app.stream function along with the config. The agent
processes this message and returns a response, which is then printed.
The second message, “I also want to book a hotel room.”, is handled in
a similar way, continuing the conversation in the same thread.
This is the output:
Human: Hello, I want to book a flight to New York?
AI: Great! When would you like to travel to New York
and from which city would you be departing?
Human: I also want to book a hotel room.
AI: Of course! Would you like assistance in finding
a hotel in New York as well? If so, what are your
preferences for the hotel such as budget, location,
amenities, etc.?
So as you can see, in the last thread from the AI, it recognizes the city.
In other words, there is persistence across the different nodes and calls to
the LLM.

LangSmith

LangSmith is a powerful platform designed to build production-ready LLM
applications. It makes it easier for developers to manage the complexities
of these systems. With LangSmith, you can keep a close eye on your

Chapter 9 IntroduCtIon to Langgraph


application’s performance and progress, allowing for faster deployment
with increased confidence. Its seamless integration with LangChain and
LangGraph, along with the ability to operate independently, provides a
flexible and reliable framework for handling LLM solutions.
Working with LLMs can be challenging due to their probabilistic
nature. That is, a response can be unpredictable, often producing
inconsistent results based on natural language prompts.
Key features of LangSmith include tracing and debugging, where it
offers detailed logs of application runs, which help developers understand
the entire operation and quickly identify any issues. The platform also
provides robust tools for evaluation and testing, enabling developers to
create datasets of inputs and expected outputs for automated and manual
assessments. In production, LangSmith offers real-time monitoring of
essential metrics like latency, cost, and user feedback, ensuring any
problems are swiftly addressed.
Collaboration is another core focus, with LangSmith providing features
for annotation and feedback, allowing developers to share insights
and improve debugging and evaluation. Moreover, the platform offers
versioning and comparison tools, enabling users to analyze different
application versions side by side and track changes over time.
LangSmith offers three pricing plans tailored to different user needs.
The Developer plan, free for one user, includes 5,000 free traces per month,
with additional traces billed at $0.05 per trace. The Plus plan costs $39 per
user per month, offering 10,000 free traces with the same rate for extra
traces. Enterprise pricing is customized, providing features like Single
Sign-On, deployment options, and dedicated support. All plans support
key features like debugging, testing, and monitoring, with additional
collaboration and security options for teams.
Let’s take a look at LangSmith. You can register for the service at this
URL: smith.langchain.com. Figure 9-2 shows the dashboard.

```
Chapter 9 IntroduCtIon to Langgraph
```

**Figure 9-2.** _This is the dashboard for LangSmith_

It’s divided into different sections, such as Projects, Datasets & Testing,
Annotation Queues, and Prompts.
To get an API key, select the Settings icon on the left side of the
dashboard. You will then choose Create API Key. You have two options.
One is the Personal Access Token, which is for an individual user. Then
there is the Service Key. This is for more advanced capabilities.
For our purposes, we’ll select the Personal Access Token.
Next, you will use these commands in the terminal:

export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY=<your-api-key>

With this, a connection will be made to LangSmith. So when you go
back to the dashboard, you can then use the different functions to track,
debug, and monitor the agent.

Assistant-UI

Assistant-UI (https://www.assistant-ui.com/docs) is a React
component library for building chatbot-like UIs. It has an integration with

Chapter 9 IntroduCtIon to Langgraph


LangGraph Cloud. You can create a new project using this, or you can use
it with existing React projects with the various components.
It’s simple to implement. First, here’s how you create a new project:

npx assistant-ui@latest create my-app
cd my-app

To add the API key for accessing OpenAI, we create a new .env file to
the project with your OpenAI API key:

OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

To run the application, use the following (as you would with a React
application):

npm run dev

This will display a skeleton for the Chat Agent UI, as you can see in
Figure 9-3.

**Figure 9-3.** _The Assistant-UI screen after running the application_

```
Chapter 9 IntroduCtIon to Langgraph
```

LangGraph Studio

LangGraph Studio (github.com/langchain-ai/langgraph-studio) is
a desktop application for prototyping and debugging LangGraph
applications. It offers visual ways to interact with, edit, and debug agent
workflows. There is also step-by-step execution and human-in-the-loop—
all integrated with LangSmith. It is currently available for macOS and
Windows (Linux support is coming soon). It requires Docker to set up.
Currently, this application is in the beta phase and is free. Figure 9-4 shows
the dashboard for this application.

**Figure 9-4.** _LangGraph Studio screen displaying a LangGraph agent
workflow_

Chapter 9 IntroduCtIon to Langgraph


Conclusion

LangGraph stands as an effective tool for building stateful, adaptive
agents that can handle complex workflows. Its flexibility in creating cyclic
structures, persistence, and fine-grained control empowers developers to
overcome the limitations of traditional DAG frameworks. By combining
LangGraph with LangChain, developers gain access to a comprehensive
ecosystem that simplifies the creation of advanced AI systems capable of
continuous learning and dynamic interactions.

```
Chapter 9 IntroduCtIon to Langgraph
```

© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 237

https://doi.org/10.1007/979-8-8688-1134-0_10

**CHAPTER 10**

**Haystack**

The Haystack framework, developed by Berlin-based startup Deepset,
is an open source tool that allows developers to build advanced AI
applications using large language models (LLMs). Founded in 2018 by
Milos Rusic and Malte Pietsch, Deepset gained early attention for its focus
on natural language processing (NLP) solutions, such as training the first
German BERT model. Haystack has since evolved into a powerful tool for
building custom applications like question answering, semantic search,
and Retrieval-Augmented Generation (RAG) systems.
Haystack’s strength lies in its modularity and flexibility. This enables
developers to integrate components like vector databases, transformer
models, and LLMs from platforms such as Hugging Face, OpenAI, or even
custom models hosted on various cloud platforms like AWS or Azure. It
allows users to connect these components into pipelines, providing full
control over the data flow and enabling the creation of robust, scalable AI
solution.
Beyond open source tools, Deepset offers an enterprise version,
Deepset Cloud, which simplifies the deployment of production-ready NLP
applications. Haystack's features make it useful for enterprises looking to
build and manage NLP-driven applications with greater ease, thanks to its
support for document retrieval, semantic search, and advanced dynamic
template generation.


With Deepset continuing to secure significant investment, including
$30 million in 2023, the company is poised to further expand its LLM-
focused offerings.^1

Haystack Program

To get a sense of how Haystack works, we’ll create a simple program. It
will use a Retrieval-Augmented Generation (RAG) pipeline to retrieve and
generate answers to a question given a set of documents.
First, we will need to install the framework:

pip install haystack-ai

```
Next, we will install few libraries:
```
from haystack import Pipeline, Document
from haystack.utils import Secret
from haystack.document_stores.in_memory import
InMemoryDocumentStore
from haystack.components.retrievers.in_memory import
InMemoryBM25Retriever
from haystack.components.generators import OpenAIGenerator
from haystack.components.builders.answer_builder import
AnswerBuilder
from haystack.components.builders.prompt_builder import
PromptBuilder

```
Here are the explanations:
```
- Pipeline: Allows you to develop a series of processes
    ranging from document retrieval to answer generation.

(^1) https://techcrunch.com/2023/08/09/deepset-secures-30m-to-expand-its-
llm-focused-mlops-offerings/
Chapter 10 haystaCk


- Document: A single unit or piece of content or text that
    is used in answering questions.
- Secret: Library for handling private information like
    API keys for the OpenAI API.
- InMemoryDocumentStore: Library to store the
    documents that are kept in memory for quick lookup at
    runtime.
- InMemoryBM25Retriever: Helps to find relevant
    documents from the document store given the
    question using BM25 as its method of retrieval. This is a
    traditional information retrieval algorithm.
- OpenAIGenerator: Library for the OpenAI API.
- AnswerBuilder and PromptBuilder: Classes for
    instantiating responses and prompts for the LLM.
We instantiate a document in an in-store memory database. We will
write three simple documents to it:

document_store = InMemoryDocumentStore()
document_store.write_documents([
Document(content="My name is Jean and I live in Paris."),
Document(content="My name is Mark and I live in Berlin."),
Document(content="My name is Giorgio and I live in Rome.")
])

These will be the documents from which the pipeline fetches
information on certain knowledge.
Then we have the code for the RAG pipeline:

# Build a RAG pipeline
prompt_template = """
Given these documents, answer the question.

```
Chapter 10 haystaCk
```

Documents:
{% for doc in documents %}
{{ doc.content }}
{% endfor %}
Question: {{question}}
Answer:
"""

retriever = InMemoryBM25Retriever(document_
store=document_store)
prompt_builder = PromptBuilder(template=prompt_template)
api_key = userdata.get('OPEN_AI_API_KEY')
llm = OpenAIGenerator(api_key=Secret.from_token(api_key))

rag_pipeline = Pipeline()
rag_pipeline.add_component("retriever", retriever)
rag_pipeline.add_component("prompt_builder", prompt_builder)
rag_pipeline.add_component("llm", llm)
rag_pipeline.connect("retriever", "prompt_builder.documents")
rag_pipeline.connect("prompt_builder", "llm")

```
Here’s a rundown:
```
- Prompt Template: A custom template is generated
    using the PromptBuilder. It takes the retrieved
    documents as input and creates a prompt for the
    language model, which asks the model to give
    an answer.
- Retriever: The InMemoryBM25Retriever is configured
    to look into the document store for the best matching
    documents to the query. In this example, it will fetch a
    document that is very likely to contain an answer.

Chapter 10 haystaCk


- PromptBuilder: This constructs the final prompt that
    goes to the LLM. It inserts the retrieved documents into
    the template.
- OpenAIGenerator: This module is responsible for
    generating responses with the use of OpenAI's GPT-
    based models. The key of the OpenAI API is securely
    retrieved through “Secret.from_token()”.
We construct a question using this code:

# Ask a question
question = "Who lives in Paris?"
results = rag_pipeline.run(
{
"retriever": {"query": question},
"prompt_builder": {"question": question},
}
)

The pipeline runs, retrieving relevant documents and generating an
answer using OpenAI’s GPT model.
We print the response:

print(results["llm"]["replies"])

In this example, the system will likely find the document “My name is
Jean, and I live in Paris” for this question's answer.
This setup illustrates how RAG pipelines combine traditional search
with the generative power of large language models to answer questions
based on documents provided with the help of the Haystack framework.

```
Chapter 10 haystaCk
```

Haystack Agent with Function Calling

The OpenAIFunctionCaller class of the haystack-experimental package
helps to connect models like GPT-4 easier in Jupyter or Colab notebooks.
It also supports function calling. That is, it will recognize when to invoke
certain functions, say to look something up or make a calculation.
This is a handy component in that it makes the integration of agents
into the workflow of Haystack easier. It also handles common problems
like API errors or poor connections. This component can even deal with
retries for failed attempts. For the most part, this component helps to
create more interactive and smart agents, since the AI can decide when to
perform particular actions based on the user’s input.
Let's take a look at the example. We will create a program that uses a
RAG pipeline. For this, the user will ask questions, and the AI agent will
dynamically decide to call on various functions like asking about the
weather or who lives where.
First, we need to install Gradio, which allows for creating simple web
interfaces:

pip install haystack-ai gradio

Next, we import various frameworks for Haystack that will allow for
using memory, RAG, prompts, OpenAI LLMs, and function calling:

from haystack.utils import Secret
from haystack.document_stores.in_memory import
InMemoryDocumentStore
from haystack.components.retrievers.in_memory import
InMemoryBM25Retriever
from haystack.components.builders.answer_builder import
AnswerBuilder
from haystack.components.builders.prompt_builder import
PromptBuilder

Chapter 10 haystaCk


from haystack import component, Pipeline, Document
from haystack.components.builders import PromptBuilder
from haystack.components.generators import OpenAIGenerator
from haystack.components.generators.chat.openai import
OpenAIChatGenerator
from haystack.dataclasses import ChatMessage
from haystack.components.joiners import BranchJoiner
from haystack_experimental.components.tools import
OpenAIFunctionCaller

Then we will create the data structure for the weather_fetch function
since we will not be using an API (although, in a production program, you
would do so):

WEATHER_INFO = {
"Berlin": {"weather": "mostly sunny", "temperature": 7,
"unit": "celsius"},
"Paris": {"weather": "mostly cloudy", "temperature": 8,
"unit": "celsius"},
"Rome": {"weather": "sunny", "temperature": 14, "unit":
"celsius"},
"Madrid": {"weather": "sunny", "temperature": 10, "unit":
"celsius"},
"London": {"weather": "cloudy", "temperature": 9, "unit":
"celsius"},
}

def get_current_weather(location: str):
if location in WEATHER_INFO:
return WEATHER_INFO[location]
else:
return {"weather": "sunny", "temperature": 70, "unit":
"fahrenheit"}

```
Chapter 10 haystaCk

Next, we define tools for the RAG pipeline and fetching the weather:
```
tools = [
{
"type": "function",
"function": {
"name": "rag_pipeline_func",
"description": "Get information about where
people live",
"parameters": {
"type": "object",
"properties": {
"query": {
"type": "string",
"description": "The query to use in
the search. Infer this from the user's
message. It should be a question or a
statement",
}
},
"required": ["query"],
},
},
},
{
"type": "function",
"function": {
"name": "get_current_weather",
"description": "Get the current weather",
"parameters": {
"type": "object",
"properties": {

Chapter 10 haystaCk


"location": {"type": "string",
"description": "The city"}
},
"required": ["location"],
},
},
},
]

```
Then we use the tools in the chat_agent:
```
message_collector = BranchJoiner(List[ChatMessage])
chat_generator = OpenAIChatGenerator(api_key=Secret.
from_token(api_key),model="gpt-3.5-turbo", generation_
kwargs={'tools': tools})
function_caller = OpenAIFunctionCaller(available_
functions={"rag_pipeline_func": rag_pipeline,
"get_current_
weather":
get_current_
weather})

chat_agent = Pipeline()
chat_agent.add_component("message_collector", message_
collector)
chat_agent.add_component("generator", chat_generator)
chat_agent.add_component("function_caller", function_caller)

chat_agent.connect("message_collector", "generator.messages")
chat_agent.connect("generator", "function_caller")
chat_agent.connect("function_caller.function_replies",
"message_collector")
chat_agent.show()

```
Chapter 10 haystaCk
```

The function chat first takes what the user typed and appends it in a
list that contains the record of the conversation. This is important as the
system needs to know what has been discussed so that answers come out
correctly in the context. The chat_agent.run() method sends the user
query to an endpoint on OpenAI's API, which then decides if a function
call is needed or if a simple text reply will be enough. So, with a query
dealing with weather, the system will invoke a pre-set function to fetch
current weather. These are then appended to the conversation history for
continuity in the chat, and the first response of the assistant is returned
and displayed to the user. Figure 10-1 shows the workflow.

Chapter 10 haystaCk


**Figure 10-1.** _Haystack chat agent architecture_

```
Chapter 10 haystaCk
```

We will now make an interactive chat interface using Gradio using the
gr.ChatInterface() function. We provide a few example questions that
the user can try, such as “How is the weather in Madrid?” and “Who lives
in London?” These examples give users an idea of how to interact with the
system and some of the things it can do.

def chat(message, history):
messages.append(ChatMessage.from_user(message))
response = chat_agent.run({"message_collector": {"value":
messages}})
messages.extend(response['function_caller']['assistant_
replies'])
return response['function_caller']['assistant_replies']
[0].content

demo = gr.ChatInterface(
fn=chat,
examples=[
"Can you tell me where Giorgio lives?",
"What's the weather like in Madrid?",
"Who lives in London?",
"What's the weather like where Mark lives?",
],
title="Ask me about weather or where people live!",
)
demo.launch(share=True)

Finally, we start the interface using the following command: demo.
launch(share=True). It opens a web-based chat interface for inputting
the queries. The argument “share=True” will provide the notebook with a
public URL to use it.

Chapter 10 haystaCk


The whole process works once the user types something in the dialog
interface. It gets processed through the chat agent that makes a decision
on whether to give a text-based answer or make a function call in order to
fetch data, such as weather information. The agent then gives a real-time
response, and at every new exchange, the conversation history updates,
therefore making the system more interactive.

Conclusion

Haystack provides a flexible, modular platform for building sophisticated
AI applications, particularly those leveraging RAG pipelines. Its open
source framework allows developers to integrate a wide variety of tools,
databases, and LLMs, making it ideal for creating not only advanced NLP
solutions but also powerful AI agents. These agents can dynamically
interact with users, retrieve relevant information, and perform tasks
like function calling in real time. Whether through its open source
framework or the enterprise-focused Deepset Cloud, Haystack streamlines
the development and deployment of AI-driven applications, offering
businesses a robust solution for managing and scaling NLP workflows and
AI agent interactions.

```
Chapter 10 haystaCk
```

© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 251

https://doi.org/10.1007/979-8-8688-1134-0_11

**CHAPTER 11**

**Takeaways**

As we write the last chapter of this book, the category for AI agents has
accelerated. The pace of change is really breathtaking.
A major validation of the space is the adoption of this technology from
some of the world’s largest technology companies. They understand the
transformative nature of this technology—how it will go well beyond the
typical chatbot approach for generative AI.
Consider the following developments:

- Salesforce’s Agentforce: This is a platform that provides
    conversational capabilities and autonomous agents
    for many tasks, such as CRM (customer relationship
    management), marketing, and data management.
    Agentforce has advanced embedding models that allow
    for working with complex business workflows and
    processes. They are also multimodal, handling images,
    audio, and video. In fact, according to Saleforce’s CEO,
    Marc Benioff, there will be one billion AI agents by the
    end of fiscal year 2026.^1
- ServiceNow’s Xanadu: This agentic system automates
    complex processes for customer service management (CSM)
    and IT service management (ITSM). For example, if a
    customer reports a Wi-Fi issue, an AI agent can verify

(^1) https://finance.yahoo.com/news/salesforce-co-founder-and-ceo-marc-
benioff-autonomous-ai-agents-will-beat-copilots-155044728.html


```
network stability, analyze similar past cases, request router
details from the customer, and guide the human agent
through the next steps—all while following company
policies.^2
```
- Workday: The company has released various HR and
    financial management agents. They are based on the
    training of models for 800 billion business transactions.
    Among the agents, there is Recruiter. It automates
    the workflows for identifying talent, outreach, and
    scheduling interviews.^3
- Oracle: The company has created more than 50 role-
    based AI agents for its Cloud Fusion Applications
    Suite. They span use cases for ERP (enterprise resource
    planning), HCM (human capital management), SCM
    (supply chain management), and CX (customer
    experience).^4
All these examples point to the strategic importance of AI agents. They
also highlight the many opportunities for developers.
According to Jensen Huang, who is the CEO and cofounder of Nvidia,
“This is an extraordinary time. In no time in history has technology moved
faster than Moore’s Law. We’re moving way faster than Moore’s Law,
reasonably Moore’s Law squared.”^5

(^2) https://www.crn.com/news/ai/2024/servicenow-partner-summit-xanadu-
release-the-biggest-ai-news
(^3) https://www.cio.com/article/3526668/will-workdays-new-ai-agents-set-
it-apart-from-competitors.html
(^4) https://finance.yahoo.com/news/oracle-adds-powerful-ai-capabilities-
132000823.html
(^5) https://venturebeat.com/ai/why-jensen-huang-and-marc-benioff-see-
gigantic- opportunity-for-agentic-ai/
Chapter 11 t akeaways


He also is a big believer in AI agents. He has said that they are a
“gigantic” opportunity and are in the “flywheel zone.”
Or consider this from Juan Jose Lopez Murphy, who is the Head of
Data Science and AI at Globant:

_AI Agents will have important use cases throughout different
industries. The more mature they are in their digital journeys,
the more they’ll act like software companies. In media and
entertainment, they’ll be used to process and aggregate even
more data for analysis and share faster, more exact personal-
ized recommendations for each user. In healthcare, AI Agents
could be used to create even stronger predictions of future
diagnoses based on initial symptoms. Agents could also pro-
actively search and test compounds, proteins, new drug devel-
opments and many exploration tasks that are very time
consuming and that combine a requirement of extensive
knowledge and high creativity._^6
These are certainly exciting times. And yes, our book is a way to get
a starting-off point to participate in this industry. You can then build on
this—focusing on those areas you find most interesting.
For the last chapter of this book, we’ll provide some takeaways and
observations. True, the category for AI agents is moving fast. But for the
most part, it seems very clear it’s an area that is poised for long-
term growth.

Rethinking Software

In this book, we saw how AI agents will be transformative across industries
and personal applications alike. From revolutionizing business workflows
to enhancing customer experiences, AI agents represent a fundamental
shift in how we interact with technology. The potential of these systems

(^6) This quote is from an interview with the authors of this book.
Chapter 11 t akeaways


lies not only in their ability to automate complex tasks but also in their
capacity to operate autonomously, learning and adapting in real time.
This evolution is already prompting significant changes, especially in
the areas of user interface (UI) and user experience (UX) design, which
must be rethought to accommodate the unique challenges of AI-driven
interactions.
Unlike traditional software that follows predictable, rule-based
workflows, AI agents require dynamic interfaces that balance autonomy
with user control. Users need transparency into the agent's decision-
making process and should be able to intervene when necessary while also
benefiting from a seamless, automated experience. This calls for interfaces
that can manage complex tasks in the background, yet provide timely
updates and options for human input. These changes will fundamentally
reshape how software is designed, emphasizing real-time feedback loops,
decision logs, and adaptable interfaces that evolve alongside the AI's
capabilities.
Moreover, the development process is changing. Whereas conventional
development follows a deterministic, step-by-step approach, working with
agentic AI relies on probabilistic models that generate outcomes based
on a range of potential inputs. This introduces unpredictability, requiring
extensive testing, fine-tuning, and ongoing iteration to ensure reliability.
Developers must now consider variables like model accuracy, data
integrity, and the potential for unexpected outputs. These complexities
demand new tools, workflows, and skill sets, as the development process
is less about writing rigid code and more about shaping models and
algorithms that can adapt to various scenarios.
Moreover, the distinction between traditional automation tools
like robotic process automation (RPA) and AI agents is also fading. AI
agents are evolving to perform not just repetitive, rule-based tasks but
also complex decision-making processes, often without direct human
oversight. This shift is driving a rethinking of business models, as the focus
moves from subscription-based services to outcome-based pricing, where

Chapter 11 t akeaways


companies pay for measurable improvements in productivity or cost
savings. In this context, AI agents are poised to become a cornerstone of
enterprise systems, seamlessly integrating with existing infrastructures and
driving efficiency in unprecedented ways.

The Challenges

While AI agents hold tremendous promise, they also come with notable
downsides that must be addressed for their widespread adoption. One
of the key challenges lies in the frameworks used to build these agents,
which are still in their nascent stages. Despite the excitement surrounding
platforms like LangChain, AutoGen, and LangGraph, their complexity
and evolving nature can make them difficult to work with. Developers
often face difficulties orchestrating multiple components—such as
memory, tools, and multi-agent systems—into a cohesive workflow. These
challenges are compounded by the need for human oversight, as fully
autonomous systems are not yet reliable enough to operate independently.
Data management presents another significant obstacle. AI agents
rely on vast amounts of data to function effectively, but managing this
data—especially in real time—can be overwhelming. Data orchestration,
which involves coordinating data from different sources, presents its own
difficulties, particularly when systems require frequent updates or process
dynamic data types.
Furthermore, these agents often deal with highly sensitive information,
raising serious concerns about privacy, security, and governance. Without
robust measures in place, the risks of data breaches, unauthorized
access, or unintentional misuse increase, potentially eroding trust in the
technology. Ensuring that AI agents are secure, private, and adhere to
governance standards is crucial for their long-term viability, particularly in
sectors like healthcare, finance, and enterprise applications.

```
Chapter 11 t akeaways
```

Another major limitation of current AI agents is the reliance on
transformer models, which have inherent weaknesses. These models,
while revolutionary, are prone to hallucinations—where the AI generates
false or misleading information—and have cut-off dates for their training
data, making them unable to provide up-to-date or entirely accurate
information. While progress has been made in improving the reliability
of large language models (LLMs), there is still much work to be done to
make them more dependable in high-stakes environments. Additionally,
transformers are resource-intensive, requiring significant computational
power and energy, making them costly and less sustainable at scale.

AI Agent Frameworks

In this book, we have covered several of the leading AI agent frameworks,
such as LangGraph, AutoGen, CrewAI, LangChain, and Haystack.
So which one to use? There are no clear-cut answers. Part of this is due
to the fact that the industry is moving so quickly.
Yet there are still some general factors to keep in mind. For example,
LangGraph approaches agents by using graphs for the decision-making
processes. This allows for more granular control of the workflows.
LangGraph will work fine in projects where complex decision-making
processes are required, such as in a customer service system, which will
take into consideration hundreds of different situations. The framework
also provides strong traceability.
AutoGen, on the other hand, is well suited for collaboration. In fact, it
can handle many functions out of the box. Think of AutoGen as a system
where various agents work together like a committee of experts. This
can be helpful with scenarios like major problem-solving and in making
advanced chatbots.

Chapter 11 t akeaways


Next, there is CrewAI. This framework is one of the most intuitive. Yet
it is still powerful. CrewAI is designed to mimic how human teams work.
That makes it a good choice for projects that require a number of different
roles, such as a virtual project management tool or a creative writing
assistant that uses different AIs.
As for LangChain, this is like the Swiss Army knife of AI frameworks:
very flexible, packed full of tools, and is a good choice if you want to build
something very specific or if you need to combine AI with other types of
data or systems. It has been around longer than the others, which generally
means there are more examples and community support to help you out.
Then there is Haystack. This framework is particularly good with
large datasets for RAG (Retrieval-Augmented Generation), with
many integrations for databases and deep NLP (natural language
processing) models.
Note that all of these frameworks work seamlessly with LLMs. But each
does this differently. There are also important differences when it comes to
the size of the application and scalability.
No doubt, a critical factor for an agent framework is the ecosystem.
How many contributors does it have? How many times has it been
downloaded and starred?
LangChain and LangGraph have perhaps the most vibrant ecosystems.
But frameworks like AutoGen, CrewAI, and Haystack have been gaining
lots of momentum. AutoGen also has the advantage of the backing of
Microsoft. This is certainly important for enterprises.
In choosing between frameworks, consider your project's complexity,
your team's strengths, the desired project growth, and special needs. If you
are in doubt, it’s a good idea to try a couple to find out what works best.
Remember, there is no one-size-fits-all answer. The best depends on what
you're trying to build and who is going to use it.
Table 11-1 provides comparisons among these frameworks.

```
Chapter 11 t akeaways

Table 11-1.
```
```
A Comparison Table for AI Agent Frameworks
```
```
Factor
```
```
LangGraph
```
```
AutoGen
```
```
CrewAI
```
```
LangChain
```
```
Haystack
```
```
Complexity
```
### ✅✅✅

### ✅✅

### ✅

### ✅✅✅

### ✅✅

```
ease of Use
```
### ✅

### ✅✅

### ✅✅✅

### ✅

### ✅✅

```
Multi-agent Collaboration
```
### ✅✅

### ✅✅✅

### ✅✅

### ✅✅

### ✅

```
Visualization of w
orkflows
```
### ✅✅✅

### ✅

### ✅✅

### ✅

### ✅✅

```
Customization Factor
```
### ✅✅

### ✅

### ✅

### ✅✅✅

### ✅✅

```
Community support
```
### ✅

### ✅✅

### ✅

### ✅✅✅

### ✅✅

```
Learning Curve
```
```
steep
```
```
Moderate
```
```
Gentle
```
```
steep
```
```
Moderate
```
```
scalability
```
### ✅✅

### ✅✅✅

### ✅✅

### ✅✅✅

### ✅✅✅

Chapter 11 takeaways


Integration Capabilities

### ✅✅

### ✅✅

### ✅

### ✅✅✅

### ✅✅✅

```
Use Case examples
```
### 1.

```
advanced
diagnostic systems in healthcare2. Financial modeling with multiple decision points3.
```
```
adaptive
e-learning platforms4. Complex customer support chatbots
```
1. Collaborative research assistants2. Multi-expert consulting systems3. Complex problem-solving platforms4.

```
simulations of
multi-entity systems (e.g., economic models)
```
### 1.

```
aI-driven project
management tools2. Virtual event planning systems3. Creative writing assistants with specialized roles4. Business simulations for training
```
1. Customized industry-specific

```
aI
```
```
assistants2. Data analysis pipelines combining LLMs with other data sources3.
```
```
rapid prototyping
of various
```
```
aI
```
```
applications4. Content generation systems requiring fine-
grained control
```
1. Large-scale document search and retrieval systems2. Question-
    answering applications over large datasets3. Information extraction from unstructured data4. Building conversational

```
aI with
```
```
access to external knowledge
```
```
Legend:
```
### ✅

```
= Fair,
```
### ✅✅

```
= Good,
```
### ✅✅✅

### =

```
excellent
```
```
Chapter 11 takeaways
```

Conclusion

In this book, we covered quite a bit about the transformative potential of
AI agents, from their foundational components and evolving frameworks
to the challenges and innovations that lie ahead. Yet, as comprehensive
as this discussion has been, it is still a foundation for further learning and
exploration.
As you continue on your journey with AI agents, remember that
this field is still evolving, and staying curious and adaptive will be key to
mastering its complexities. New advancements will emerge and, with
them, fresh opportunities to push the boundaries of what AI can achieve.
The potential of AI agents is boundless, and we are only at the beginning of
this exciting transformation.
So, we wish you the best of luck as you continue to explore, innovate,
and make your mark in this rapidly advancing world of AI agents!

Chapter 11 takeaways


© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 261

https://doi.org/10.1007/979-8-8688-1134-0

**Glossary**

AGI (Artificial General Intelligence): A concept in AI that refers to a
machine’s ability to understand, learn, and apply knowledge across a wide
range of tasks, similar to human intelligence.
AI Agents: Software systems that operate autonomously, using artificial
intelligence to make decisions, perform tasks, and interact with users or
other systems without constant human intervention.
Alignment: The ability of a model to produce responses that meet user
expectations, ensuring outputs are coherent, contextually appropriate, and
aligned with the desired goals. Techniques like Reinforcement Learning
from Human Feedback (RLHF) enhance alignment.
AutoGen: An open source framework for building LLM-based
applications that feature multiple agents working together, enabling
advanced multi-agent conversational AI systems.
AutoGen Studio: A low-code platform within AutoGen that helps
developers create generative AI agents, providing tools for building skills,
models, agents, and workflows.
AutoGPT: An early generative AI system that aimed to automate
complex tasks with minimal human intervention, known for its initial
excitement followed by the realization of its limitations.
Autonomy: The ability of AI agents to independently make decisions
and execute tasks without human intervention, relying on their ability to
learn, adapt, and respond to new situations in real time.
Conditional Edges: In LangGraph, these are edges that use a function
to decide the next node(s) to transition to based on the current state of
the graph.


ConversableAgent: A specialized agent in AutoGen designed to
manage conversations effectively, handling input, processing it using
predefined logic, and generating appropriate responses.
Copilots: Specialized AI agents designed for specific applications
or domains, assisting with tasks like content creation, data analysis, or
decision-making within a particular context.
CrewAI: A system within OpenAI’s offerings that allows for the
development of sophisticated conversational agents, integrating multiple
AI technologies to create complex interactions.
Delimiters: Tools used in prompt engineering to clearly separate
different sections of text, enhancing the accuracy and focus of AI models in
processing information.
Directed Acyclic Graph (DAG): A conceptual model used in computer
science and mathematics, consisting of vertices connected by directed
edges with no cycles, often used in task scheduling and data processing.
Embodied Agents: AI systems that interact with the physical world,
often used in robotics or simulated environments to perform tasks like
navigation, assembly, or interaction with humans.
Fine-Tuning: The process of training a general AI model on a smaller,
task-specific dataset to refine its performance for particular applications.
Generative AI: A branch of AI that creates diverse content such as text,
images, videos, and music based on prompts, often utilizing large language
models (LLMs).
Goal-Based Agents: AI systems that achieve specific objectives by
considering future outcomes and planning their actions accordingly, often
using search algorithms to find the most efficient path to a goal.
Google Colab: A cloud-based Jupyter Notebook environment offering
free access to GPUs and TPUs, enabling AI practitioners to train and
deploy models without local setup.
Gradio: A web-based interface builder that allows developers to
quickly create demos for AI models, enabling real-time user interaction
with machine learning applications.

GLOSSARY


Haystack: A framework developed by Deepset, an open source tool
that allows developers to build advanced AI applications using large
language models (LLMs). It supports applications like question answering,
semantic search, and Retrieval-Augmented Generation (RAG) systems.
Hierarchical Agents: AI systems organized in a tiered structure
where high-level agents set overarching goals and lower-level agents
handle specific tasks to achieve those goals, optimizing efficiency and
decision-making.
Hugging Face: A platform and open source community that offers
pretrained AI models, datasets, and tools to simplify natural language
processing and generative AI applications.
Jupyter Notebook: A web-based interactive development environment
that combines live code, visualizations, and text, commonly used for
exploratory data analysis and AI model development.
Jupyter Widgets: Interactive elements such as sliders and buttons
that can be embedded within Jupyter Notebooks to allow dynamic
manipulation of parameters in AI models.
LangChain: A development framework for building generative AI
agents that integrate LLMs with various data sources and tools, allowing
for the creation of sophisticated AI-driven applications.
LangGraph: An open source framework by LangChain that allows
developers to create stateful and multi-actor AI applications, with a focus
on dynamic and adaptive agent architectures.
Learning Agents: AI systems that improve their performance over time
by learning from experiences, typically using machine learning techniques
to refine their actions and decisions.
LLM (Large Language Model): A type of AI model trained on vast
amounts of text data to generate humanlike responses, understand
context, and perform a wide range of language-related tasks.
Memory: In AI, the ability to retain and utilize information from
previous interactions, enabling the system to maintain context, learn from
experiences, and provide coherent and personalized responses.

```
GLOSSARY
```

Model-Based Reflex Agents: AI systems that enhance decision-making
by incorporating internal models of the environment, allowing them to
predict outcomes and make more informed actions.
Multimodal LLMs: Advanced language models that can process and
generate information across various data types such as text, images, audio,
and video, enabling more versatile interactions.
Multi-agent Collaboration: The interaction of multiple AI agents, each
specializing in different tasks, working together to achieve a common goal,
akin to how human teams operate.
Natural Language Processing (NLP): A field of artificial intelligence
that focuses on the interaction between computers and humans using
natural language. It enables machines to understand, interpret, and
generate human language.
Nodes: In LangGraph, these are Python functions that encode the logic
of agents, taking the current state as input, performing computations, and
returning an updated state.
Ollama: A tool that facilitates running large language models locally on
personal devices, providing the ability to load and interact with AI models
such as Llama 2 and Mistral.
Open Source LLMs and SLMs: Language models developed and
distributed openly, allowing for transparency, community collaboration,
and customization. Small language models (SLMs) are more efficient,
requiring less computational power and tailored for specific tasks.
Outcome-Based Pricing Model: A business model where charges
for software or services are based on measurable improvements in
productivity, cost savings, or decision-making effectiveness, rather than
the number of users or licenses.
Planning: The process by which AI agents determine a sequence
of steps to achieve a specific goal, breaking down complex tasks into
manageable actions.

GLOSSARY


Pretrained Models: LLMs that are trained on extensive datasets before
being fine-tuned for specific tasks, allowing for efficient adaptation to
various applications.
Prompt Engineering: The art and science of crafting inputs that guide
AI systems to generate accurate and relevant responses, often involving
iterative refinement of prompts.
Proprietary LLMs: Advanced AI systems owned and controlled by
private organizations, offering high performance but often with limitations
like customization and data privacy concerns.
Reflection Agent: A specialized agent in LangGraph designed to
analyze and evaluate its own decisions and actions, enabling it to improve
performance over time through self-assessment.
Retrieval-Augmented Generation (RAG): An AI technique where
external data sources are incorporated during text generation, improving
the accuracy of responses by retrieving relevant information.
RPA (Robotic Process Automation): Technology that automates
repetitive, rule-based tasks typically performed by humans, often used in
conjunction with AI to handle more complex processes.
Semantic Search: A search technique that improves upon traditional
keyword matching by understanding the meanings of words and phrases
in their broader context, providing more relevant search results.
Simple Reflex Agents: The most basic type of AI agents, operating
based on predefined rules that dictate how they should respond to specific
sensory inputs without using memory or learning from past experiences.
State in LangGraph: The current snapshot of an application managed
by LangGraph, which includes the schema and reducer functions that
dictate how updates are applied during workflow execution.
Streaming Outputs: A feature in LangGraph that allows real-time
streaming of results from nodes, enabling responsive interactions and
immediate feedback during AI operations.

```
GLOSSARY
```

Streamlit: A Python-based tool for creating simple, interactive web
applications, useful for visualizing AI model outputs like text or image
generation.
Synthetic Data: Artificially created data that mimics real-world data,
used to train AI models when real data is scarce or expensive to obtain.
Test-Time Training (TTT): An emerging AI model that processes more
data than transformers while consuming less energy, offering a constant
model size regardless of the data volume.
Tools: External APIs or software that AI agents use to extend their
capabilities, allowing them to perform complex tasks beyond their core
functions.
Transfer Learning: A machine learning technique where a model
trained on one task is repurposed for a different but related task, leveraging
the knowledge gained during initial training.
Transformer Models: A revolutionary architecture in natural language
processing that uses attention mechanisms for efficient data processing,
outperforming previous models like RNNs.
TPTU (Task Planning and Tool Usage) Framework: A system that
evaluates how effectively LLMs can plan tasks and utilize tools, allowing AI
agents to dynamically adjust their actions based on ongoing feedback.
Vector Databases: Specialized databases used to store and query
vector representations of data, particularly useful in AI applications like
semantic search, where similarities between data points are computed
based on their vector representations.

GLOSSARY


© Tom Taulli, Gaurav Deshmukh 2025 T. Taulli and G. Deshmukh, _Building Generative AI Agents_ , 267

https://doi.org/10.1007/979-8-8688-1134-0

